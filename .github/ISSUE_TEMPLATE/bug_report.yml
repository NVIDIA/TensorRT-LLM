name: "Bug Report"
description: Submit a bug report to help us improve TensorRT-LLM
labels: [ "bug" ]
body:
  - type: textarea
    id: system-info
    attributes:
      label: System Info
      description: Please share your system info with us.
      placeholder: |
        - CPU architecture (e.g., x86_64, aarch64)
        - CPU/Host memory size (if known)
        - GPU properties
          - GPU name (e.g., NVIDIA H100, NVIDIA A100, NVIDIA L40S)
          - GPU memory size (if known)
          - Clock frequencies used (if applicable)
        - Libraries
          - TensorRT-LLM branch or tag (e.g., main, v0.7.1)
          - TensorRT-LLM commit (if known)
          - Versions of TensorRT, Modelopt, CUDA, cuBLAS, etc. used
          - Container used (if running TensorRT-LLM in a container)
        - NVIDIA driver version
        - OS (Ubuntu 24.04, CentOS 8)
        - Any other information that may be useful in reproducing the bug
    validations:
      required: true

  - type: textarea
    id: who-can-help
    attributes:
      label: Who can help?
      description: |
        To expedite the response to your issue, it would be helpful if you could identify the appropriate person
        to tag using the **@** symbol. Here is a general guideline on **whom to tag**.

        Rest assured that all issues are reviewed by the core maintainers. If you are unsure about whom to tag,
        you can leave it blank, and a core maintainer will make sure to involve the appropriate person.

        Please tag fewer than 3 people.

        Quantization: @Tracin

        Documentation: @juney-nvidia

        Feature request: @ncomly-nvidia

        Performance: @kaiyux

        Others: @byshiue

      placeholder: "@Username ..."

  - type: checkboxes
    id: information-scripts-examples
    attributes:
      label: Information
      description: 'The problem arises when using:'
      options:
        - label: "The official example scripts"
        - label: "My own modified scripts"

  - type: checkboxes
    id: information-tasks
    attributes:
      label: Tasks
      description: "The tasks I am working on are:"
      options:
        - label: "An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)"
        - label: "My own task or dataset (give details below)"

  - type: textarea
    id: reproduction
    validations:
      required: true
    attributes:
      label: Reproduction
      description: |
        Kindly share a code example that demonstrates the issue you encountered. It is recommending to provide a code snippet directly.
        Additionally, if you have any error messages, or stack traces related to the problem, please include them here.

        Remember to use code tags to properly format your code. You can refer to the
        link https://help.github.com/en/github/writing-on-github/creating-and-highlighting-code-blocks#syntax-highlighting for guidance on code formatting.

        Please refrain from using screenshots, as they can be difficult to read and prevent others from copying and pasting your code.
        It would be most helpful if we could reproduce your issue by simply copying and pasting your scripts and codes.

      placeholder: |
        Steps to reproduce the behavior:

          1.
          2.
          3.

  - type: textarea
    id: expected-behavior
    validations:
      required: true
    attributes:
      label: Expected behavior
      description: "Provide a brief summary of the expected behavior of the software. Provide output files or examples if possible."

  - type: textarea
    id: actual-behavior
    validations:
      required: true
    attributes:
      label: actual behavior
      description: "Describe the actual behavior of the software and how it deviates from the expected behavior. Provide output files or examples if possible."

  - type: textarea
    id: additioanl-notes
    validations:
      required: true
    attributes:
      label: additional notes
      description: "Provide any additional context here you think might be useful for the TensorRT-LLM team to help debug this issue (such as experiments done, potential things to investigate)."
