Generate text in streaming
==========================
Source https://github.com/NVIDIA/TensorRT-LLM/blob/48b7b5d8b7ed1e6bff57aecc6ff7d1533288bed8/examples/llm-api/llm_inference_async_streaming.py.

.. literalinclude:: ../../../examples/llm-api/llm_inference_async_streaming.py
    :lines: 4-64
    :language: python
    :linenos:
