/*
 * SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: NVIDIA TensorRT Source Code License Agreement
 *
 * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
 * property and proprietary rights in and to this material, related
 * documentation and any modifications thereto. Any use, reproduction,
 * disclosure or distribution of this material and related documentation
 * without an express license agreement from NVIDIA CORPORATION or
 * its affiliates is strictly prohibited.
 */

#include "tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/include/nvrtcWrapper.h"

#include <cstring>
#include <cuda.h>
#include <nvrtc.h>
#include <sstream>
#include <string>
#include <unordered_map>
#include <vector>

// Would be generated by gen_cpp_header.py via CMake dependency.
#include "xqa_sources.h"

// We only read Data_type definition from this header file, should be safe because there is no C++ ABI stuff involved.
#include "tensorrt_llm/kernels/multiHeadAttentionCommon.h"

#define CHECK_NVRTC_ERROR(content)                                                                                     \
    do                                                                                                                 \
    {                                                                                                                  \
        nvrtcResult status_ = content;                                                                                 \
        if (status_ != NVRTC_SUCCESS)                                                                                  \
        {                                                                                                              \
            setErrorString("NVRTC Internal Error");                                                                    \
            return TLLM_XQA_JIT_INTERNAL_ERROR;                                                                        \
        }                                                                                                              \
    } while (0)

#define CHECK_TLLM_XQA_JIT_ERROR(content)                                                                              \
    do                                                                                                                 \
    {                                                                                                                  \
        tllmXqaJitStatus status_ = content;                                                                            \
        if (status_ != TLLM_XQA_JIT_SUCCESS)                                                                           \
        {                                                                                                              \
            return status_;                                                                                            \
        }                                                                                                              \
    } while (0)

struct _tllmXqaJitProgram
{
    nvrtcProgram program;
    tllmXqaJitContext const* context;
};

namespace
{

std::string gErrorString;

void setErrorString(std::string const& errorString)
{
    gErrorString = errorString;
}

std::string getMacroFlag(std::string const& name, std::string const& value)
{
    return "-D" + name + "=" + value;
}

std::string getSMFlag(int SM)
{
    std::string smStr = std::to_string(SM);
    if (SM == 90)
    {
        smStr += "a";
    }
    return "-arch=sm_" + smStr;
}

tllmXqaJitStatus getMacroFlags(tllmXqaJitContext const* context, std::vector<std::string>* result)
{
    // Macro name -> Macro value.
    std::unordered_map<std::string, std::string> macros;

    unsigned int head_size = context->head_size;
    unsigned int num_q_heads = context->num_q_heads;
    unsigned int num_kv_heads = context->num_kv_heads;
    if (num_q_heads % num_kv_heads != 0)
    {
        std::ostringstream oss;
        oss << "num_q_heads (" << num_q_heads << ") must be multiples of num_kv_heads (" << num_kv_heads << ").";
        setErrorString(oss.str());
        return TLLM_XQA_JIT_INVALID_INPUT;
    }
    unsigned int num_q_heads_over_kv = num_q_heads / num_kv_heads;
    unsigned int beam_width = context->beam_width;
    if (context->multi_query_tokens)
    {
        macros["SPEC_DEC"] = "1";
    }
    // MultiQueryToken kernels can handle either 16/32 for M direction per CTA.
    uint32_t const m_tilesize = [&context, num_q_heads_over_kv]() -> uint32_t
    {
        if (!context->multi_query_tokens)
        {
            return num_q_heads_over_kv;
        }
        if (context->kernel_type == TLLM_XQA_JIT_QGMMA)
        {
            return 64;
        }
        uint32_t const m = context->q_seq_len * num_q_heads_over_kv;
        return m < 16 ? 16 : 32;
    }();
    if (context->data_type == tensorrt_llm::kernels::DATA_TYPE_FP16)
    {
        macros["INPUT_FP16"] = "1";
        macros["DTYPE"] = "__half";
    }
    else if (context->data_type == tensorrt_llm::kernels::DATA_TYPE_BF16)
    {
        macros["INPUT_FP16"] = "0";
        macros["DTYPE"] = "__nv_bfloat16";
    }
    else
    {
        setErrorString("data_type is neither DATA_TYPE_FP16 nor DATA_TYPE_BF16");
        return TLLM_XQA_JIT_INVALID_INPUT;
    }

    macros["GENERATE_CUBIN"] = "1";
    macros["NDEBUG"] = "1";
    macros["HEAD_ELEMS"] = std::to_string(head_size);
    macros["BEAM_WIDTH"] = std::to_string(beam_width);

    if (context->kv_cache_data_type == tensorrt_llm::kernels::DATA_TYPE_INT8)
    {
        macros["CACHE_ELEM_ENUM"] = "1";
    }
    else if (context->kv_cache_data_type == tensorrt_llm::kernels::DATA_TYPE_E4M3)
    {
        macros["CACHE_ELEM_ENUM"] = "2";
    }
    else
    {
        if (context->data_type == tensorrt_llm::kernels::DATA_TYPE_FP16)
        {
            if (context->kv_cache_data_type != tensorrt_llm::kernels::DATA_TYPE_FP16)
            {
                setErrorString("kv_cache_data_type must be DATA_TYPE_FP16 when data_type is DATA_TYPE_FP16");
                return TLLM_XQA_JIT_INVALID_INPUT;
            }
        }
        else
        {
            if (context->kv_cache_data_type != tensorrt_llm::kernels::DATA_TYPE_BF16)
            {
                setErrorString("kv_cache_data_type must be DATA_TYPE_BF16 when data_type is not DATA_TYPE_FP16");
                return TLLM_XQA_JIT_INVALID_INPUT;
            }
        }
        macros["CACHE_ELEM_ENUM"] = "0";
    }

    macros["TOKENS_PER_PAGE"] = context->paged_kv_cache ? std::to_string(context->tokens_per_block) : "0";
    macros["HEAD_GRP_SIZE"] = std::to_string(num_q_heads_over_kv);
    macros["M_TILESIZE"] = std::to_string(m_tilesize);
    macros["USE_CUSTOM_BARRIER"] = "1";
    // Sliding window is not supported when spec dec is enabled.
    macros["SLIDING_WINDOW"] = context->multi_query_tokens ? "0" : "1";
    macros["LOW_PREC_OUTPUT"] = context->fp8_output ? "1" : "0";
    macros["USE_INPUT_KV"] = context->use_input_kv ? "1" : "0";
    macros["ROPE_STYLE"] = std::to_string(int(context->rope_style));

    // Without these macros, NVRTC uses precompiled headers for cuda_fp16.h etc.
    // Linking might fail due to ABI incompatibility.
    //
    // https://nvbugspro.nvidia.com/bug/4549708 this WAR is proposed to bypass the issue.
    macros["__FORCE_INCLUDE_CUDA_FP16_HPP_FROM_FP16_H__"] = "1";
    macros["__FORCE_INCLUDE_CUDA_BF16_HPP_FROM_BF16_H__"] = "1";

    for (auto const& macro : macros)
    {
        result->push_back(getMacroFlag(macro.first, macro.second));
    }

#ifndef NDEBUG
    std::stringstream ss;
    ss << "XQA Macros: ";
    for (auto const& [k, v] : macros)
    {
        ss << k << "=" << v << " ";
    }
    puts(ss.str().c_str());
#endif

    return TLLM_XQA_JIT_SUCCESS;
}

tllmXqaJitStatus getBuildOptions(_tllmXqaJitProgram const* prog, std::vector<std::string>* result)
{
    // Common flags
    result->push_back("-dw");
    result->push_back("--use_fast_math");
    result->push_back("-default-device");

    // Arch
    result->push_back(getSMFlag(prog->context->sm));

    std::vector<std::string> macros;
    CHECK_TLLM_XQA_JIT_ERROR(getMacroFlags(prog->context, &macros));
    // Macros
    for (auto const& flag : macros)
    {
        result->push_back(flag);
    }

    return TLLM_XQA_JIT_SUCCESS;
}

tllmXqaJitStatus createProgram(tllmXqaJitProgram* prog, tllmXqaJitContext const* context)
{
    *prog = new _tllmXqaJitProgram;
    (*prog)->context = context;

    char const* src_content = context->kernel_type == TLLM_XQA_JIT_QGMMA ? tensorrt_llm::kernels::mha_sm90_cu_content
                                                                         : tensorrt_llm::kernels::mha_cu_content;

    std::vector<char const*> headers_content, headers_name;
    for (auto x : tensorrt_llm::kernels::xqa_headers_content)
        headers_content.push_back(x);
    for (auto x : tensorrt_llm::kernels::xqa_headers_name)
        headers_name.push_back(x);

    CHECK_NVRTC_ERROR(nvrtcCreateProgram(&(*prog)->program, src_content, /*name=*/nullptr, headers_content.size(),
        headers_content.data(), headers_name.data()));

    return TLLM_XQA_JIT_SUCCESS;
}

tllmXqaJitStatus compileProgram(tllmXqaJitProgram prog)
{
    std::vector<std::string> options;
    CHECK_TLLM_XQA_JIT_ERROR(getBuildOptions(prog, &options));
    std::vector<char const*> options_cstr;
    for (auto const& option : options)
    {
        options_cstr.push_back(option.c_str());
    }
#ifdef NDEBUG
    CHECK_NVRTC_ERROR(nvrtcCompileProgram(prog->program, options_cstr.size(), options_cstr.data()));
#else
    auto const err = nvrtcCompileProgram(prog->program, options_cstr.size(), options_cstr.data());
    if (err != NVRTC_SUCCESS)
    {
        size_t logSize;
        CHECK_NVRTC_ERROR(nvrtcGetProgramLogSize(prog->program, &logSize));
        std::string log;
        log.resize(logSize);
        CHECK_NVRTC_ERROR(nvrtcGetProgramLog(prog->program, log.data()));
        printf("nvrtc error log:\n%s\n", log.c_str());
        CHECK_NVRTC_ERROR(err);
    }
#endif
    return TLLM_XQA_JIT_SUCCESS;
}

} // anonymous namespace

tllmXqaJitStatus tllmXqaJitCreateAndCompileProgram(tllmXqaJitProgram* prog, tllmXqaJitContext const* context)
{
    CHECK_TLLM_XQA_JIT_ERROR(createProgram(prog, context));
    CHECK_TLLM_XQA_JIT_ERROR(compileProgram(*prog));
    return TLLM_XQA_JIT_SUCCESS;
}

tllmXqaJitStatus tllmXqaJitGetCUBINSize(tllmXqaJitProgram prog, size_t* cubinSizeRet)
{
    CHECK_NVRTC_ERROR(nvrtcGetCUBINSize(prog->program, cubinSizeRet));
    return TLLM_XQA_JIT_SUCCESS;
}

tllmXqaJitStatus tllmXqaJitGetCUBIN(tllmXqaJitProgram prog, char* cubin)
{
    CHECK_NVRTC_ERROR(nvrtcGetCUBIN(prog->program, cubin));
    return TLLM_XQA_JIT_SUCCESS;
}

tllmXqaJitStatus tllmXqaJitDestroyProgram(tllmXqaJitProgram* prog)
{
    CHECK_NVRTC_ERROR(nvrtcDestroyProgram(&(*prog)->program));

    delete *prog;
    *prog = nullptr;

    return TLLM_XQA_JIT_SUCCESS;
}

size_t tllmXqaJitGetLastErrorStringSize()
{
    return gErrorString.size() + 1;
}

void tllmXqaJitGetLastErrorString(char* output)
{
    if (gErrorString.empty())
    {
        return;
    }
    strcpy(output, gErrorString.c_str());
}
