{
    "templates": {
        "BatchedGemmFp4LowLatency": {
            "dtypeA": "e2m1",
            "dtypeC": "e2m1",
            "mmaM": 128,
            "mmaN": 8,
            "mmaK": 64,
            "tileM": 128,
            "tileN": 8,
            "tileK": 512,
            "epilogueTileM": 128,
            "epilogueTileN": 8,
            "numStages": 4,
            "numSlicesForSplitK": 1,
            "useTwoTmaLoadWarps": true,
            "clusterDimX": 1,
            "clusterDimY": 1,
            "clusterDimZ": 1,
            "sliceK": false,
            "transposeMmaOutput": true,
            "useShuffledMatrixA": true,
            "useDeepSeekFp8": false,
            "useTmaStore": true,
            "useCustomMmaSchedule": true,
            "gridTriggerSecondaryB": true,
            "gridWaitForPrimaryA": false,
            "gridWaitForPrimaryB": true,
            "sfLayoutB": "8x4",
            "sfLayoutC": "8x4",
            "batch": "N",
            "numExperts": 128,
            "useCudaGraph": true
        },
        "BatchedGemmPerTensorScalingFp8LowLatency": {
            "dtypeA": "e4m3",
            "dtypeC": "e4m3",
            "mmaM": 128,
            "mmaN": 8,
            "mmaK": 32,
            "tileM": 128,
            "tileN": 8,
            "tileK": 512,
            "epilogueTileM": 128,
            "epilogueTileN": 8,
            "numStages": 3,
            "numSlicesForSplitK": 1,
            "useTwoTmaLoadWarps": true,
            "clusterDimX": 1,
            "clusterDimY": 1,
            "clusterDimZ": 1,
            "sliceK": false,
            "transposeMmaOutput": true,
            "useShuffledMatrixA": true,
            "useDeepSeekFp8": false,
            "useTmaStore": true,
            "useCustomMmaSchedule": true,
            "gridTriggerSecondaryB": true,
            "gridWaitForPrimaryA": false,
            "gridWaitForPrimaryB": true,
            "batch": "N",
            "numExperts": 128,
            "useCudaGraph": true
        },
        "BatchedGemmDeepSeekFp8LowLatency": {
            "dtypeA": "e4m3",
            "dtypeC": "e4m3",
            "mmaM": 64,
            "mmaN": 8,
            "mmaK": 32,
            "tileM": 128,
            "tileN": 8,
            "tileK": 128,
            "epilogueTileM": 64,
            "epilogueTileN": 8,
            "numStages": 3,
            "numSlicesForSplitK": 1,
            "useTwoTmaLoadWarps": true,
            "clusterDimX": 1,
            "clusterDimY": 1,
            "clusterDimZ": 1,
            "sliceK": false,
            "transposeMmaOutput": true,
            "useShuffledMatrixA": false,
            "useDeepSeekFp8": true,
            "useTmaStore": true,
            "useCustomMmaSchedule": true,
            "numStagesMmaWithinWorkTile": 2,
            "gridTriggerSecondaryA": false,
            "gridTriggerSecondaryB": true,
            "gridWaitForPrimaryA": false,
            "gridWaitForPrimaryB": true,
            "hoistMmaTaskTryWaits": true,
            "numStagesMma": 4,
            "batch": "N",
            "numExperts": 128,
            "useCudaGraph": true
        }
    },
    "configs": [
        {
            "_template": "BatchedGemmFp4LowLatency",
            "routeAct": false,
            "fusedAct": false,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": ["bf16", "fp16", "e2m1"],
            "listN": "8,8",
            "numExperts": 2,
            "numStagesMma": 1,
            "tileScheduler": "static"
        },
        {
            "_template": "BatchedGemmPerTensorScalingFp8LowLatency",
            "routeAct": false,
            "fusedAct": false,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": ["bf16", "fp16", "e4m3"],
            "listN": "8,8",
            "numExperts": 2,
            "numStagesMma": 1,
            "tileScheduler": "static"
        },
        {
            "_template": "BatchedGemmDeepSeekFp8LowLatency",
            "routeAct": false,
            "fusedAct": false,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": ["bf16", "fp16", "e4m3"],
            "listN": "8,8",
            "numExperts": 2,
            "numStagesMma": 2,
            "tileScheduler": "static"
        },
        {
            "_comment": "FP4_FC1",
            "_template": "BatchedGemmFp4LowLatency",
            "routeAct": true,
            "fusedAct": true,
            "sfLayoutB": "linear",
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": "e2m1",
            "numTokens": 2,
            "numExperts": 2,
            "mmaN,tileN,epilogueTileN,tileK,numStages": [
                [8, 8, 8, 512, 4],
                [16, 16, 16, 512, 4],
                [32, 32, 32, 512, 4],
                [64, 64, 64, 256, 6]
            ],
            "tileScheduler,numStagesMma": [
                ["static", 1],
                ["persistent", 2]
            ]
        },
        {
            "_comment": "FP4_FC2",
            "_template": "BatchedGemmFp4LowLatency",
            "routeAct": false,
            "fusedAct": false,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": "bf16",
            "numTokens": 2,
            "numExperts": 2,
            "tileN,epilogueTileN,mmaN,tileK,numStages": [
                [8, 8, 8, 512, 4],
                [16, 16, 16, 512, 4],
                [32, 32, 32, 512, 4],
                [64, 64, 64, 512, 3],
                [8, 8, 8, 256, 6],
                [16, 16, 16, 256, 6],
                [32, 32, 32, 256, 6],
                [64, 64, 64, 256, 6]
            ],
            "tileScheduler,numStagesMma": [
                ["static", 1],
                ["persistent", 2]
            ]
        },
        {
            "_comment": "DS_FP8_FC1",
            "_template": "BatchedGemmDeepSeekFp8LowLatency",
            "routeAct": true,
            "fusedAct": false,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": "e4m3",
            "numTokens": 2,
            "numExperts": 2,
            "mmaN,tileN,epilogueTileN,numStages": [
                [8, 8, 8, 8],
                [16, 16, 16, 6],
                [32, 32, 32, 4],
                [64, 64, 64, 4]
            ],
            "tileScheduler,numStagesMma": [
                ["static", 2],
                ["persistent", 4]
            ]
        },
        {
            "_comment": "DS_FP8_FC2",
            "_template": "BatchedGemmDeepSeekFp8LowLatency",
            "routeAct": false,
            "fusedAct": false,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": "bf16",
            "numTokens": 2,
            "numExperts": 2,
            "mmaN,tileN,epilogueTileN,numStages": [
                [8, 8, 8, 8],
                [16, 16, 16, 6],
                [32, 32, 32, 4],
                [64, 64, 64, 4]
            ],
            "tileScheduler,numStagesMma": [
                ["static", 2],
                ["persistent", 4]
            ]
        },
        {
            "_comment": "Llama4_FP8_FC1",
            "_template": "BatchedGemmPerTensorScalingFp8LowLatency",
            "routeAct": true,
            "fusedAct": true,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": "e4m3",
            "numTokens": 2,
            "numExperts": 2,
            "numStages": 3,
            "numStagesMma": 1,
            "tileScheduler": "static"
        },
        {
            "_comment": "Llama4_FP8_FC2",
            "_template": "BatchedGemmPerTensorScalingFp8LowLatency",
            "routeAct": false,
            "fusedAct": false,
            "useUnrollLoop2xForMma": [true, false],
            "dtypeC": "bf16",
            "numTokens": 2,
            "numExperts": 2,
            "numStages": 3,
            "tileScheduler,numStagesMma": [
                ["static", 1],
                ["persistent", 2]
            ]
        }
    ]
}
