Run trtllm-serve with pytorch backend on Slurm
==============================================
Source https://github.com/NVIDIA/TensorRT-LLM/blob/31116825b39f4e6a6a1e127001f5204b73d1dc32/examples/llm-api/llm_mgmn_trtllm_serve.sh.

.. literalinclude:: ../../../examples/llm-api/llm_mgmn_trtllm_serve.sh
    :lines: 1-10,14-56
    :language: bash
    :linenos:
