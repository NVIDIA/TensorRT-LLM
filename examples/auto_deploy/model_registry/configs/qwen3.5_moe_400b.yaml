runtime: trtllm
compile_backend: torch-cudagraph
max_seq_len: 2048
max_num_tokens: 2048
max_batch_size: 512
world_size: 8
enable_chunked_prefill: true
model_factory: AutoModelForCausalLM
kv_cache_config:
  enable_block_reuse: false
  free_gpu_memory_fraction: 0.95
  tokens_per_block: 64
model_kwargs:
  torch_dtype: bfloat16
# skip_loading_weights: true
