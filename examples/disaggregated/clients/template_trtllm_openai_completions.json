{
  "dataset": {
      "type": "fixed_isl_osl"
  },
  "inference_server": {
      "type": "trtllm_openai_completions",
      "host": "test",
      "port": null,
      "inference_server_config": {
        "model_name": "test"
      }
  },
  "timing_strategy": {
      "type": "fixed",
      "desired_rps": -1
    },
  "post_processors": [
    {
      "type": "infbench_summary",
      "model_name": "test"
    }
],
  "timeout": null
}
