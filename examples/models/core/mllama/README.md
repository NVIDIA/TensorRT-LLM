# MLLaMA (llama-3.2 Vision model)

MLLaMA is a multimodal model, and reuse the multimodal modules in [examples/models/core/multimodal](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/models/core/multimodal)
