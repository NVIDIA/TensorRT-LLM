# arch: MODEL_CLASS_MAPPING key; required when model has get_model_defaults. Add when adding entries.
- model: Qwen/Qwen3-Next-80B-A3B-Thinking
  arch: Qwen3NextForCausalLM
  config_path: examples/configs/curated/qwen3-next.yaml
- model: Qwen/Qwen3-30B-A3B
  arch: Qwen3MoeForCausalLM
  config_path: examples/configs/curated/qwen3.yaml
- model: Qwen/Qwen3-30B-A3B
  arch: Qwen3MoeForCausalLM
  config_path: examples/configs/curated/qwen3-disagg-prefill.yaml
- model: deepseek-ai/DeepSeek-R1-0528
  arch: DeepseekV3ForCausalLM
  config_path: examples/configs/curated/deepseek-r1-latency.yaml
- model: deepseek-ai/DeepSeek-R1-0528
  arch: DeepseekV3ForCausalLM
  config_path: examples/configs/curated/deepseek-r1-throughput.yaml
- model: deepseek-ai/DeepSeek-R1-0528
  arch: DeepseekV3ForCausalLM
  config_path: examples/configs/curated/deepseek-r1-deepgemm.yaml
- model: openai/gpt-oss-120b
  arch: GptOssForCausalLM
  config_path: examples/configs/curated/gpt-oss-120b-latency.yaml
- model: openai/gpt-oss-120b
  arch: GptOssForCausalLM
  config_path: examples/configs/curated/gpt-oss-120b-throughput.yaml
- model: nvidia/Llama-3.3-70B-Instruct-FP8
  arch: LlamaForCausalLM
  config_path: examples/configs/curated/llama-3.3-70b.yaml
- model: nvidia/Llama-4-Scout-17B-16E-Instruct-FP8
  arch: Llama4ForConditionalGeneration
  config_path: examples/configs/curated/llama-4-scout.yaml
