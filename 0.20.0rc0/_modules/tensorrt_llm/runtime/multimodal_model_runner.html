

<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tensorrt_llm.runtime.multimodal_model_runner &#8212; TensorRT-LLM</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/nvidia-sphinx-theme.css?v=df3ac72c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/autodoc_pydantic.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=65e89d2a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/tensorrt_llm/runtime/multimodal_model_runner';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = './_static/switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.20.0rc0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="0.20.0rc0" />


  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="TensorRT-LLM - Home"/>
    <img src="../../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="TensorRT-LLM - Home"/>
  
  
    <p class="title logo__title">TensorRT-LLM</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="TensorRT-LLM - Home"/>
    <img src="../../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="TensorRT-LLM - Home"/>
  
  
    <p class="title logo__title">TensorRT-LLM</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quick-start-guide.html">Quick Start Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../key-features.html">Key Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch.html">PyTorch Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../release-notes.html">Release Notes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../installation/linux.html">Installing on Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation/build-from-source-linux.html">Building from Source Code on Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation/grace-hopper.html">Installing on Grace Hopper</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../llm-api/index.html">API Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../llm-api/reference.html">API Reference</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples/index.html">LLM Examples Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_guided_decoding.html">Generate text with guided decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_logits_processor.html">Control generated text using logits processor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference.html">Generate text</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_async.html">Generate Text Asynchronously</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_async_streaming.html">Generate Text in Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_customize.html">Generate text with customization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_distributed.html">Distributed LLM Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_medusa_decoding.html">Generate Text Using Medusa Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_quantization.html">Generation with Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_lookahead_decoding.html">Generate Text Using Lookahead Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_eagle_decoding.html">Generate Text Using Eagle Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_kv_events.html">Get KV Cache Events</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_multilora.html">Generate text with multiple LoRA adapters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_auto_parallel.html">Automatic Parallelism with LLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_mgmn_llm_distributed.html">Llm Mgmn Llm Distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_mgmn_trtllm_bench.html">Llm Mgmn Trtllm Bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_mgmn_trtllm_serve.html">Llm Mgmn Trtllm Serve</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/customization.html">LLM Common Customizations</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples/llm_api_examples.html">LLM Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_guided_decoding.html">Generate text with guided decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_logits_processor.html">Control generated text using logits processor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference.html">Generate text</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_async.html">Generate Text Asynchronously</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_async_streaming.html">Generate Text in Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_customize.html">Generate text with customization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_distributed.html">Distributed LLM Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_medusa_decoding.html">Generate Text Using Medusa Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_quantization.html">Generation with Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_lookahead_decoding.html">Generate Text Using Lookahead Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_eagle_decoding.html">Generate Text Using Eagle Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_inference_kv_events.html">Get KV Cache Events</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_multilora.html">Generate text with multiple LoRA adapters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_auto_parallel.html">Automatic Parallelism with LLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_mgmn_llm_distributed.html">Llm Mgmn Llm Distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_mgmn_trtllm_bench.html">Llm Mgmn Trtllm Bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/llm_mgmn_trtllm_serve.html">Llm Mgmn Trtllm Serve</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples/trtllm_serve_examples.html">Online Serving Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/curl_chat_client.html">Curl Chat Client</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/curl_chat_client_for_multimodal.html">Curl Chat Client For Multimodal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/curl_completion_client.html">Curl Completion Client</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/genai_perf_client.html">Genai Perf Client</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/openai_chat_client.html">OpenAI Chat Client</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/openai_chat_client_for_multimodal.html">OpenAI Chat Client</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/openai_completion_client.html">OpenAI Completion Client</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Model Definition API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../python-api/tensorrt_llm.layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python-api/tensorrt_llm.functional.html">Functionals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python-api/tensorrt_llm.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python-api/tensorrt_llm.plugin.html">Plugin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python-api/tensorrt_llm.quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python-api/tensorrt_llm.runtime.html">Runtime</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">C++ API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../_cpp_gen/executor.html">Executor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_cpp_gen/runtime.html">Runtime</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Command-Line Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../commands/trtllm-build.html">trtllm-build</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../commands/trtllm-serve.html">trtllm-serve</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Architecture</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../architecture/overview.html">TensorRT-LLM Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architecture/core-concepts.html">Model Definition</a></li>



<li class="toctree-l1"><a class="reference internal" href="../../../architecture/checkpoint.html">TensorRT-LLM Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architecture/workflow.html">TensorRT-LLM Build Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architecture/add-model.html">Adding a Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/gpt-attention.html">Multi-Head, Multi-Query, and Group-Query Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/gpt-runtime.html">C++ GPT Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/executor.html">Executor API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/graph-rewriting.html">Graph Rewriting Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/lora.html">Run gpt-2b + LoRA using Executor / cpp runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/expert-parallelism.html">Expert Parallelism in TensorRT-LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/kv-cache-reuse.html">KV cache reuse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/speculative-decoding.html">Speculative Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/disaggregated-service.html">Disaggregated-Service (experimental)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Performance</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../performance/perf-overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../performance/perf-benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../performance/performance-tuning-guide/index.html">Performance Tuning Guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/performance-tuning-guide/benchmarking-default-performance.html">Benchmarking Default Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/performance-tuning-guide/useful-build-time-flags.html">Useful Build-Time Flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/performance-tuning-guide/tuning-max-batch-size-and-max-num-tokens.html">Tuning Max Batch Size and Max Num Tokens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/performance-tuning-guide/deciding-model-sharding-strategy.html">Deciding Model Sharding Strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/performance-tuning-guide/fp8-quantization.html">FP8 Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/performance-tuning-guide/useful-runtime-flags.html">Useful Runtime Options</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../performance/perf-analysis.html">Performance Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../reference/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/support-matrix.html">Support Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/precision.html">Numerical Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/memory.html">Memory Usage of TensorRT-LLM</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Blogs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../blogs/H100vsA100.html">H100 has 4.6x A100 Performance in TensorRT-LLM, achieving 10,000 tok/s at 100ms to first token</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../blogs/H200launch.html">H200 achieves nearly 12,000 tokens/sec on Llama2-13B with TensorRT-LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../blogs/Falcon180B-H200.html">Falcon-180B on a single H200 GPU with INT4 AWQ, and 6.7x faster Llama-70B over A100</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../blogs/quantization-in-TRT-LLM.html">Speed up inference with SOTA quantization techniques in TRT-LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../blogs/XQA-kernel.html">New XQA-kernel provides 2.4x more Llama-70B throughput within the same latency budget</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">tensorrt_llm.runtime.multimodal_model_runner</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for tensorrt_llm.runtime.multimodal_model_runner</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="n">BytesIO</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="c1"># isort: off</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="c1"># isort: on</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cuda</span><span class="w"> </span><span class="kn">import</span> <span class="n">cudart</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">hf_hub_download</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">safetensors</span><span class="w"> </span><span class="kn">import</span> <span class="n">safe_open</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoProcessor</span><span class="p">,</span>
                          <span class="n">AutoTokenizer</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">..</span><span class="w"> </span><span class="kn">import</span> <span class="n">profiler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.._utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">mpi_rank</span><span class="p">,</span> <span class="n">str_dtype_to_torch</span><span class="p">,</span> <span class="n">str_dtype_to_trt</span><span class="p">,</span>
                      <span class="n">supports_inflight_batching</span><span class="p">,</span> <span class="n">torch_dtype_to_trt</span><span class="p">,</span>
                      <span class="n">trt_dtype_to_torch</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">RopeEmbeddingUtils</span><span class="p">,</span> <span class="n">RotaryScalingType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">MropeParams</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..logger</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.enc_dec_model_runner</span><span class="w"> </span><span class="kn">import</span> <span class="n">EncDecModelRunner</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.model_runner</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelRunner</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.session</span><span class="w"> </span><span class="kn">import</span> <span class="n">Session</span><span class="p">,</span> <span class="n">TensorInfo</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">tensorrt_llm.bindings</span>  <span class="c1"># NOQA</span>
    <span class="n">PYTHON_BINDINGS</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">PYTHON_BINDINGS</span> <span class="o">=</span> <span class="kc">False</span>

<span class="k">if</span> <span class="n">PYTHON_BINDINGS</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">.model_runner_cpp</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelRunnerCpp</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LlavaNextUtils</span><span class="p">:</span>
    <span class="c1"># https://github.com/haotian-liu/LLaVA/blob/main/llava/mm_utils.py</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">select_best_resolution</span><span class="p">(</span><span class="n">original_size</span><span class="p">,</span> <span class="n">possible_resolutions</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Selects the best resolution from a list of possible resolutions based on the original size.</span>

<span class="sd">            Args:</span>
<span class="sd">                original_size (tuple): The original size of the image in the format (width, height).</span>
<span class="sd">                possible_resolutions (list): A list of possible resolutions in the format [(width1, height1), (width2, height2), ...].</span>

<span class="sd">            Returns:</span>
<span class="sd">                tuple: The best fit resolution in the format (width, height).</span>
<span class="sd">            &quot;&quot;&quot;</span>
        <span class="n">original_width</span><span class="p">,</span> <span class="n">original_height</span> <span class="o">=</span> <span class="n">original_size</span>
        <span class="n">best_fit</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">max_effective_resolution</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">min_wasted_resolution</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="ow">in</span> <span class="n">possible_resolutions</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">width</span> <span class="o">/</span> <span class="n">original_width</span><span class="p">,</span> <span class="n">height</span> <span class="o">/</span> <span class="n">original_height</span><span class="p">)</span>
            <span class="n">downscaled_width</span><span class="p">,</span> <span class="n">downscaled_height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                <span class="n">original_width</span> <span class="o">*</span> <span class="n">scale</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">original_height</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)</span>
            <span class="n">effective_resolution</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">downscaled_width</span> <span class="o">*</span> <span class="n">downscaled_height</span><span class="p">,</span>
                                       <span class="n">original_width</span> <span class="o">*</span> <span class="n">original_height</span><span class="p">)</span>
            <span class="n">wasted_resolution</span> <span class="o">=</span> <span class="p">(</span><span class="n">width</span> <span class="o">*</span> <span class="n">height</span><span class="p">)</span> <span class="o">-</span> <span class="n">effective_resolution</span>

            <span class="k">if</span> <span class="n">effective_resolution</span> <span class="o">&gt;</span> <span class="n">max_effective_resolution</span> <span class="ow">or</span> <span class="p">(</span>
                    <span class="n">effective_resolution</span> <span class="o">==</span> <span class="n">max_effective_resolution</span>
                    <span class="ow">and</span> <span class="n">wasted_resolution</span> <span class="o">&lt;</span> <span class="n">min_wasted_resolution</span><span class="p">):</span>
                <span class="n">max_effective_resolution</span> <span class="o">=</span> <span class="n">effective_resolution</span>
                <span class="n">min_wasted_resolution</span> <span class="o">=</span> <span class="n">wasted_resolution</span>
                <span class="n">best_fit</span> <span class="o">=</span> <span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">best_fit</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_anyres_image_grid_shape</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span>
                                    <span class="n">patch_size</span><span class="p">,</span>
                                    <span class="n">image_grid_pinpoints</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Calculate the shape of the image patch grid after the preprocessing for images of any resolution.</span>

<span class="sd">            Args:</span>
<span class="sd">                image_size (tuple): The size of the input image in the format (width, height).</span>
<span class="sd">                patch_size (int): The size of each image patch.</span>

<span class="sd">            Returns:</span>
<span class="sd">                tuple: The shape of the image patch grid in the format (width, height).</span>
<span class="sd">            &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">image_grid_pinpoints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">image_grid_pinpoints</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">336</span><span class="p">,</span> <span class="mi">672</span><span class="p">],</span> <span class="p">[</span><span class="mi">672</span><span class="p">,</span> <span class="mi">336</span><span class="p">],</span> <span class="p">[</span><span class="mi">672</span><span class="p">,</span> <span class="mi">672</span><span class="p">],</span>
                                    <span class="p">[</span><span class="mi">1008</span><span class="p">,</span> <span class="mi">336</span><span class="p">],</span> <span class="p">[</span><span class="mi">336</span><span class="p">,</span> <span class="mi">1008</span><span class="p">]]</span>
        <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">LlavaNextUtils</span><span class="o">.</span><span class="n">select_best_resolution</span><span class="p">(</span>
            <span class="n">image_size</span><span class="p">,</span> <span class="n">image_grid_pinpoints</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">width</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">height</span> <span class="o">//</span> <span class="n">patch_size</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">unpad_image</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">original_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Unpads a PyTorch tensor of a padded and resized image.</span>

<span class="sd">            Args:</span>
<span class="sd">            tensor (torch.Tensor): The image tensor, assumed to be in CxHxW format.</span>
<span class="sd">            original_size (tuple): The original size of the image (width, height).</span>

<span class="sd">            Returns:</span>
<span class="sd">            torch.Tensor: The unpadded image tensor.</span>
<span class="sd">            &quot;&quot;&quot;</span>
        <span class="n">original_width</span><span class="p">,</span> <span class="n">original_height</span> <span class="o">=</span> <span class="n">original_size</span>
        <span class="n">current_height</span><span class="p">,</span> <span class="n">current_width</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="n">original_aspect_ratio</span> <span class="o">=</span> <span class="n">original_width</span> <span class="o">/</span> <span class="n">original_height</span>
        <span class="n">current_aspect_ratio</span> <span class="o">=</span> <span class="n">current_width</span> <span class="o">/</span> <span class="n">current_height</span>

        <span class="k">if</span> <span class="n">original_aspect_ratio</span> <span class="o">&gt;</span> <span class="n">current_aspect_ratio</span><span class="p">:</span>
            <span class="n">scale_factor</span> <span class="o">=</span> <span class="n">current_width</span> <span class="o">/</span> <span class="n">original_width</span>
            <span class="n">new_height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">original_height</span> <span class="o">*</span> <span class="n">scale_factor</span><span class="p">)</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_height</span> <span class="o">-</span> <span class="n">new_height</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="n">unpadded_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[:,</span> <span class="n">padding</span><span class="p">:</span><span class="n">current_height</span> <span class="o">-</span> <span class="n">padding</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale_factor</span> <span class="o">=</span> <span class="n">current_height</span> <span class="o">/</span> <span class="n">original_height</span>
            <span class="n">new_width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">original_width</span> <span class="o">*</span> <span class="n">scale_factor</span><span class="p">)</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_width</span> <span class="o">-</span> <span class="n">new_width</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="n">unpadded_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">padding</span><span class="p">:</span><span class="n">current_width</span> <span class="o">-</span> <span class="n">padding</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">unpadded_tensor</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">rearrange_image_features</span><span class="p">(</span><span class="n">image_feature</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">,</span> <span class="n">image_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Combine PyTorch feature grids from image patches.</span>

<span class="sd">            Args:</span>
<span class="sd">            image_feature (torch.Tensor): The feature grids, assumed to be in NxCxHxW format.</span>
<span class="sd">            image_newline (torch.Tensor): The newline embedding.</span>
<span class="sd">            image_size (tuple): Size of the original image (width, height).</span>
<span class="sd">            &quot;&quot;&quot;</span>
        <span class="n">CLIP_IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">336</span>
        <span class="n">CLIP_PATCH_SIZE</span> <span class="o">=</span> <span class="mi">14</span>
        <span class="n">NUM_PATCHES_PER_SIDE</span> <span class="o">=</span> <span class="n">CLIP_IMAGE_SIZE</span> <span class="o">//</span> <span class="n">CLIP_PATCH_SIZE</span>
        <span class="k">if</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">image_feature</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">[</span><span class="kc">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">base_image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">width</span> <span class="o">=</span> <span class="n">NUM_PATCHES_PER_SIDE</span>
        <span class="k">assert</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span> <span class="o">==</span> <span class="n">base_image_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">num_patch_width</span><span class="p">,</span> <span class="n">num_patch_height</span> <span class="o">=</span> <span class="n">LlavaNextUtils</span><span class="o">.</span><span class="n">get_anyres_image_grid_shape</span><span class="p">(</span>
            <span class="n">image_size</span><span class="p">,</span> <span class="n">CLIP_IMAGE_SIZE</span><span class="p">)</span>
        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">num_patch_height</span><span class="p">,</span> <span class="n">num_patch_width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">LlavaNextUtils</span><span class="o">.</span><span class="n">unpad_image</span><span class="p">(</span><span class="n">image_feature</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>
        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">(</span><span class="n">image_feature</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                <span class="o">*</span><span class="n">image_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">image_feature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">base_image_feature</span><span class="p">,</span> <span class="n">image_feature</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image_feature</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LlavaOnevisionUtils</span><span class="p">:</span>
    <span class="c1"># https://github.com/huggingface/transformers/blob/main/src/transformers/models/llava_onevision/modeling_llava_onevision.py</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">pack_image_features</span><span class="p">(</span><span class="n">image_features</span><span class="p">,</span> <span class="n">image_sizes</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reshape, unpad and then pack each image_feature into a single image_features tensor containing all visual vectors.</span>

<span class="sd">        Args:</span>
<span class="sd">            image_features (`torch.Tensor` of shape `(num_images, num_patches, image_length, embed_dim)`)</span>
<span class="sd">                Image feature tensor, each contains all the visual feature of all patches.</span>
<span class="sd">            image_sizes (`torch.Tensor` of shape `(num_images, 2)`)</span>
<span class="sd">                Actual image size of each images (H, W).</span>
<span class="sd">            image_newline (`torch.Tensor` of shape `(embed_dim)`)</span>
<span class="sd">                New line embedding vector.</span>
<span class="sd">        Returns:</span>
<span class="sd">            image_features (`torch.Tensor` of shape `(all_feat_len, embed_dim)`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">384</span>
        <span class="n">PATCH_SIZE</span> <span class="o">=</span> <span class="mi">14</span>
        <span class="n">MAX_NUM_PATCHES</span> <span class="o">=</span> <span class="mi">9</span>

        <span class="n">new_image_features</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">image_idx</span><span class="p">,</span> <span class="n">image_feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">image_features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">base_image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
                <span class="n">height</span> <span class="o">=</span> <span class="n">width</span> <span class="o">=</span> <span class="n">IMAGE_SIZE</span> <span class="o">//</span> <span class="n">PATCH_SIZE</span>
                <span class="k">if</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span> <span class="o">!=</span> <span class="n">base_image_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;The number of patches is not consistent with the image size.&quot;</span>
                    <span class="p">)</span>

                <span class="n">IMAGE_GRID_PINPOINTS</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span> <span class="p">[</span><span class="mi">384</span><span class="p">,</span> <span class="mi">768</span><span class="p">],</span> <span class="p">[</span><span class="mi">384</span><span class="p">,</span> <span class="mi">1152</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">384</span><span class="p">,</span> <span class="mi">1536</span><span class="p">],</span> <span class="p">[</span><span class="mi">384</span><span class="p">,</span> <span class="mi">1920</span><span class="p">],</span> <span class="p">[</span><span class="mi">384</span><span class="p">,</span> <span class="mi">2304</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">768</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span> <span class="p">[</span><span class="mi">768</span><span class="p">,</span> <span class="mi">768</span><span class="p">],</span> <span class="p">[</span><span class="mi">768</span><span class="p">,</span> <span class="mi">1152</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">768</span><span class="p">,</span> <span class="mi">1536</span><span class="p">],</span> <span class="p">[</span><span class="mi">768</span><span class="p">,</span> <span class="mi">1920</span><span class="p">],</span> <span class="p">[</span><span class="mi">768</span><span class="p">,</span> <span class="mi">2304</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span> <span class="p">[</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">768</span><span class="p">],</span> <span class="p">[</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">1152</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">1536</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">1920</span><span class="p">],</span> <span class="p">[</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">2304</span><span class="p">],</span> <span class="p">[</span><span class="mi">1536</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">1536</span><span class="p">,</span> <span class="mi">768</span><span class="p">],</span> <span class="p">[</span><span class="mi">1536</span><span class="p">,</span> <span class="mi">1152</span><span class="p">],</span> <span class="p">[</span><span class="mi">1536</span><span class="p">,</span> <span class="mi">1536</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">1536</span><span class="p">,</span> <span class="mi">1920</span><span class="p">],</span> <span class="p">[</span><span class="mi">1536</span><span class="p">,</span> <span class="mi">2304</span><span class="p">],</span> <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mi">768</span><span class="p">],</span> <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mi">1152</span><span class="p">],</span> <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mi">1536</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mi">1920</span><span class="p">],</span> <span class="p">[</span><span class="mi">1920</span><span class="p">,</span> <span class="mi">2304</span><span class="p">],</span> <span class="p">[</span><span class="mi">2304</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">2304</span><span class="p">,</span> <span class="mi">768</span><span class="p">],</span> <span class="p">[</span><span class="mi">2304</span><span class="p">,</span> <span class="mi">1152</span><span class="p">],</span> <span class="p">[</span><span class="mi">2304</span><span class="p">,</span> <span class="mi">1536</span><span class="p">],</span>
                                        <span class="p">[</span><span class="mi">2304</span><span class="p">,</span> <span class="mi">1920</span><span class="p">],</span> <span class="p">[</span><span class="mi">2304</span><span class="p">,</span> <span class="mi">2304</span><span class="p">]]</span>
                <span class="n">num_patch_width</span><span class="p">,</span> <span class="n">num_patch_height</span> <span class="o">=</span> <span class="n">LlavaNextUtils</span><span class="o">.</span><span class="n">get_anyres_image_grid_shape</span><span class="p">(</span>
                    <span class="n">image_sizes</span><span class="p">[</span><span class="n">image_idx</span><span class="p">][[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span>
                    <span class="n">IMAGE_GRID_PINPOINTS</span><span class="p">)</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">num_patch_height</span><span class="p">,</span>
                                                   <span class="n">num_patch_width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span>
                                                   <span class="n">width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                                                      <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">LlavaNextUtils</span><span class="o">.</span><span class="n">unpad_image</span><span class="p">(</span>
                    <span class="n">image_feature</span><span class="p">,</span> <span class="n">image_sizes</span><span class="p">[</span><span class="n">image_idx</span><span class="p">][[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

                <span class="n">channels</span><span class="p">,</span> <span class="n">curr_height</span><span class="p">,</span> <span class="n">curr_width</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">curr_height</span> <span class="o">*</span> <span class="n">curr_width</span> <span class="o">/</span>
                                  <span class="p">(</span><span class="n">MAX_NUM_PATCHES</span> <span class="o">*</span> <span class="n">height</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">ratio</span> <span class="o">&gt;</span> <span class="mf">1.1</span><span class="p">:</span>
                    <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span>
                    <span class="n">image_feature</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
                        <span class="n">image_feature</span><span class="p">,</span>
                        <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">curr_height</span> <span class="o">//</span> <span class="n">ratio</span><span class="p">),</span>
                         <span class="nb">int</span><span class="p">(</span><span class="n">curr_width</span> <span class="o">//</span> <span class="n">ratio</span><span class="p">)],</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">image_feature</span><span class="p">,</span>
                        <span class="n">image_newline</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                            <span class="o">*</span><span class="n">image_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                <span class="n">image_feature</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                    <span class="p">),</span>
                    <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">base_image_feature</span><span class="p">,</span> <span class="n">image_feature</span><span class="p">),</span>
                                          <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">image_feature</span> <span class="o">=</span> <span class="n">image_feature</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">image_newline</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">image_feature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">image_feature</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">image_feature</span><span class="p">)),</span>
                        <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">new_image_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_feature</span><span class="p">)</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">new_image_features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image_features</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">apply_pooling</span><span class="p">(</span><span class="n">image_features</span><span class="p">):</span>
        <span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">384</span>
        <span class="n">PATCH_SIZE</span> <span class="o">=</span> <span class="mi">14</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">width</span> <span class="o">=</span> <span class="n">IMAGE_SIZE</span> <span class="o">//</span> <span class="n">PATCH_SIZE</span>
        <span class="n">batch_frames</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_frames</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">scaled_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">height</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">width</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">image_features</span><span class="p">,</span>
                                                   <span class="n">size</span><span class="o">=</span><span class="n">scaled_shape</span><span class="p">,</span>
                                                   <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">)</span>

        <span class="n">image_features</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_frames</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image_features</span>


<span class="k">class</span><span class="w"> </span><span class="nc">PhiMMUtils</span><span class="p">:</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_image_newline</span><span class="p">(</span><span class="n">image_features</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">):</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">image_newline</span> <span class="o">=</span> <span class="n">image_newline</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">image_features_newline</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">image_features</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">],</span>
                                           <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image_features_newline</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reshape_hd_patches</span><span class="p">(</span><span class="n">image_features</span><span class="p">,</span> <span class="n">h_crop</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">w_crop</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">n_crops</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">n_crops</span> <span class="o">==</span> <span class="n">h_crop</span> <span class="o">*</span> <span class="n">w_crop</span>

        <span class="n">h</span> <span class="o">=</span> <span class="n">w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tokens</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">h_crop</span><span class="p">,</span> <span class="n">w_crop</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span>
            <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h_crop</span> <span class="o">*</span> <span class="n">h</span><span class="p">,</span> <span class="n">w_crop</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image_features</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">hd_feature_transform</span><span class="p">(</span><span class="n">image_features</span><span class="p">,</span>
                             <span class="n">h_crop</span><span class="p">,</span>
                             <span class="n">w_crop</span><span class="p">,</span>
                             <span class="n">sub_GN</span><span class="p">,</span>
                             <span class="n">glb_GN</span><span class="p">,</span>
                             <span class="n">patch_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">glb_image_features</span> <span class="o">=</span> <span class="n">PhiMMUtils</span><span class="o">.</span><span class="n">add_image_newline</span><span class="p">(</span>
            <span class="n">PhiMMUtils</span><span class="o">.</span><span class="n">reshape_hd_patches</span><span class="p">(</span><span class="n">image_features</span><span class="p">[:</span><span class="mi">1</span><span class="p">]),</span> <span class="n">sub_GN</span><span class="p">)</span>

        <span class="n">num_crops</span> <span class="o">=</span> <span class="n">h_crop</span> <span class="o">*</span> <span class="n">w_crop</span>
        <span class="n">sub_image_features</span> <span class="o">=</span> <span class="n">PhiMMUtils</span><span class="o">.</span><span class="n">reshape_hd_patches</span><span class="p">(</span>
            <span class="n">image_features</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">num_crops</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">h_crop</span><span class="p">,</span> <span class="n">w_crop</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">patch_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">patch_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">patch_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="n">sub_image_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">patch_mask</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">num_crops</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span>
                                         <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                                             <span class="n">h_crop</span><span class="p">,</span> <span class="n">w_crop</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span>
                                             <span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                                                 <span class="n">h_crop</span> <span class="o">*</span> <span class="n">h</span><span class="p">,</span> <span class="n">w_crop</span> <span class="o">*</span> <span class="n">w</span><span class="p">))</span>
            <span class="n">hh</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sub_image_mask</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">ww</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sub_image_mask</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">sub_image_features</span> <span class="o">=</span> <span class="n">sub_image_features</span><span class="p">[:</span><span class="n">hh</span><span class="p">,</span> <span class="p">:</span><span class="n">ww</span><span class="p">]</span>
        <span class="n">sub_image_features</span> <span class="o">=</span> <span class="n">PhiMMUtils</span><span class="o">.</span><span class="n">add_image_newline</span><span class="p">(</span>
            <span class="n">sub_image_features</span><span class="p">,</span> <span class="n">sub_GN</span><span class="p">)</span>

        <span class="n">image_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">sub_image_features</span><span class="p">,</span>
             <span class="n">glb_GN</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">glb_image_features</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">image_features</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reshape_audio_chunks</span><span class="p">(</span><span class="n">audio_features</span><span class="p">,</span> <span class="n">chunk_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">audio_features</span> <span class="o">=</span> <span class="n">audio_features</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">chunk_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># only the last chunk may include paddings</span>
            <span class="n">n_tokens</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">chunk_mask</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mi">8</span><span class="p">)</span>
            <span class="n">audio_features</span> <span class="o">=</span> <span class="n">audio_features</span><span class="p">[:</span><span class="n">n_tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">audio_features</span>


<div class="viewcode-block" id="MultimodalModelRunner">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MultimodalModelRunner</span><span class="p">:</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_trtllm_vision_engine</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">runtime_rank</span> <span class="o">=</span> <span class="n">mpi_rank</span><span class="p">()</span>
        <span class="n">device_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_rank</span> <span class="o">%</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">device_id</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">device_id</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">())</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stream</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">enable_chunked_context</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">enable_chunked_context</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;mm_embedding_offloading requires enable_chunked_context to be True. Setting mm_embedding_offloading to None.&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># parse model type from visual engine config</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_engine_dir</span><span class="p">,</span> <span class="s2">&quot;config.json&quot;</span><span class="p">),</span>
                  <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;pretrained_config&#39;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;pretrained_config&#39;</span><span class="p">][</span>
                    <span class="s1">&#39;architecture&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;LlavaNextForConditionalGeneration&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;llava_next&#39;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;pretrained_config&#39;</span><span class="p">][</span><span class="s1">&#39;dtype&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_trtllm_vision_engine</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;Currently only Llava-NeXT supports TRT-LLM vision engines.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;builder_config&#39;</span><span class="p">][</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;builder_config&#39;</span><span class="p">][</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span> <span class="o">=</span> <span class="s1">&#39;float16&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span> <span class="o">=</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="s1">&#39;t5&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;nougat&#39;</span><span class="p">,</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">]</span>
        <span class="p">)</span>  <span class="c1"># BLIP2-T5, pix2struct and Nougat are using encoder-decoder models as LLMs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;video-neva&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;builder_config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_frames&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;llava_next&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">llm_name</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">)</span><span class="o">.</span><span class="n">text_config</span><span class="o">.</span><span class="n">_name_or_path</span>
        <span class="k">if</span> <span class="s1">&#39;internlm&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">lora_task_uids</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;qwen2_vl&quot;</span><span class="p">:</span>
            <span class="n">hf_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_start_token_id</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">vision_start_token_id</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_end_token_id</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">vision_end_token_id</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_token_id</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">vision_token_id</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_token_id</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">image_token_id</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">video_token_id</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">video_token_id</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spatial_merge_size</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">vision_config</span><span class="o">.</span><span class="n">spatial_merge_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">max_position_embeddings</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">hidden_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">num_attention_heads</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rope_theta</span> <span class="o">=</span> <span class="n">hf_config</span><span class="o">.</span><span class="n">rope_theta</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;llava_onevision&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_num_frames</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span> <span class="o">=</span> <span class="mi">8</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">image_path</span> <span class="ow">is</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">audio_input_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_output_names</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;mllama&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_input_names</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;pixel_values&quot;</span><span class="p">,</span>
                <span class="s2">&quot;aspect_ratio_ids&quot;</span><span class="p">,</span>
                <span class="s2">&quot;aspect_ratio_mask&quot;</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_output_names</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;encoder_output&quot;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;llava_next&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_trtllm_vision_engine</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_input_names</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;pixel_values&quot;</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_output_names</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;image_features&quot;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-4-multimodal&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">audio_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">audio_output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encoder_output&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encoder_output&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encoder_output&quot;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">session</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_e2e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visual_output_shape</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;builder_config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;output_shape&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">supports_inflight_batching</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_engine_dir</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;The given engine does not support in-flight batching, both visual engine and LLM fallback to python session&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="s1">&#39;python&#39;</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">PYTHON_BINDINGS</span> <span class="ow">and</span> <span class="s1">&#39;cpp&#39;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">session</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Python bindings of C++ session is unavailable, both visual engine and LLM fallback to Python session.&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="s1">&#39;python&#39;</span>

            <span class="n">args</span><span class="o">.</span><span class="n">debug_mode</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">debug_mode</span> <span class="ow">and</span> <span class="s1">&#39;cpp&#39;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">session</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Debug mode is not supported in C++ session for now, both visual engine and LLM fallback to Python session.&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="s1">&#39;python&#39;</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;qwen2_vl&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">session</span> <span class="o">!=</span> <span class="s2">&quot;cpp_llm_only&quot;</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;Qwen2-vl only support C++ session for now, fallback to C++ session.&quot;</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="s2">&quot;cpp_llm_only&quot;</span>

            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span>
                     <span class="p">(</span><span class="s1">&#39;llava&#39;</span><span class="p">,</span> <span class="s1">&#39;vila&#39;</span><span class="p">,</span> <span class="s1">&#39;blip2-opt&#39;</span><span class="p">,</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">,</span> <span class="s1">&#39;fuyu&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;cogvlm&#39;</span><span class="p">,</span> <span class="s1">&#39;neva&#39;</span><span class="p">,</span> <span class="s2">&quot;internvl&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;internlm&#39;</span>
                     <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">))</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">session</span> <span class="o">==</span> <span class="s1">&#39;cpp&#39;</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;C++ end-to-end mode does not support </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s1">. Visual engine fallbacks to Python session. See support matrix in README.&#39;</span>
                <span class="p">)</span>
                <span class="n">args</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="s1">&#39;cpp_llm_only&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">session</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="s1">&#39;cpp_llm_only&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_tokenizer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_processor</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_image_encoder</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_llm</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_input_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">audio_engine_dir</span><span class="p">,</span> <span class="s2">&quot;config.json&quot;</span><span class="p">),</span>
                      <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">audio_precision</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;builder_config&#39;</span><span class="p">][</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_audio_encoder</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">audio_encoder_session</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_precision</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">cpp_e2e</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">==</span> <span class="s1">&#39;cpp&#39;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">cpp_llm_only</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">==</span> <span class="s1">&#39;cpp_llm_only&#39;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">python_e2e</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">==</span> <span class="s1">&#39;python&#39;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">visual_engine_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">engine_dir</span><span class="p">,</span> <span class="s1">&#39;vision&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">audio_engine_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">engine_dir</span><span class="p">,</span> <span class="s1">&#39;audio&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">llm_engine_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">engine_dir</span><span class="p">,</span> <span class="s1">&#39;llm&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="MultimodalModelRunner.init_tokenizer">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.init_tokenizer">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;nougat&#39;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">NougatTokenizerFast</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">NougatTokenizerFast</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;neva&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;video-neva&#39;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">sentencepiece</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentencePieceProcessor</span>

            <span class="n">sp</span> <span class="o">=</span> <span class="n">SentencePieceProcessor</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">,</span> <span class="s1">&#39;tokenizer.model&#39;</span><span class="p">))</span>

            <span class="k">class</span><span class="w"> </span><span class="nc">return_obj</span><span class="p">:</span>

                <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span>

                <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span>
                        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;&#39;return_obj&#39; has no item &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>

            <span class="c1"># sentencepiece does not follow the same interface as HF</span>
            <span class="k">class</span><span class="w"> </span><span class="nc">HFTokenizerInterface</span><span class="p">():</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;pt&quot;</span><span class="p">:</span>
                        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">return_obj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

                <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">return_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">sp</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">batch_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">HFTokenizerInterface</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">eos_id</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">bos_token_id</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">bos_id</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">pad_id</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;vila&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span> <span class="o">+</span> <span class="s2">&quot;/llm&quot;</span><span class="p">,</span>
                <span class="n">use_fast</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">use_legacy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">use_fast</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s2">&quot;phi-3-vision&quot;</span><span class="p">,</span> <span class="s2">&quot;phi-4-multimodal&quot;</span><span class="p">,</span> <span class="s2">&quot;internvl&quot;</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">,</span>
                <span class="n">use_fast</span><span class="o">=</span><span class="n">use_fast</span><span class="p">,</span>
                <span class="n">use_legacy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.init_processor">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.init_processor">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_processor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>

        <span class="k">if</span> <span class="s1">&#39;blip2&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Blip2Processor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">Blip2Processor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s1">&#39;nougat&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">NougatProcessor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">NougatProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s1">&#39;cogvlm&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">image_size</span> <span class="o">=</span> <span class="mi">490</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">),</span>
                    <span class="n">interpolation</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">InterpolationMode</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.48145466</span><span class="p">,</span> <span class="mf">0.4578275</span><span class="p">,</span> <span class="mf">0.40821073</span><span class="p">),</span>
                                     <span class="p">(</span><span class="mf">0.26862954</span><span class="p">,</span> <span class="mf">0.26130258</span><span class="p">,</span> <span class="mf">0.27577711</span><span class="p">)),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ConvertImageDtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">),</span>
            <span class="p">])</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s1">&#39;phi-3-vision&#39;</span><span class="p">,</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">,</span> <span class="s1">&#39;llava_next&#39;</span><span class="p">,</span> <span class="s1">&#39;llava&#39;</span><span class="p">,</span> <span class="s1">&#39;fuyu&#39;</span><span class="p">,</span>
                <span class="s1">&#39;kosmos-2&#39;</span><span class="p">,</span> <span class="s1">&#39;mllama&#39;</span><span class="p">,</span> <span class="s1">&#39;llava_onevision&#39;</span><span class="p">,</span> <span class="s1">&#39;qwen2_vl&#39;</span><span class="p">,</span>
                <span class="s1">&#39;phi-4-multimodal&#39;</span>
        <span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_crops</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s1">&#39;internlm&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">image_size</span> <span class="o">=</span> <span class="mi">490</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">),</span>
                    <span class="n">interpolation</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">InterpolationMode</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.48145466</span><span class="p">,</span> <span class="mf">0.4578275</span><span class="p">,</span> <span class="mf">0.40821073</span><span class="p">),</span>
                                     <span class="p">(</span><span class="mf">0.26862954</span><span class="p">,</span> <span class="mf">0.26130258</span><span class="p">,</span> <span class="mf">0.27577711</span><span class="p">)),</span>
            <span class="p">])</span>

        <span class="k">elif</span> <span class="s1">&#39;internvl&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CLIPImageProcessor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">CLIPImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="s1">&#39;OpenGVLab/InternViT-300M-448px&#39;</span>
            <span class="p">)</span>  <span class="c1"># You can change the InternViT model type according to your InternVL type</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;neva&quot;</span><span class="p">:</span>
            <span class="n">image_size</span> <span class="o">=</span> <span class="mi">384</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">),</span>
                    <span class="n">interpolation</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">InterpolationMode</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ConvertImageDtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
            <span class="p">])</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;video-neva&quot;</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;vila&quot;</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span> <span class="o">+</span> <span class="s2">&quot;/../VILA&quot;</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">llava.mm_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_images</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">llava.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlavaLlamaConfig</span>  <span class="c1"># noqa</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">,</span>
                <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">vision_tower</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_vision_tower</span><span class="p">()</span>
            <span class="n">vision_tower</span><span class="o">.</span><span class="n">image_processor</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">processor</span><span class="p">(</span><span class="n">raw_image</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">process_images</span><span class="p">(</span><span class="n">raw_image</span><span class="p">,</span> <span class="n">vision_tower</span><span class="o">.</span><span class="n">image_processor</span><span class="p">,</span>
                                      <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                                                       <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">processor</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;mllama&#39;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">.processor_wrapper</span><span class="w"> </span><span class="kn">import</span> <span class="n">MllamaProcessorWrapper</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">MllamaProcessorWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span> <span class="n">logger</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.init_image_encoder">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.init_image_encoder">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_image_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># Phi-4-multimodal uses pytorch engine due to issues with creating TRT engine.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-4-multimodal&quot;</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">,</span>
                <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embed_tokens_extend</span><span class="o">.</span><span class="n">image_embed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="s1">&#39;sub_GN&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">img_projection</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">sub_GN</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="s1">&#39;glb_GN&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">img_projection</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">glb_GN</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-3-vision&quot;</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">,</span>
                <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vision_embed_tokens</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="c1"># Test run vision_model.get_img_features to pre-allocate memory for flash attention</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;&lt;|image_1|&gt;&quot;</span><span class="p">,</span>
                                   <span class="n">images</span><span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                               <span class="n">dtype</span><span class="o">=</span><span class="n">str_dtype_to_torch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">),</span>
                               <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">get_img_features</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_e2e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Using C++ runtime for both visual engine and LLM decoder, skip loading visual engine in Python runtime.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;llava_next&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_trtllm_vision_engine</span><span class="p">:</span>
            <span class="n">cudart</span><span class="o">.</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">runtime_rank</span> <span class="o">%</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">())</span>

            <span class="n">vision_encoder_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">visual_engine_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;rank</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">runtime_rank</span><span class="si">}</span><span class="s2">.engine&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loading engine from </span><span class="si">{</span><span class="n">vision_encoder_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vision_encoder_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">engine_buffer</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Creating session from engine </span><span class="si">{</span><span class="n">vision_encoder_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">engine_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">visual_encoder_session</span> <span class="o">=</span> <span class="n">Session</span><span class="o">.</span><span class="n">from_serialized_engine</span><span class="p">(</span>
                <span class="n">engine_buffer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vision_encoder_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_engine_dir</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">visual_engine_name</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loading engine from </span><span class="si">{</span><span class="n">vision_encoder_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vision_encoder_path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">engine_buffer</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Creating session from engine </span><span class="si">{</span><span class="n">vision_encoder_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visual_encoder_session</span> <span class="o">=</span> <span class="n">Session</span><span class="o">.</span><span class="n">from_serialized_engine</span><span class="p">(</span>
                <span class="n">engine_buffer</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;llava_next&quot;</span><span class="p">,</span> <span class="s2">&quot;llava_onevision&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">image_newlines_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_engine_dir</span><span class="p">,</span>
                                               <span class="s1">&#39;image_newlines.safetensors&#39;</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">safe_open</span><span class="p">(</span><span class="n">image_newlines_path</span><span class="p">,</span>
                           <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                           <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">k</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.init_audio_encoder">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.init_audio_encoder">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_audio_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-4-multimodal&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">,</span>
                                                     <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
                                                     <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                     <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">audio_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embed_tokens_extend</span><span class="o">.</span><span class="n">audio_embed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.init_llm">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.init_llm">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_llm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span><span class="p">:</span>
            <span class="n">cross_kv_cache_fraction</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;mllama&#39;</span><span class="p">:</span>
                <span class="n">cross_kv_cache_fraction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">cross_kv_cache_fraction</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_e2e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Running LLM with Python runner&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelRunner</span><span class="o">.</span><span class="n">from_dir</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">llm_engine_dir</span><span class="p">,</span>
                    <span class="n">rank</span><span class="o">=</span><span class="n">tensorrt_llm</span><span class="o">.</span><span class="n">mpi_rank</span><span class="p">(),</span>
                    <span class="n">debug_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">stream</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stream</span><span class="p">,</span>
                    <span class="n">enable_context_fmha_fp32_acc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span>
                    <span class="n">enable_context_fmha_fp32_acc</span><span class="p">,</span>
                    <span class="n">multi_block_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">multi_block_mode</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">_model_config</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_e2e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Running both visual engine and LLM with Python runner&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelRunnerCpp</span><span class="o">.</span><span class="n">from_dir</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">engine_dir</span><span class="p">,</span>
                    <span class="n">rank</span><span class="o">=</span><span class="n">tensorrt_llm</span><span class="o">.</span><span class="n">mpi_rank</span><span class="p">(),</span>
                    <span class="n">debug_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">is_enc_dec</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># TODO: add a separate model variant here?</span>
                    <span class="n">enable_context_fmha_fp32_acc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span>
                    <span class="n">enable_context_fmha_fp32_acc</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_config</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Running LLM with C++ runner&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelRunnerCpp</span><span class="o">.</span><span class="n">from_dir</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">llm_engine_dir</span><span class="p">,</span>
                    <span class="n">rank</span><span class="o">=</span><span class="n">tensorrt_llm</span><span class="o">.</span><span class="n">mpi_rank</span><span class="p">(),</span>
                    <span class="n">debug_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">enable_chunked_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">enable_chunked_context</span><span class="p">,</span>
                    <span class="n">enable_context_fmha_fp32_acc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span>
                    <span class="n">enable_context_fmha_fp32_acc</span><span class="p">,</span>
                    <span class="n">kv_cache_free_gpu_memory_fraction</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span>
                    <span class="n">kv_cache_free_gpu_memory_fraction</span><span class="p">,</span>
                    <span class="n">cross_kv_cache_fraction</span><span class="o">=</span><span class="n">cross_kv_cache_fraction</span><span class="p">,</span>
                    <span class="n">multi_block_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">multi_block_mode</span><span class="p">,</span>
                    <span class="n">mm_embedding_offloading</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_config</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mapping</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">EncDecModelRunner</span><span class="o">.</span><span class="n">from_engine</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">llm_engine_dir</span><span class="p">,</span>
                <span class="n">skip_encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;nougat&#39;</span><span class="p">,</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">],</span>
                <span class="n">debug_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">stream</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stream</span><span class="p">,</span>
                <span class="n">enable_context_fmha_fp32_acc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span>
                <span class="n">enable_context_fmha_fp32_acc</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;nougat&#39;</span><span class="p">,</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder_model_config</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder_runtime_mapping</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder_model_config</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder_runtime_mapping</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.video_preprocess">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.video_preprocess">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">video_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video_path</span><span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">decord</span><span class="w"> </span><span class="kn">import</span> <span class="n">VideoReader</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">vr</span> <span class="o">=</span> <span class="n">VideoReader</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
            <span class="n">num_frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span>
            <span class="k">if</span> <span class="n">num_frames</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">frames</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">frame</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">vr</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># equally sliced frames into self.num_frames frames</span>
                <span class="c1"># if self.num_frames is greater than the number of frames in the video, we will repeat the last frame</span>
                <span class="n">num_frames</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">num_frames</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vr</span><span class="p">))</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vr</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">num_frames</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
                <span class="n">frames</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span>
                        <span class="n">vr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span>
                <span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_frames</span><span class="p">:</span>
                    <span class="n">frames</span> <span class="o">+=</span> <span class="p">[</span><span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_frames</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_path</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CLIPImageProcessor</span>
        <span class="n">processor</span> <span class="o">=</span> <span class="n">CLIPImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="s2">&quot;openai/clip-vit-large-patch14&quot;</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span>
                                      <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
        <span class="c1"># make dtype consistent with vision encoder</span>
        <span class="n">media_tensors</span> <span class="o">=</span> <span class="n">frames</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">str_dtype_to_torch</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">))</span>  <span class="c1"># [num_frames, 3, H, W]</span>
        <span class="k">return</span> <span class="n">media_tensors</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1">#[1, num_frames, 3, H, W]</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.preprocess">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.preprocess">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre_prompt</span><span class="p">,</span> <span class="n">post_prompt</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">,</span>
                   <span class="n">other_audio_inputs</span><span class="p">):</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># same prompt for single/multiple image(s)</span>
        <span class="n">n_prompts_n_images</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">,</span>
                      <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;pixel_values&quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">)</span> <span class="o">==</span> <span class="n">image</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="n">n_prompts_n_images</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="c1"># n prompts and n images</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                        <span class="n">image</span><span class="p">,</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">)</span> <span class="o">==</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="n">n_prompts_n_images</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="c1"># n prompts and n images</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">image_mask</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="s2">&quot;image_embeds_position_mask&quot;</span><span class="p">]</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
            <span class="n">input_ids</span> <span class="o">+=</span> <span class="n">image_mask</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="o">*</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;phi-3-vision&#39;</span><span class="p">:</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">image</span>
            <span class="n">image</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;phi-4-multimodal&#39;</span><span class="p">:</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">image</span>
            <span class="n">image</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;input_image_embeds&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span>
                <span class="s1">&#39;image_attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>

            <span class="n">audio</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;input_audio_embeds&#39;</span><span class="p">]</span>
            <span class="n">l</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">audio</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">audio</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="mi">4000</span> <span class="o">-</span> <span class="n">l</span> <span class="o">%</span> <span class="mi">4000</span>
            <span class="n">audio</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">audio</span><span class="p">,</span> <span class="n">audio</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">d</span><span class="p">)],</span>
                              <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
            <span class="n">audio_mask</span> <span class="o">=</span> <span class="n">audio</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="o">*</span><span class="n">audio</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">audio_mask</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="n">pad</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">other_audio_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">audio_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;llava_next&#39;</span><span class="p">:</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">image</span>
            <span class="n">image</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">image_size</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;image_sizes&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;qwen2_vl&quot;</span><span class="p">:</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">image</span>
            <span class="n">image</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span>
            <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;image_grid_thw&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask_llm&#39;</span><span class="p">]</span>
            <span class="n">other_vision_inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;attention_mask_llm&#39;</span><span class="p">)</span>
            <span class="n">image_grid_thw</span> <span class="o">=</span> <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;image_grid_thw&#39;</span><span class="p">]</span>
            <span class="n">other_vision_inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;image_grid_thw&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;llava_onevision&#39;</span><span class="p">:</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">image</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">image_size</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;image_sizes&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s1">&#39;pixel_values_videos&#39;</span><span class="p">]</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;fuyu&quot;</span><span class="p">:</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="s2">&quot;image_patches&quot;</span><span class="p">])</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
                <span class="n">image</span><span class="p">[</span><span class="s2">&quot;image_patches&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="s2">&quot;image_patches&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;Vision encoder&quot;</span><span class="p">)</span>
        <span class="n">visual_features</span><span class="p">,</span> <span class="n">visual_atts</span><span class="p">,</span> <span class="n">model_runner_input</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_runner_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="n">image</span><span class="p">[</span><span class="s1">&#39;image_patches&#39;</span><span class="p">],</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;fuyu&#39;</span> <span class="k">else</span> <span class="n">image</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-3-vision&quot;</span><span class="p">:</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">get_img_features</span><span class="p">(</span>
                    <span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">image_dim_out</span><span class="p">)</span>
                <span class="n">visual_atts</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-4-multimodal&quot;</span><span class="p">:</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">get_img_features</span><span class="p">(</span>
                    <span class="n">model_runner_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                        <span class="n">str_dtype_to_torch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">)),</span>
                    <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">img_projection</span><span class="p">(</span>
                    <span class="n">visual_features</span><span class="p">)</span>
                <span class="n">visual_atts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">visual_features</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                         <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                             <span class="n">model_runner_input</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_e2e</span><span class="p">:</span>
                    <span class="c1"># If using E2E C++ runtime, visual_features will not be computed here in Python runtime.</span>
                    <span class="c1"># Instead, it only contains a shape read from the engine config, and is used for generating</span>
                    <span class="c1"># decoder prompt later</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s1">&#39;Skip running visual engine, get visual output shape from engine config.&#39;</span>
                    <span class="p">)</span>
                    <span class="n">model_runner_input</span> <span class="o">=</span> <span class="n">model_runner_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                        <span class="n">str_dtype_to_torch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">))</span>
                    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">model_runner_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">output_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_output_shape</span><span class="p">)</span>
                    <span class="n">output_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_size</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;fuyu&#39;</span><span class="p">:</span>
                        <span class="n">output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_runner_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                            <span class="mi">2</span><span class="p">]</span>  <span class="c1"># fuyu&#39;s output patch number is not fixed, same as input patch number</span>
                    <span class="n">visual_features</span> <span class="o">=</span> <span class="n">TensorInfo</span><span class="p">(</span>
                        <span class="s1">&#39;encoder_output&#39;</span><span class="p">,</span>
                        <span class="n">str_dtype_to_trt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">),</span>
                        <span class="nb">tuple</span><span class="p">(</span><span class="n">output_shape</span><span class="p">))</span>
                    <span class="n">atts_shape</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">visual_atts</span> <span class="o">=</span> <span class="n">TensorInfo</span><span class="p">(</span><span class="s1">&#39;image_atts&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
                                             <span class="nb">tuple</span><span class="p">(</span><span class="n">atts_shape</span><span class="p">))</span>
                    <span class="n">model_runner_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vsplit</span><span class="p">(</span>
                        <span class="n">model_runner_input</span><span class="p">,</span> <span class="n">model_runner_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">visual_features</span><span class="p">,</span> <span class="n">visual_atts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_visual_features</span><span class="p">(</span>
                        <span class="n">model_runner_input</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">)</span>
                    <span class="n">model_runner_input</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Vision encoder&quot;</span><span class="p">)</span>

        <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;Audio encoder&quot;</span><span class="p">)</span>
        <span class="n">audio_features</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">audio</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">audio_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_audio_features</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">other_audio_inputs</span><span class="p">)</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Audio encoder&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;fuyu&#39;</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">image_patches_indices</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="s1">&#39;image_patches_indices&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="o">*</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="n">image_patches_indices</span> <span class="o">=</span> <span class="n">image_patches_indices</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">image_patches_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>

            <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ptuning_setup_fuyu</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span>
                                                <span class="n">image_patches_indices</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_e2e</span><span class="p">:</span>  <span class="c1"># TODO: bs &gt; 1 for C++ E2E Fuyu</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;qwen2_vl&#39;</span><span class="p">:</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">([</span><span class="n">length</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">input_ids</span><span class="p">,</span> <span class="n">ptuning_args</span><span class="p">,</span> <span class="n">mrope_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_fake_prompts_qwen2vl</span><span class="p">(</span>
                <span class="n">visual_features</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">image_grid_thw</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">input_lengths</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">ptuning_args</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">mrope_args</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">:</span>
            <span class="n">visual_features</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
            <span class="p">)</span> <span class="k">if</span> <span class="n">visual_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;vila&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">n_prompts_n_images</span><span class="p">:</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_image_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                                       <span class="n">pre_prompt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                       <span class="n">post_prompt</span><span class="p">,</span>
                                                       <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_image_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                                       <span class="n">pre_prompt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                       <span class="n">post_prompt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                       <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
            <span class="n">batch_split_prompts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_prompt_by_images</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">n_prompts_n_images</span><span class="p">:</span>
                <span class="n">first_batch_split_prompts</span> <span class="o">=</span> <span class="n">batch_split_prompts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># compute prompt length + visual length</span>
                <span class="n">length</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">first_batch_split_prompts</span><span class="p">])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># mode 1: multiple image as a whole, flatten visual dims</span>
                    <span class="n">length</span> <span class="o">+=</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">length</span> <span class="o">+=</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">length</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                <span class="n">input_ids</span><span class="p">,</span> <span class="n">ptuning_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_fake_prompts_vila</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span>
                    <span class="n">first_batch_split_prompts</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># mode 2: multiple different prompts corresponding to multiple images (1-1 correspondence)</span>
                <span class="n">length</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="nb">sum</span><span class="p">([</span><span class="n">ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">batch_split_prompt</span><span class="p">])</span>
                    <span class="k">for</span> <span class="n">batch_split_prompt</span> <span class="ow">in</span> <span class="n">batch_split_prompts</span>
                <span class="p">]</span>
                <span class="n">length</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">length</span><span class="p">]</span>
                <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">(</span><span class="n">length</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                <span class="n">input_ids</span><span class="p">,</span> <span class="n">ptuning_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_fake_prompts_vila</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">batch_split_prompts</span><span class="p">,</span>
                    <span class="n">input_lengths</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">ptuning_args</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">model_runner_input</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;phi-3-vision&#39;</span><span class="p">:</span>
            <span class="n">image_sizes</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;image_sizes&quot;</span><span class="p">]</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;Feature transform&quot;</span><span class="p">)</span>
            <span class="n">visual_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">hd_feature_transform</span><span class="p">(</span>
                <span class="n">visual_features</span><span class="p">,</span> <span class="n">image_sizes</span><span class="p">)</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Feature transform&quot;</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="o">*</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="n">num_img_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ptuning_setup_phi3</span><span class="p">(</span><span class="n">visual_features</span><span class="o">=</span><span class="n">visual_features</span><span class="p">,</span>
                                                <span class="n">audio_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                                                <span class="n">num_img_tokens</span><span class="o">=</span><span class="n">num_img_tokens</span><span class="p">,</span>
                                                <span class="n">num_aud_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">visual_features</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;phi-4-multimodal&#39;</span><span class="p">:</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;image_sizes&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">image_attention_mask</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;image_attention_mask&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">image_attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">image_attention_mask</span> <span class="o">=</span> <span class="n">image_attention_mask</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            <span class="n">patch_size</span> <span class="o">=</span> <span class="mi">336</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;phi-3-vision&#39;</span> <span class="k">else</span> <span class="mi">448</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;Feature transform&quot;</span><span class="p">)</span>
            <span class="n">visual_features</span> <span class="o">=</span> <span class="n">PhiMMUtils</span><span class="o">.</span><span class="n">hd_feature_transform</span><span class="p">(</span>
                <span class="n">visual_features</span><span class="p">,</span>
                <span class="n">h</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">,</span>
                <span class="n">w</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="s2">&quot;sub_GN&quot;</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="s2">&quot;glb_GN&quot;</span><span class="p">],</span>
                <span class="n">patch_mask</span><span class="o">=</span><span class="n">image_attention_mask</span><span class="p">)</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Feature transform&quot;</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="o">*</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="n">num_img_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">if</span> <span class="n">audio_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dim</span> <span class="o">=</span> <span class="n">audio_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="n">audio_features</span> <span class="o">=</span> <span class="n">audio_features</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">dim</span><span class="p">:]</span>
                <span class="n">audio_features</span> <span class="o">=</span> <span class="n">PhiMMUtils</span><span class="o">.</span><span class="n">reshape_audio_chunks</span><span class="p">(</span>
                    <span class="n">audio_features</span><span class="p">,</span> <span class="n">other_audio_inputs</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span>
                <span class="n">num_aud_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">audio_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">num_aud_tokens</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ptuning_setup_phi3</span><span class="p">(</span><span class="n">visual_features</span><span class="o">=</span><span class="n">visual_features</span><span class="p">,</span>
                                                <span class="n">audio_features</span><span class="o">=</span><span class="n">audio_features</span><span class="p">,</span>
                                                <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                                                <span class="n">num_img_tokens</span><span class="o">=</span><span class="n">num_img_tokens</span><span class="p">,</span>
                                                <span class="n">num_aud_tokens</span><span class="o">=</span><span class="n">num_aud_tokens</span><span class="p">)</span>
            <span class="n">visual_features</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">audio_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">audio_features</span> <span class="o">=</span> <span class="n">audio_features</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;llava_next&#39;</span><span class="p">:</span>
            <span class="n">visual_features</span> <span class="o">=</span> <span class="n">LlavaNextUtils</span><span class="o">.</span><span class="n">rearrange_image_features</span><span class="p">(</span>
                <span class="n">visual_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="s2">&quot;image_newline&quot;</span><span class="p">],</span>
                <span class="n">image_size</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ptuning_setup_llava_next</span><span class="p">(</span><span class="n">visual_features</span><span class="p">,</span>
                                                      <span class="n">pre_prompt</span><span class="p">,</span> <span class="n">post_prompt</span><span class="p">)</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;mllama&#39;</span><span class="p">:</span>
            <span class="n">pre_input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">pre_prompt</span><span class="p">,</span>
                                           <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                                           <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
            <span class="k">if</span> <span class="n">n_prompts_n_images</span><span class="p">:</span>
                <span class="n">length</span> <span class="o">=</span> <span class="p">[</span><span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">length</span> <span class="o">=</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">post_input_ids</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;llava_onevision&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">visual_features</span><span class="p">,</span>
                                              <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                              <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="n">LlavaOnevisionUtils</span><span class="o">.</span><span class="n">pack_image_features</span><span class="p">(</span>
                    <span class="n">visual_features</span><span class="p">,</span>
                    <span class="n">image_size</span><span class="p">,</span>
                    <span class="n">image_newline</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="s2">&quot;image_newline&quot;</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="n">LlavaOnevisionUtils</span><span class="o">.</span><span class="n">apply_pooling</span><span class="p">(</span>
                    <span class="n">visual_features</span><span class="p">)</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span> <span class="o">*</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">image_newline</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_newlines</span><span class="p">[</span><span class="s2">&quot;image_newline&quot;</span><span class="p">][</span>
                    <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                                          <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">visual_features</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">visual_features</span><span class="p">,</span> <span class="n">image_newline</span><span class="p">),</span>
                                            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">pre_input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">pre_prompt</span><span class="p">,</span>
                                           <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                                           <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
            <span class="n">post_input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">,</span>
                                            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                                            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">post_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pre_input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">pre_prompt</span><span class="p">,</span>
                                           <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                                           <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
            <span class="k">if</span> <span class="n">post_prompt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">post_input_encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">,</span>
                                                    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                                                    <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">post_input_ids</span> <span class="o">=</span> <span class="n">post_input_encoded</span><span class="o">.</span><span class="n">input_ids</span>
                <span class="k">if</span> <span class="n">n_prompts_n_images</span> <span class="ow">and</span> <span class="s1">&#39;neva&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
                    <span class="n">post_input_attention_mask</span> <span class="o">=</span> <span class="n">post_input_encoded</span><span class="o">.</span><span class="n">attention_mask</span>
                    <span class="n">post_input_ids</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">input_id</span><span class="p">[</span><span class="n">mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()]</span> <span class="k">for</span> <span class="n">input_id</span><span class="p">,</span> <span class="n">mask</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                            <span class="n">post_input_ids</span><span class="p">,</span> <span class="n">post_input_attention_mask</span><span class="p">)</span>
                    <span class="p">]</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;video-neva&#39;</span><span class="p">:</span>
                    <span class="n">length</span> <span class="o">=</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">post_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                        <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;internvl&#39;</span><span class="p">:</span>
                    <span class="n">length</span> <span class="o">=</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">post_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                        <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">n_prompts_n_images</span><span class="p">:</span>
                        <span class="n">length</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
                            <span class="n">post_input_id</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">post_input_id</span> <span class="ow">in</span> <span class="n">post_input_ids</span>
                        <span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">length</span> <span class="o">=</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">post_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                            <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">post_input_ids</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">assert</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">length</span> <span class="o">=</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">length</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">visual_atts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="p">]</span>

        <span class="k">if</span> <span class="n">n_prompts_n_images</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span> <span class="n">length</span> <span class="o">=</span> <span class="p">[</span><span class="n">length</span><span class="p">]</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
            <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">(</span><span class="n">length</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
            <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">([</span><span class="n">length</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s1">&#39;fuyu&#39;</span><span class="p">,</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">,</span> <span class="s1">&#39;phi-3-vision&#39;</span><span class="p">,</span> <span class="s1">&#39;llava_next&#39;</span>
        <span class="p">]:</span>
            <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="p">[</span>
                <span class="n">visual_features</span>
            <span class="p">],</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">model_runner_input</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;phi-4-multimodal&#39;</span><span class="p">:</span>
            <span class="n">multimodal_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">visual_features</span><span class="p">,</span> <span class="n">audio_features</span><span class="p">],</span>
                                            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="p">[</span>
                <span class="n">multimodal_features</span>
            <span class="p">],</span> <span class="n">multimodal_features</span><span class="p">,</span> <span class="n">model_runner_input</span>

        <span class="n">input_ids</span><span class="p">,</span> <span class="n">ptuning_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_fake_prompts</span><span class="p">(</span>
            <span class="n">visual_features</span><span class="p">,</span> <span class="n">pre_input_ids</span><span class="p">,</span> <span class="n">post_input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">ptuning_args</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">model_runner_input</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.tokenizer_image_token">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.tokenizer_image_token">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">tokenizer_image_token</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span>
                              <span class="n">pre_prompt</span><span class="p">,</span>
                              <span class="n">post_prompt</span><span class="p">,</span>
                              <span class="n">tokenizer</span><span class="p">,</span>
                              <span class="n">image_token_index</span><span class="o">=-</span><span class="mi">200</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">post_prompt</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">post_prompt</span><span class="p">]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">insert_separator</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sep</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="n">ele</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">[</span><span class="n">sep</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span> <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">sublist</span>
            <span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">prompts</span><span class="p">:</span>
            <span class="n">prompt_chunks</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">tokenizer</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">prompt</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;image&gt;&quot;</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt_chunks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt_chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span>
                    <span class="ow">and</span> <span class="n">prompt_chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">):</span>
                <span class="n">offset</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt_chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">insert_separator</span><span class="p">(</span><span class="n">prompt_chunks</span><span class="p">,</span>
                                      <span class="p">[</span><span class="n">image_token_index</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">offset</span><span class="p">:])</span>

            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
            <span class="n">input_ids</span><span class="p">[</span><span class="n">input_ids</span> <span class="o">==</span> <span class="n">image_token_index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">post_prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.split_prompt_by_images">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.split_prompt_by_images">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">split_prompt_by_images</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="n">batch_splits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tensor</span><span class="p">:</span>
            <span class="c1"># Find indices where value is zero (&lt;image&gt;)</span>
            <span class="n">zero_indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># Add starting point for slicing</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">zero_indices</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">start_idx</span> <span class="o">!=</span> <span class="n">idx</span><span class="p">:</span>  <span class="c1"># Ensure not slicing zero-length tensors</span>
                    <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
                <span class="n">start_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Move start index past the zero</span>
            <span class="k">if</span> <span class="n">start_idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="n">batch</span><span class="p">):</span>  <span class="c1"># Handle last segment if it&#39;s not zero-ending</span>
                <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
            <span class="c1"># Remove empty tensors resulting from consecutive zeros</span>
            <span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="n">split</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">splits</span> <span class="k">if</span> <span class="n">split</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">batch_splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">batch_splits</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.prepare_position_ids_for_cogvlm">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.prepare_position_ids_for_cogvlm">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_position_ids_for_cogvlm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">position_ids</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">1227</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">position_ids</span><span class="p">[</span><span class="mi">1227</span><span class="p">:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1225</span><span class="p">)</span>

        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
        <span class="n">input_position_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">input_position_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_position_ids</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.generate">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.generate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">pre_prompt</span><span class="p">,</span>
                 <span class="n">post_prompt</span><span class="p">,</span>
                 <span class="n">image</span><span class="p">,</span>
                 <span class="n">decoder_input_ids</span><span class="p">,</span>
                 <span class="n">max_new_tokens</span><span class="p">,</span>
                 <span class="n">other_vision_inputs</span><span class="o">=</span><span class="p">{},</span>
                 <span class="n">other_audio_inputs</span><span class="o">=</span><span class="p">{},</span>
                 <span class="n">other_decoder_inputs</span><span class="o">=</span><span class="p">{}):</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;Generate&quot;</span><span class="p">)</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;Preprocess&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;qwen2_vl&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">ptuning_args</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">mrope_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span>
                <span class="n">pre_prompt</span><span class="p">,</span> <span class="n">post_prompt</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">,</span>
                <span class="n">other_audio_inputs</span><span class="p">)</span>
            <span class="n">mrope_params</span> <span class="o">=</span> <span class="n">MropeParams</span><span class="p">(</span>
                <span class="n">mrope_rotary_cos_sin</span><span class="o">=</span><span class="n">mrope_args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">mrope_position_deltas</span><span class="o">=</span><span class="n">mrope_args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">ptuning_args</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">model_runner_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span>
                <span class="n">pre_prompt</span><span class="p">,</span> <span class="n">post_prompt</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">,</span>
                <span class="n">other_audio_inputs</span><span class="p">)</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Preprocess&quot;</span><span class="p">)</span>

        <span class="c1"># use prompt tuning to pass multimodal features</span>
        <span class="c1"># model.generate() expects the following params (see layers/embedding.py):</span>
        <span class="c1"># args[0]: prompt embedding table, [batch_size, multimodal_len, hidden_size], later flattened to [batch_size * multimodal_len, hidden_size]</span>
        <span class="c1"># args[1]: prompt task ids, [batch_size]. in multimodal case, arange(batch_size), i.e. in VILA batching mode 2, each image is treated separately in the batch instead of concated together (although the prompt embedding table has to be concated)</span>
        <span class="c1"># args[2]: prompt task vocab size, [1]. assuming all table has the same length, which in multimodal case equals to multimodal_len</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;LLM&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">!=</span> <span class="s2">&quot;mllama&quot;</span><span class="p">:</span>
            <span class="n">end_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">if</span> <span class="s1">&#39;opt&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">and</span> <span class="s1">&#39;blip2&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
                <span class="c1"># For BLIP2-OPT, model outputs a &quot;\n&quot; at the end.</span>
                <span class="c1"># we avoid it by using newline as the end token</span>
                <span class="n">end_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                                               <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;cogvlm&#39;</span><span class="p">:</span>
                <span class="n">input_position_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_position_ids_for_cogvlm</span><span class="p">(</span>
                    <span class="n">input_ids</span><span class="p">)</span>

            <span class="n">prompt_tasks</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">prompt_table</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_e2e</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
                <span class="n">prompt_tasks</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>
                <span class="n">prompt_table</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">ptuning_args</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
                <span class="n">prompt_table</span> <span class="o">=</span> <span class="n">prompt_table</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                                 <span class="n">prompt_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

            <span class="n">output_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">input_ids</span><span class="p">,</span>
                <span class="n">input_position_ids</span><span class="o">=</span><span class="n">input_position_ids</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;cogvlm&#39;</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">mrope_params</span><span class="o">=</span><span class="n">mrope_params</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;qwen2_vl&#39;</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">encoder_input_features</span><span class="o">=</span><span class="n">model_runner_input</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_e2e</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">sampling_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">prompt_table</span><span class="o">=</span><span class="n">prompt_table</span><span class="p">,</span>
                <span class="n">prompt_tasks</span><span class="o">=</span><span class="n">prompt_tasks</span><span class="p">,</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
                <span class="n">end_id</span><span class="o">=</span><span class="n">end_id</span><span class="p">,</span>
                <span class="n">pad_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">all_special_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">top_k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">top_k</span><span class="p">,</span>
                <span class="n">top_p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">top_p</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">repetition_penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">repetition_penalty</span><span class="p">,</span>
                <span class="n">num_beams</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_beams</span><span class="p">,</span>
                <span class="n">lora_uids</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">lora_task_uids</span><span class="p">,</span>
                <span class="n">output_sequence_lengths</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">mm_embedding_offloading</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;mllama&quot;</span><span class="p">:</span>
            <span class="c1"># When image is passed:</span>
            <span class="c1"># the shape of visual_features is [bs, 1, 4, 1025, hidden_size]</span>
            <span class="c1"># the shape of cross_attention_mask is [bs, decode_input_len, 1, 4]</span>
            <span class="c1"># When image is None, create dummy visual_features and cross_attention_mask</span>
            <span class="k">if</span> <span class="n">visual_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">visual_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span><span class="o">.</span><span class="n">tp_size</span>
                <span class="p">],</span>
                                              <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                              <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">dummy_cross_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">skip_cross_attn_blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span>
                                                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                                                    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">skip_cross_attn_blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span>
                                                     <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                                                     <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

            <span class="n">visual_features</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">encoder_input_features</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">cross_attention_masks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">encoder_output_lengths</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">visual_feature</span> <span class="o">=</span> <span class="n">visual_features</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span>
                <span class="n">num_vision_tokens</span> <span class="o">=</span> <span class="n">visual_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
                <span class="n">visual_feature</span> <span class="o">=</span> <span class="n">visual_feature</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">visual_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
                <span class="n">encoder_max_input_length</span> <span class="o">=</span> <span class="n">visual_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">encoder_input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">encoder_max_input_length</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">visual_feature</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># prepare cross_attention_mask of context phase</span>
                <span class="k">if</span> <span class="s1">&#39;cross_attention_mask&#39;</span> <span class="ow">in</span> <span class="n">other_decoder_inputs</span><span class="p">:</span>
                    <span class="n">cross_attention_mask</span> <span class="o">=</span> <span class="n">other_decoder_inputs</span><span class="p">[</span>
                        <span class="s1">&#39;cross_attention_mask&#39;</span><span class="p">][</span><span class="n">batch_idx</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">cross_attention_mask</span> <span class="o">=</span> <span class="n">dummy_cross_attention_mask</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span>
                <span class="n">text_total_length</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">cross_attention_mask</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">cross_attention_mask</span> <span class="o">=</span> <span class="n">cross_attention_mask</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
                    <span class="n">num_vision_tokens</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">cross_attention_mask</span> <span class="o">=</span> <span class="n">cross_attention_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                    <span class="n">text_total_length</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">cross_attention_mask</span> <span class="o">=</span> <span class="n">cross_attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">cross_attention_mask</span> <span class="o">=</span> <span class="n">cross_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="n">visual_feature</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                        <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cross_attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

                <span class="c1"># prepare cross_attention_mask for generation phase and concat them</span>
                <span class="n">tmp_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">cross_attention_mask</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
                    <span class="n">cross_attention_mask</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">)</span>
                <span class="p">]</span>
                <span class="n">cross_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">tmp_mask</span><span class="p">)</span>

                <span class="n">encoder_input_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">visual_feature</span><span class="p">)</span>
                <span class="n">cross_attention_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cross_attention_mask</span><span class="p">)</span>
                <span class="n">encoder_output_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoder_input_lengths</span><span class="p">)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">batch_input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                <span class="n">encoder_input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">encoder_input_features</span><span class="o">=</span><span class="n">encoder_input_features</span><span class="p">,</span>
                <span class="n">encoder_output_lengths</span><span class="o">=</span><span class="n">encoder_output_lengths</span><span class="p">,</span>
                <span class="n">cross_attention_masks</span><span class="o">=</span><span class="n">cross_attention_masks</span><span class="p">,</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
                <span class="c1"># max_attention_window_size=args.max_attention_window_size,</span>
                <span class="c1"># sink_token_length=args.sink_token_length,</span>
                <span class="n">end_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="n">pad_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">top_k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">top_k</span><span class="p">,</span>
                <span class="n">top_p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">top_p</span><span class="p">,</span>
                <span class="n">num_beams</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_beams</span><span class="p">,</span>
                <span class="c1"># length_penalty=args.length_penalty,</span>
                <span class="c1"># early_stopping=args.early_stopping,</span>
                <span class="c1"># beam_width_array=args.beam_width_array,</span>
                <span class="n">repetition_penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">repetition_penalty</span><span class="p">,</span>
                <span class="c1"># presence_penalty=args.presence_penalty,</span>
                <span class="c1"># frequency_penalty=args.frequency_penalty,</span>
                <span class="c1"># stop_words_list=stop_words_list,</span>
                <span class="c1"># bad_words_list=bad_words_list,</span>
                <span class="c1"># output_cum_log_probs=(args.output_cum_log_probs_npy != None),</span>
                <span class="c1"># output_log_probs=(args.output_log_probs_npy != None),</span>
                <span class="c1"># random_seed=args.random_seed,</span>
                <span class="c1"># lora_uids=args.lora_task_uids,</span>
                <span class="c1"># prompt_table=args.prompt_table_path,</span>
                <span class="c1"># prompt_tasks=args.prompt_tasks,</span>
                <span class="c1"># streaming=args.streaming,</span>
                <span class="n">output_sequence_lengths</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="c1"># no_repeat_ngram_size=self.args.no_repeat_ngram_size,</span>
                <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="c1"># medusa_choices=args.medusa_choices,</span>
                <span class="c1"># return_all_generated_tokens=args.return_all_generated_tokens,</span>
                <span class="c1"># input_token_extra_ids=input_token_extra_ids,</span>
                <span class="n">encoder_max_input_length</span><span class="o">=</span><span class="n">encoder_max_input_length</span><span class="p">,</span>
                <span class="n">skip_cross_attn_blocks</span><span class="o">=</span><span class="n">skip_cross_attn_blocks</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">mpi_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">output_ids</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;output_ids&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;nougat&#39;</span><span class="p">,</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">]:</span>
                <span class="c1"># Trim encoder input_ids to match visual features shape</span>
                <span class="n">ids_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;nougat&#39;</span><span class="p">:</span>
                    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ids_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">:</span>
                    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">ids_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

            <span class="n">output_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">input_ids</span><span class="p">,</span>
                <span class="n">decoder_input_ids</span><span class="p">,</span>
                <span class="n">max_new_tokens</span><span class="p">,</span>
                <span class="n">num_beams</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_beams</span><span class="p">,</span>
                <span class="n">bos_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">,</span>
                <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
                <span class="n">eos_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="n">debug_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">prompt_embedding_table</span><span class="o">=</span><span class="n">ptuning_args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">prompt_tasks</span><span class="o">=</span><span class="n">ptuning_args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">prompt_vocab_size</span><span class="o">=</span><span class="n">ptuning_args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

            <span class="c1"># Reset input_lengths to match decoder_input_ids</span>
            <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">input_lengths</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">input_lengths</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;LLM&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mpi_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Extract a list of tensors of shape beam_width x output_ids.</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;Tokenizer decode&quot;</span><span class="p">)</span>
            <span class="n">output_beams_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
                    <span class="n">output_ids</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="p">:,</span> <span class="n">input_lengths</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]:],</span>
                    <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
                        <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_lengths</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="p">]</span>

            <span class="n">stripped_text</span> <span class="o">=</span> <span class="p">[[</span>
                <span class="n">output_beams_list</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">][</span><span class="n">beam_idx</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">beam_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_beams</span><span class="p">)</span>
            <span class="p">]</span> <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
                <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_lengths</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))]</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Tokenizer decode&quot;</span><span class="p">)</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Generate&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">stripped_text</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s2">&quot;Generate&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.get_visual_features">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.get_visual_features">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_visual_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">):</span>
        <span class="n">visual_features</span> <span class="o">=</span> <span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">str_dtype_to_torch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">)),</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;qwen2_vl&quot;</span><span class="p">:</span>
            <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">other_vision_inputs</span><span class="p">[</span>
                <span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">str_dtype_to_torch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">other_vision_inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">visual_features</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="n">tensor</span><span class="p">})</span>

        <span class="n">tensor_info</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">TensorInfo</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                       <span class="n">str_dtype_to_trt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_precision</span><span class="p">),</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">other_vision_inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">tensor_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">TensorInfo</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">torch_dtype_to_trt</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="n">visual_output_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_encoder_session</span><span class="o">.</span><span class="n">infer_shapes</span><span class="p">(</span>
            <span class="n">tensor_info</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">visual_encoder_session</span><span class="o">.</span><span class="n">set_shapes</span><span class="p">(</span><span class="n">visual_features</span><span class="p">)</span>
        <span class="n">visual_outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">t</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">trt_dtype_to_torch</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">visual_output_info</span>
        <span class="p">}</span>

        <span class="n">ok</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_encoder_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">visual_features</span><span class="p">,</span> <span class="n">visual_outputs</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">stream</span><span class="o">.</span><span class="n">cuda_stream</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">ok</span><span class="p">,</span> <span class="s2">&quot;Runtime execution failed for vision encoder session&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stream</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>

        <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">visual_outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_output_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span><span class="p">:</span>
            <span class="c1"># CUDA Stream Overlapping Requirements:</span>
            <span class="c1"># 1. Both memory copy stream and kernel execution stream must be non-default streams</span>
            <span class="c1"># 2. For host&lt;-&gt;device transfers (H2D/D2H), host memory MUST be page-locked (pinned)</span>
            <span class="n">pinned_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span>
                                             <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span>
                                             <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">pinned_embeds</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">pinned_embeds</span>

        <span class="n">image_atts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">image_embeds</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image_embeds</span><span class="p">,</span> <span class="n">image_atts</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.get_audio_features">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.get_audio_features">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_audio_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">,</span> <span class="n">other_audio_inputs</span><span class="p">):</span>
        <span class="n">tmp_features</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span>
            <span class="n">audio</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">str_dtype_to_torch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">audio_precision</span><span class="p">)),</span>
            <span class="n">other_audio_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
        <span class="n">speech_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_model</span><span class="o">.</span><span class="n">audio_projection</span><span class="p">[</span><span class="s1">&#39;speech&#39;</span><span class="p">](</span><span class="n">tmp_features</span><span class="p">)</span>
        <span class="n">vision_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_model</span><span class="o">.</span><span class="n">audio_projection</span><span class="p">[</span><span class="s1">&#39;vision&#39;</span><span class="p">](</span><span class="n">tmp_features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">speech_out</span><span class="p">,</span> <span class="n">vision_out</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.setup_fake_prompts_vila">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.setup_fake_prompts_vila">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_fake_prompts_vila</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span>
                                <span class="n">split_input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">):</span>
        <span class="c1"># visual_features (num_images, feature_len, token_embed)</span>
        <span class="c1"># Assemble fake prompts which points to image embedding actually</span>
        <span class="n">fake_prompt_counter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># only check for multi-image inference (mode 1)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">visual_features</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">split_input_ids</span>
            <span class="p">),</span> <span class="s2">&quot;Unexpected number of visual features. Please check #&lt;image&gt; in prompt and the #image files.&quot;</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># mode 1: multiple image as a whole, concat all prompts together, &lt;pre&gt;&lt;image1&gt;&lt;inter&gt;&lt;image2&gt;...&lt;post&gt;</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">split_input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">visual_features</span><span class="p">)</span>
            <span class="p">):</span>  <span class="c1"># TODO:alternatively make TensorInfo iterable if this breaks others</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                    <span class="n">fake_prompt_counter</span><span class="p">,</span>
                    <span class="n">fake_prompt_counter</span> <span class="o">+</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">fake_prompt_counter</span> <span class="o">+=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">fake_prompt_id</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fake_prompt_id</span><span class="p">)</span>
                <span class="c1"># in case no inter or post prompt</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split_input_ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">split_input_ids</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># mode 2: each image have individual prompt, &lt;pre&gt;&lt;image&gt;&lt;post&gt;</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">visual_features</span><span class="p">)):</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">split_input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                    <span class="n">fake_prompt_counter</span><span class="p">,</span>
                    <span class="n">fake_prompt_counter</span> <span class="o">+</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">fake_prompt_id</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fake_prompt_id</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split_input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">split_input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">),</span> <span class="mi">3</span><span class="p">):</span>
                <span class="c1"># Concatenate every 3 items (&lt;pre&gt;, &lt;image&gt;, &lt;post&gt;)</span>
                <span class="n">concatenated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">3</span><span class="p">],</span>
                                         <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">concatenated</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">result</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span><span class="o">.</span><span class="n">is_first_pp_rank</span><span class="p">())</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="n">visual_features</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">ptuning_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ptuning_setup</span><span class="p">(</span><span class="n">visual_features</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span>
                                              <span class="n">input_lengths</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ptuning_args</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">ptuning_args</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.setup_fake_prompts">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.setup_fake_prompts">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_fake_prompts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">pre_input_ids</span><span class="p">,</span> <span class="n">post_input_ids</span><span class="p">,</span>
                           <span class="n">input_lengths</span><span class="p">):</span>
        <span class="c1"># Assemble fake prompts which points to image embedding actually</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;num_frames&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                                            <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">):</span>
            <span class="n">visual_features</span> <span class="o">=</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                                   <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">visual_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_e2e</span><span class="p">:</span>
                <span class="c1"># Non-IFB Mode(used in python session): All requests in a batch have their prompt_table concatenated in</span>
                <span class="c1"># a shape of (bs*vision_embedding_len, vision_hidden). So only one fake_prompt_id is needed for the</span>
                <span class="c1"># entire batch, with values from 0 to bs * vision_embedding_len-1.</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span>
                    <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">fake_prompt_id</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># IFB Mode(used in c++ session): Each request&#39;s prompt_table is independent and requires a fake_prompt_id</span>
                <span class="c1"># for each request, with values ranging from 0 to vision_embedding_len-1.</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">fake_prompt_id</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                       <span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="s1">&#39;internvl&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">fake_prompt_id</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="s1">&#39;cogvlm&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">pre_input_ids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">fake_prompt_id</span><span class="p">,</span> <span class="n">pre_input_ids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]],</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;mllama&#39;</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">pre_input_ids</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">post_input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">post_input_ids</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">pre_input_fake_prompt_ids</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">pre_input_ids</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">fake_prompt_id</span><span class="p">)],</span> <span class="n">fake_prompt_id</span>
                    <span class="p">]</span>
                    <span class="n">pre_input_fake_prompt_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                        <span class="n">pre_input_fake_prompt_ids</span><span class="p">,</span>
                        <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                    <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pre_input_fake_prompt_id</span><span class="p">,</span>
                                   <span class="n">post_input_id</span><span class="p">))</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">pre_input_fake_prompt_id</span><span class="p">,</span> <span class="n">post_input_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                            <span class="n">pre_input_fake_prompt_ids</span><span class="p">,</span> <span class="n">post_input_ids</span><span class="p">)</span>
                    <span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">pre_input_ids</span><span class="p">,</span> <span class="n">fake_prompt_id</span><span class="p">,</span> <span class="n">post_input_ids</span><span class="p">]</span>
                    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span>
                                          <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">fake_prompt_id</span><span class="p">,</span> <span class="n">pre_input_ids</span><span class="p">]</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span>
                                      <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span><span class="o">.</span><span class="n">is_first_pp_rank</span><span class="p">()</span>
            <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">!=</span> <span class="s2">&quot;mllama&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">visual_features</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">ptuning_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ptuning_setup</span><span class="p">(</span><span class="n">visual_features</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span>
                                              <span class="n">input_lengths</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ptuning_args</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">ptuning_args</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.get_rope_index">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.get_rope_index">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_rope_index</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span>
        <span class="n">image_grid_thw</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">video_grid_thw</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the 3D rope index based on image and video&#39;s temporal, height and width in LLM.</span>

<span class="sd">        Explanation:</span>
<span class="sd">            Each embedding sequence contains vision embedding and text embedding or just contains text embedding.</span>

<span class="sd">            For pure text embedding sequence, the rotary position embedding has no difference with modern LLMs.</span>
<span class="sd">            Examples:</span>
<span class="sd">                input_ids: [T T T T T], here T is for text.</span>
<span class="sd">                temporal position_ids: [0, 1, 2, 3, 4]</span>
<span class="sd">                height position_ids: [0, 1, 2, 3, 4]</span>
<span class="sd">                width position_ids: [0, 1, 2, 3, 4]</span>

<span class="sd">            For vision and text embedding sequence, we calculate 3D rotary position embedding for vision part</span>
<span class="sd">            and 1D rotary position embedding for text part.</span>
<span class="sd">            Examples:</span>
<span class="sd">                Assume we have a video input with 3 temporal patches, 2 height patches and 2 width patches.</span>
<span class="sd">                input_ids: [V V V V V V V V V V V V T T T T T], here V is for vision.</span>
<span class="sd">                vision temporal position_ids: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]</span>
<span class="sd">                vision height position_ids: [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]</span>
<span class="sd">                vision width position_ids: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]</span>
<span class="sd">                text temporal position_ids: [3, 4, 5, 6, 7]</span>
<span class="sd">                text height position_ids: [3, 4, 5, 6, 7]</span>
<span class="sd">                text width position_ids: [3, 4, 5, 6, 7]</span>
<span class="sd">                Here we calculate the text start position_ids as the max vision position_ids plus 1.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):</span>
<span class="sd">                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide</span>
<span class="sd">                it.</span>
<span class="sd">            image_grid_thw (`torch.LongTensor` of shape `(num_images, 3)`, *optional*):</span>
<span class="sd">                The temporal, height and width of feature shape of each image in LLM.</span>
<span class="sd">            video_grid_thw (`torch.LongTensor` of shape `(num_videos, 3)`, *optional*):</span>
<span class="sd">                The temporal, height and width of feature shape of each video in LLM.</span>
<span class="sd">            attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):</span>
<span class="sd">                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:</span>

<span class="sd">                - 1 for tokens that are **not masked**,</span>
<span class="sd">                - 0 for tokens that are **masked**.</span>

<span class="sd">        Returns:</span>
<span class="sd">            position_ids (`torch.LongTensor` of shape `(3, batch_size, sequence_length)`)</span>
<span class="sd">            mrope_position_deltas (`torch.Tensor` of shape `(batch_size)`)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spatial_merge_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_merge_size</span>
        <span class="n">image_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_token_id</span>
        <span class="n">video_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_token_id</span>
        <span class="n">vision_start_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_start_token_id</span>
        <span class="n">mrope_position_deltas</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">image_grid_thw</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">video_grid_thw</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">total_input_ids</span> <span class="o">=</span> <span class="n">input_ids</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span>
                                      <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                      <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                      <span class="n">dtype</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                      <span class="n">device</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">image_index</span><span class="p">,</span> <span class="n">video_index</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">input_ids</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">total_input_ids</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="n">attention_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">image_nums</span><span class="p">,</span> <span class="n">video_nums</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
                <span class="n">vision_start_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span>
                    <span class="n">input_ids</span> <span class="o">==</span> <span class="n">vision_start_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">vision_tokens</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="n">vision_start_indices</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">image_nums</span> <span class="o">=</span> <span class="p">(</span><span class="n">vision_tokens</span> <span class="o">==</span> <span class="n">image_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">video_nums</span> <span class="o">=</span> <span class="p">(</span><span class="n">vision_tokens</span> <span class="o">==</span> <span class="n">video_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="n">llm_pos_ids_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">st</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">remain_images</span><span class="p">,</span> <span class="n">remain_videos</span> <span class="o">=</span> <span class="n">image_nums</span><span class="p">,</span> <span class="n">video_nums</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image_nums</span> <span class="o">+</span> <span class="n">video_nums</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">image_token_id</span> <span class="ow">in</span> <span class="n">input_tokens</span> <span class="ow">and</span> <span class="n">remain_images</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">ed_image</span> <span class="o">=</span> <span class="n">input_tokens</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">image_token_id</span><span class="p">,</span> <span class="n">st</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">ed_image</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">video_token_id</span> <span class="ow">in</span> <span class="n">input_tokens</span> <span class="ow">and</span> <span class="n">remain_videos</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">ed_video</span> <span class="o">=</span> <span class="n">input_tokens</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">video_token_id</span><span class="p">,</span> <span class="n">st</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">ed_video</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">ed_image</span> <span class="o">&lt;</span> <span class="n">ed_video</span><span class="p">:</span>
                        <span class="n">t</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">image_grid_thw</span><span class="p">[</span><span class="n">image_index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">image_grid_thw</span><span class="p">[</span><span class="n">image_index</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                            <span class="n">image_grid_thw</span><span class="p">[</span><span class="n">image_index</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
                        <span class="p">)</span>
                        <span class="n">image_index</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">remain_images</span> <span class="o">-=</span> <span class="mi">1</span>
                        <span class="n">ed</span> <span class="o">=</span> <span class="n">ed_image</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">t</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">video_grid_thw</span><span class="p">[</span><span class="n">video_index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">video_grid_thw</span><span class="p">[</span><span class="n">video_index</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                            <span class="n">video_grid_thw</span><span class="p">[</span><span class="n">video_index</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
                        <span class="p">)</span>
                        <span class="n">video_index</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">remain_videos</span> <span class="o">-=</span> <span class="mi">1</span>
                        <span class="n">ed</span> <span class="o">=</span> <span class="n">ed_video</span>
                    <span class="n">llm_grid_t</span><span class="p">,</span> <span class="n">llm_grid_h</span><span class="p">,</span> <span class="n">llm_grid_w</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">t</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                        <span class="n">h</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">//</span> <span class="n">spatial_merge_size</span><span class="p">,</span>
                        <span class="n">w</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">//</span> <span class="n">spatial_merge_size</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">text_len</span> <span class="o">=</span> <span class="n">ed</span> <span class="o">-</span> <span class="n">st</span>

                    <span class="n">st_idx</span> <span class="o">=</span> <span class="n">llm_pos_ids_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="n">llm_pos_ids_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
                    <span class="n">llm_pos_ids_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">text_len</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">st_idx</span><span class="p">)</span>

                    <span class="n">t_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">llm_grid_t</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                        <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">llm_grid_h</span> <span class="o">*</span> <span class="n">llm_grid_w</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                    <span class="n">h_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">llm_grid_h</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                        <span class="n">llm_grid_t</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">llm_grid_w</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                    <span class="n">w_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">llm_grid_w</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                        <span class="n">llm_grid_t</span><span class="p">,</span> <span class="n">llm_grid_h</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                    <span class="n">llm_pos_ids_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">t_index</span><span class="p">,</span> <span class="n">h_index</span><span class="p">,</span> <span class="n">w_index</span><span class="p">])</span> <span class="o">+</span> <span class="n">text_len</span> <span class="o">+</span>
                        <span class="n">st_idx</span><span class="p">)</span>
                    <span class="n">st</span> <span class="o">=</span> <span class="n">ed</span> <span class="o">+</span> <span class="n">llm_grid_t</span> <span class="o">*</span> <span class="n">llm_grid_h</span> <span class="o">*</span> <span class="n">llm_grid_w</span>

                <span class="k">if</span> <span class="n">st</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">):</span>
                    <span class="n">st_idx</span> <span class="o">=</span> <span class="n">llm_pos_ids_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="n">llm_pos_ids_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
                    <span class="n">text_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span> <span class="o">-</span> <span class="n">st</span>
                    <span class="n">llm_pos_ids_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">text_len</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">st_idx</span><span class="p">)</span>

                <span class="n">llm_positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">llm_pos_ids_list</span><span class="p">,</span>
                                          <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">position_ids</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">llm_positions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="n">position_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">mrope_position_deltas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">llm_positions</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span>
                                             <span class="nb">len</span><span class="p">(</span><span class="n">total_input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="n">mrope_position_deltas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">mrope_position_deltas</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">position_ids</span><span class="p">,</span> <span class="n">mrope_position_deltas</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">position_ids</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">position_ids</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="n">input_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">max_position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">mrope_position_deltas</span> <span class="o">=</span> <span class="n">max_position_ids</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">position_ids</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                             <span class="n">device</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                                                 <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                                                     <span class="mi">3</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">mrope_position_deltas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">return</span> <span class="n">position_ids</span><span class="p">,</span> <span class="n">mrope_position_deltas</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.setup_fake_prompts_qwen2vl">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.setup_fake_prompts_qwen2vl">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_fake_prompts_qwen2vl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span>
                                   <span class="n">vision_grid_thws</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span>
                                   <span class="n">input_lengths</span><span class="p">):</span>

        <span class="n">visual_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">visual_features</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Get the rope index</span>
        <span class="c1"># From HF&#39;s preprocess code</span>
        <span class="n">mrope_position_ids</span><span class="p">,</span> <span class="n">mrope_position_deltas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_rope_index</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="p">,</span>
            <span class="n">image_grid_thw</span><span class="o">=</span><span class="n">vision_grid_thws</span><span class="p">,</span>
            <span class="n">video_grid_thw</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># This is where we convert input_ids of image features into fake_prompt_ids mapping for TRT-LLM engine.</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_ids</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_token_id</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span>
            <span class="n">input_ids</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_token_id</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">input_ids</span>
                                                  <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_token_id</span><span class="p">)</span>
        <span class="n">cumulative_counts</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">cumulative_counts</span>
        <span class="n">input_ids</span><span class="p">[</span><span class="n">masks</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">masks</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span><span class="o">.</span><span class="n">is_first_pp_rank</span><span class="p">():</span>
            <span class="n">ptuning_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ptuning_setup</span><span class="p">(</span><span class="n">visual_features</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span>
                                              <span class="n">input_lengths</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ptuning_args</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="c1"># This does not have dependency on input.</span>
        <span class="c1"># Switch to attributes to use across iterations.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;rotary_cos_sin&#39;</span><span class="p">):</span>
            <span class="n">inv_freq</span><span class="p">,</span> <span class="n">rotary_cos_sin</span> <span class="o">=</span> <span class="n">RopeEmbeddingUtils</span><span class="o">.</span><span class="n">create_sinusoidal_positions_for_attention_plugin</span><span class="p">(</span>
                <span class="n">num_pos</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span>
                <span class="n">dim</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">),</span>
                <span class="n">theta</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rope_theta</span><span class="p">),</span>
                <span class="n">scale_type</span><span class="o">=</span><span class="n">RotaryScalingType</span><span class="o">.</span><span class="n">mrope</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rotary_cos_sin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">rotary_cos_sin</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">visual_features</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rotary_cos_sin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rotary_cos_sin</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span>
                <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cos_ori</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rotary_cos_sin</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sin_ori</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rotary_cos_sin</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">mrope_position_ids</span> <span class="o">=</span> <span class="n">mrope_position_ids</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">mrope_position_ids_padding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="n">mrope_position_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span> <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">visual_features</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mrope_position_ids_padding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">mrope_position_ids</span><span class="o">.</span>
                                   <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">mrope_position_ids</span>
        <span class="n">cos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos_ori</span><span class="p">[</span><span class="n">mrope_position_ids_padding</span><span class="p">]</span>
        <span class="n">sin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sin_ori</span><span class="p">[</span><span class="n">mrope_position_ids_padding</span><span class="p">]</span>

        <span class="n">mrope_section</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">]</span>
        <span class="n">cos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
            <span class="n">m</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cos</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">mrope_section</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="p">],</span>
                        <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">sin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
            <span class="n">m</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sin</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">mrope_section</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="p">],</span>
                        <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">concat_cos_sin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">cos</span><span class="p">,</span> <span class="n">sin</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">concat_cos_sin</span> <span class="o">=</span> <span class="n">concat_cos_sin</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">concat_cos_sin</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">mrope_args</span> <span class="o">=</span> <span class="p">[</span><span class="n">concat_cos_sin</span><span class="p">,</span> <span class="n">mrope_position_deltas</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">ptuning_args</span><span class="p">,</span> <span class="n">mrope_args</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.ptuning_setup_fuyu">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.ptuning_setup_fuyu">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">ptuning_setup_fuyu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">image_patches_indices</span><span class="p">):</span>
        <span class="n">res_input_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">cur_input_ids</span><span class="p">,</span> <span class="n">cur_image_patches_indices</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">input_ids</span><span class="p">,</span> <span class="n">image_patches_indices</span><span class="p">):</span>
            <span class="c1"># Truncate input_ids to the length of image_patches_indices</span>
            <span class="n">cur_image_patches_indices</span> <span class="o">=</span> <span class="n">cur_image_patches_indices</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span>
                <span class="n">cur_input_ids</span><span class="p">)]</span>
            <span class="c1"># Get ids of the image_patches</span>
            <span class="n">non_zero_mask</span> <span class="o">=</span> <span class="n">cur_image_patches_indices</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="c1"># Replace input_ids with image_patches_indices values (where the patches are placed)</span>
            <span class="n">cur_input_ids</span> <span class="o">=</span> <span class="n">cur_input_ids</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">(</span>
                <span class="n">non_zero_mask</span><span class="p">,</span>
                <span class="n">cur_image_patches_indices</span><span class="p">[</span><span class="n">non_zero_mask</span><span class="p">]</span> <span class="o">+</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">res_input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_input_ids</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res_input_ids</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.ptuning_setup_llava_next">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.ptuning_setup_llava_next">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">ptuning_setup_llava_next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">pre_prompt</span><span class="p">,</span>
                                 <span class="n">post_prompt</span><span class="p">):</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">fake_prompt_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
            <span class="n">pre_prompt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">fake_prompt_ids</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
                <span class="n">post_prompt</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_bos_token</span><span class="p">:]</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_ids</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">pre_prompt</span><span class="p">)</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">input_ids</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.ptuning_setup_phi3">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.ptuning_setup_phi3">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">ptuning_setup_phi3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">,</span> <span class="n">audio_features</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span>
                           <span class="n">num_img_tokens</span><span class="p">,</span> <span class="n">num_aud_tokens</span><span class="p">):</span>
        <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-3-vision&quot;</span><span class="p">:</span>
            <span class="n">MAX_INPUT_ID</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e9</span><span class="p">)</span>
            <span class="n">positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span>
                <span class="p">(</span><span class="n">input_ids</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">input_ids</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">MAX_INPUT_ID</span><span class="p">),</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-4-multimodal&quot;</span><span class="p">:</span>
            <span class="n">IMAGE_TOKEN_ID</span> <span class="o">=</span> <span class="mi">200010</span>
            <span class="n">positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">==</span> <span class="n">IMAGE_TOKEN_ID</span><span class="p">,</span>
                                      <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cnt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_img_tokens</span><span class="p">):</span>
            <span class="n">input_ids</span><span class="p">[</span><span class="n">positions</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">positions</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span><span class="n">positions</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
                      <span class="n">cnt</span><span class="p">]</span> <span class="o">=</span> <span class="n">fake_prompt_id</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span> <span class="o">+</span> <span class="n">cnt</span><span class="p">]</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="n">cnt</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;phi-4-multimodal&quot;</span> <span class="ow">and</span> <span class="n">audio_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_id_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">visual_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                <span class="mi">0</span><span class="p">]</span>
            <span class="n">fake_prompt_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                <span class="n">prompt_id_offset</span><span class="p">,</span> <span class="n">prompt_id_offset</span> <span class="o">+</span> <span class="n">audio_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">AUDIO_TOKEN_ID</span> <span class="o">=</span> <span class="mi">200011</span>
            <span class="n">positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">==</span> <span class="n">AUDIO_TOKEN_ID</span><span class="p">,</span>
                                      <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cnt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_aud_tokens</span><span class="p">):</span>
                <span class="n">input_ids</span><span class="p">[</span><span class="n">positions</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">positions</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span>
                                                       <span class="mi">1</span><span class="p">]:</span><span class="n">positions</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
                          <span class="n">cnt</span><span class="p">]</span> <span class="o">=</span> <span class="n">fake_prompt_id</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span> <span class="o">+</span> <span class="n">cnt</span><span class="p">]</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="n">cnt</span>
        <span class="k">return</span> <span class="n">input_ids</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.ptuning_setup">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.ptuning_setup">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">ptuning_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt_table</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">):</span>
        <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_mapping</span><span class="o">.</span><span class="n">tp_size</span>
        <span class="k">if</span> <span class="n">prompt_table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_vocab_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[</span><span class="n">prompt_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="n">prompt_table</span> <span class="o">=</span> <span class="n">prompt_table</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="p">(</span><span class="n">prompt_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">prompt_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                 <span class="n">prompt_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>

            <span class="k">assert</span> <span class="n">prompt_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
                <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="s2">&quot;Prompt table dimensions do not match hidden size&quot;</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">):</span>
                <span class="n">prompt_table</span> <span class="o">=</span> <span class="n">prompt_table</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">str_dtype_to_torch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mm_embedding_offloading</span><span class="p">:</span>
                    <span class="c1"># CUDA Stream Overlapping Requirements:</span>
                    <span class="c1"># 1. Both memory copy stream and kernel execution stream must be non-default streams</span>
                    <span class="c1"># 2. For host&lt;-&gt;device transfers (H2D/D2H), host memory MUST be page-locked (pinned)</span>
                    <span class="n">prompt_table</span> <span class="o">=</span> <span class="n">prompt_table</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prompt_table</span> <span class="o">=</span> <span class="n">prompt_table</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt_table</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="n">task_vocab_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">remove_input_padding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">remove_input_padding</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span>
            <span class="s1">&#39;remove_input_padding&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">use_packed_input</span>
        <span class="k">if</span> <span class="n">remove_input_padding</span><span class="p">:</span>
            <span class="n">tasks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">input_lengths</span><span class="p">)],</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span><span class="p">:</span> <span class="n">tasks</span> <span class="o">=</span> <span class="n">tasks</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">tasks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">input_id</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">input_id</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">)</span>
                <span class="n">tasks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">),</span> <span class="n">max_length</span><span class="p">),</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">prompt_table</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">task_vocab_size</span><span class="p">]</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.load_test_data">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.load_test_data">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_test_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">video_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">load_images</span><span class="p">(</span><span class="n">image_paths</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_paths</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">image_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">image_paths</span><span class="p">]</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">image_paths</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">image_path</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;http&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">image_path</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span>
                        <span class="s2">&quot;https&quot;</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;downloading image from url </span><span class="si">{</span><span class="n">image_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
                <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">images</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;vila&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">image_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">img_urls</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="s1">&#39;https://github.com/NVlabs/VILA/blob/6b941da19e31ddfdfaa60160908ccf0978d96615/demo_images/av.png?raw=true&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;https://storage.googleapis.com/sfr-vision-language-research/LAVIS/assets/merlion.png&#39;</span>
                <span class="p">]</span> <span class="o">*</span> <span class="mi">4</span>

                <span class="n">img_urls</span> <span class="o">=</span> <span class="n">img_urls</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">image_path</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">img_urls</span><span class="p">)</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">load_images</span><span class="p">(</span><span class="n">img_urls</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">image_path</span> <span class="o">=</span> <span class="n">image_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">path_sep</span><span class="p">)</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">load_images</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;nougat&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="n">hf_hub_download</span><span class="p">(</span>
                <span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;hf-internal-testing/fixtures_docvqa&quot;</span><span class="p">,</span>
                <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;nougat_paper.png&quot;</span><span class="p">,</span>
                <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;fuyu&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;adept/fuyu-8b&quot;</span><span class="p">,</span>
                                       <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;skateboard.png&quot;</span><span class="p">,</span>
                                       <span class="n">repo_type</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;kosmos&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">image_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;https://huggingface.co/microsoft/kosmos-2-patch14-224/resolve/main/snowman.png&#39;</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">load_images</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;pix2struct&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">image_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/multi_col_40963.png&#39;</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">load_images</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;video-neva&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">video_path</span>
        <span class="k">elif</span> <span class="s2">&quot;internlm&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">img_url</span> <span class="o">=</span> <span class="s2">&quot;https://huggingface.co/internlm/internlm-xcomposer2-vl-7b/resolve/main/image1.webp&quot;</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">load_images</span><span class="p">(</span><span class="n">img_url</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;internvl&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">image_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">img_url</span> <span class="o">=</span> <span class="s1">&#39;https://huggingface.co/OpenGVLab/InternVL2-4B/resolve/main/examples/image1.jpg&#39;</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
                    <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">timeout</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;qwen2_vl&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">image_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">img_url</span> <span class="o">=</span> <span class="s1">&#39;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg&#39;</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
                    <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">timeout</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">504</span><span class="p">,</span> <span class="mi">504</span><span class="p">))</span>
                <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">image_path</span><span class="p">:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">504</span><span class="p">,</span> <span class="mi">504</span><span class="p">))</span>
                    <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;llava_onevision&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="o">==</span> <span class="s1">&#39;llava-onevision-accuracy&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="o">=</span> <span class="n">hf_hub_download</span><span class="p">(</span>
                    <span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;raushan-testing-hf/videos-test&quot;</span><span class="p">,</span>
                    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;sample_demo_1.mp4&quot;</span><span class="p">,</span>
                    <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">av</span>
            <span class="k">with</span> <span class="n">av</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">container</span><span class="p">:</span>
                <span class="n">total_frames</span> <span class="o">=</span> <span class="n">container</span><span class="o">.</span><span class="n">streams</span><span class="o">.</span><span class="n">video</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">frames</span>
                <span class="k">assert</span> <span class="n">total_frames</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_frames</span><span class="p">,</span>
                                    <span class="n">total_frames</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
                <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">container</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">start_index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">end_index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">frame</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">container</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">video</span><span class="o">=</span><span class="mi">0</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">end_index</span><span class="p">:</span>
                        <span class="k">break</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">start_index</span> <span class="ow">and</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
                        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;rgb24&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">frames</span><span class="p">])</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">!=</span> <span class="s1">&#39;mllama&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">image_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;llava&quot;</span><span class="p">:</span>
                        <span class="n">image_path</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="s1">&#39;https://storage.googleapis.com/sfr-vision-language-research/LAVIS/assets/merlion.png&#39;</span>
                        <span class="p">]</span> <span class="o">*</span> <span class="mi">8</span>
                        <span class="n">image_path</span> <span class="o">=</span> <span class="n">image_path</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">image_path</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;https://storage.googleapis.com/sfr-vision-language-research/LAVIS/assets/merlion.png&#39;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">image_path</span> <span class="o">=</span> <span class="n">image_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">path_sep</span><span class="p">)</span>

            <span class="n">images</span> <span class="o">=</span> <span class="n">load_images</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">image_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">images</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.load_test_audio">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.load_test_audio">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_test_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_path</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">!=</span> <span class="s2">&quot;phi-4-multimodal&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">assert</span> <span class="n">audio_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">soundfile</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">soundfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">audio_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">audio</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.setup_inputs">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.setup_inputs">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">raw_image</span><span class="p">,</span> <span class="n">raw_audio</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">..tools.multimodal_builder</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_rotary_pos_emb</span>
        <span class="n">other_vision_inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">other_audio_inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">other_decoder_inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;qwen2_vl&#39;</span><span class="p">,</span> <span class="s1">&#39;vila&#39;</span><span class="p">,</span> <span class="s1">&#39;llava&#39;</span><span class="p">]:</span>
            <span class="n">input_text</span> <span class="o">=</span> <span class="n">input_text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span>
                                                     <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">input_text</span>

        <span class="k">if</span> <span class="s1">&#39;blip2&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">raw_image</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Question: which city is this? Answer:&quot;</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="n">input_text</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="s1">&#39;internlm&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="c1">#Feed the raw image into vis_processor, to get processed image</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">raw_image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Please describe this image in detail.&quot;</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
            <span class="n">meta_instruction</span> <span class="o">=</span> <span class="s1">&#39;You are an AI assistant whose name is InternLM-XComposer ().</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="s1">&#39;- InternLM-XComposer () is a multi-modality conversational language model that is developed by Shanghai AI Laboratory (). It is designed to be helpful, honest, and harmless.</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="s1">&#39;- InternLM-XComposer () can understand and communicate fluently in the language chosen by the user such as English and .</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="s1">&#39;- InternLM-XComposer () is capable of comprehending and articulating responses effectively based on the provided image.&#39;</span><span class="p">,</span>
            <span class="n">pre_prompt</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;[UNUSED_TOKEN_146]system</span><span class="se">\n</span><span class="si">{</span><span class="n">meta_instruction</span><span class="si">}</span><span class="s2">[UNUSED_TOKEN_145]</span><span class="se">\n</span><span class="s2">&quot;&quot;&quot;</span>
            <span class="n">pre_prompt</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;[UNUSED_TOKEN_146]user</span><span class="se">\n</span><span class="s2">&quot;&quot;&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">[UNUSED_TOKEN_145]</span><span class="se">\n</span><span class="s2">[UNUSED_TOKEN_146]assistant</span><span class="se">\n</span><span class="s2">&quot;&quot;&quot;</span>
        <span class="k">elif</span> <span class="s1">&#39;qwen2_vl&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">qwen_vl_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_vision_info</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers.models.qwen2_vl.modeling_qwen2_vl</span><span class="w"> </span><span class="kn">import</span> \
                <span class="n">VisionRotaryEmbedding</span>
            <span class="n">hf_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Question: Describe this image. Answer:&quot;</span>
                              <span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[[{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span>
                <span class="s2">&quot;user&quot;</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="n">raw_image</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                    <span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">input_text</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                    <span class="p">},</span>
                <span class="p">],</span>
            <span class="p">}]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)]</span>

            <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span>
                                                   <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                   <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">messages</span>
            <span class="p">]</span>
            <span class="n">image_inputs</span><span class="p">,</span> <span class="n">video_inputs</span> <span class="o">=</span> <span class="n">process_vision_info</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span>
                <span class="n">text</span><span class="o">=</span><span class="n">texts</span><span class="p">,</span>
                <span class="n">images</span><span class="o">=</span><span class="n">image_inputs</span><span class="p">,</span>
                <span class="n">videos</span><span class="o">=</span><span class="n">video_inputs</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
            <span class="n">image_grid_thw</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;image_grid_thw&#39;</span><span class="p">]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span>
            <span class="n">cu_seqlens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
                <span class="n">image_grid_thw</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">image_grid_thw</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span>
                <span class="n">image_grid_thw</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">cu_seqlens</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">cu_seqlens</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">seq_length</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Create block indices using bucketing</span>
            <span class="n">block_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bucketize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span>
                                                         <span class="n">device</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                                            <span class="n">cu_seqlens</span><span class="p">,</span>
                                            <span class="n">right</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="c1"># Generate block diagonal mask using matrix expansion</span>
            <span class="n">attention_mask_vit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">block_indices</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">block_indices</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((),</span>
                           <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">,</span>
                           <span class="n">device</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">images_qwenvl</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">rotary_pos_emb</span> <span class="o">=</span> <span class="n">compute_rotary_pos_emb</span><span class="p">(</span>
                <span class="n">image_grid_thw</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">VisionRotaryEmbedding</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
            <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask_llm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask</span>
            <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;image_grid_thw&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_grid_thw</span>
            <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask_vit</span>
            <span class="n">other_vision_inputs</span><span class="p">[</span><span class="s1">&#39;rotary_pos_emb&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rotary_pos_emb</span>
            <span class="k">return</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">pre_prompt</span><span class="p">,</span> <span class="n">post_prompt</span><span class="p">,</span> <span class="n">images_qwenvl</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">,</span> <span class="n">other_audio_inputs</span><span class="p">,</span> <span class="n">other_decoder_inputs</span>
        <span class="k">elif</span> <span class="s1">&#39;nougat&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">raw_image</span><span class="p">,</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
            <span class="c1"># Nougat doesn&#39;t need text prompt (mBART use single token to start generation), just leave a dummy one here</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Question: which city is this? Answer:&quot;</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="n">input_text</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">elif</span> <span class="s1">&#39;cogvlm&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">raw_image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot; [INST] which city is this? [/INST] &quot;</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="n">input_text</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">elif</span> <span class="s1">&#39;phi-3-vision&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|user|&gt;</span><span class="se">\n</span><span class="s2">&lt;|image_1|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Which city is this?&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="n">input_text</span> <span class="o">+</span> <span class="s2">&quot;&lt;|end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|assistant|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">post_prompt</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                                   <span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s1">&#39;phi-4-multimodal&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|user|&gt;&lt;|image_1|&gt;&lt;|audio_1|&gt;&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|end|&gt;&lt;|assistant|&gt;&quot;</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">post_prompt</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                                   <span class="n">images</span><span class="o">=</span><span class="p">[</span><span class="n">raw_image</span><span class="p">],</span>
                                   <span class="n">audios</span><span class="o">=</span><span class="p">[</span><span class="n">raw_audio</span><span class="p">],</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s1">&#39;internvl&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|system|&gt;</span><span class="se">\n</span><span class="s2">InternVL, &lt;|end|&gt;&lt;|user|&gt;</span><span class="se">\n</span><span class="s2">&lt;image&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Please describe the image shortly.&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="n">input_text</span> <span class="o">+</span> <span class="s2">&quot;&lt;|end|&gt;&lt;|assistant|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">post_prompt</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">pixel_values</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;pix2struct&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span>
                <span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                <span class="n">text</span><span class="o">=</span><span class="n">input_text</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;flattened_patches&#39;</span><span class="p">]</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;neva&quot;</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">raw_image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Hi! What is in this image?&quot;</span>

            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;extra_id_0&gt;System</span><span class="se">\n\n</span><span class="s2">&lt;extra_id_1&gt;User</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="se">\n</span><span class="s2">&lt;extra_id_1&gt;Assistant</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;video-neva&quot;</span><span class="p">:</span>

            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_preprocess</span><span class="p">(</span>
                <span class="n">raw_image</span><span class="p">)</span>  <span class="c1"># shape (1, num_frames, 3, H, W)</span>

            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Hi! What is in this video?&quot;</span>

            <span class="c1"># SteerLM prompt template</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;&lt;extra_id_0&gt;System</span><span class="se">\n</span><span class="s2">A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#39;s questions.</span><span class="se">\n\n</span><span class="s2">&lt;extra_id_1&gt;User&quot;&quot;&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="se">\n</span><span class="s2">&lt;extra_id_1&gt;Assistant</span><span class="se">\n</span><span class="s2">&lt;extra_id_2&gt;quality:4,toxicity:0,humor:0,creativity:0,helpfulness:4,correctness:4,coherence:4,complexity:4,verbosity:4</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="s2">&quot;&quot;</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;llava_next&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_name</span> <span class="o">==</span> <span class="s2">&quot;mistralai/Mistral-7B-Instruct-v0.2&quot;</span><span class="p">:</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;[INST] &quot;</span>
                <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Question: which city is this? Answer:&quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2"> [/INST]&quot;</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">post_prompt</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_name</span> <span class="o">==</span> <span class="s2">&quot;NousResearch/Nous-Hermes-2-Yi-34B&quot;</span><span class="p">:</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|im_start|&gt;system</span><span class="se">\n</span><span class="s2">Answer the questions.&lt;|im_end|&gt;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Question: which city is this? Answer:&quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">post_prompt</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Prompt template for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">llm_name</span><span class="si">}</span><span class="s2"> for not included currently&quot;</span>
                <span class="p">)</span>

            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                                   <span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;vila&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;&lt;image&gt;</span><span class="se">\n</span><span class="s2"> Please elaborate what you see in the images?&quot;</span>
            <span class="k">if</span> <span class="s1">&#39;8b&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;</span><span class="se">\n\n</span><span class="s2">You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span><span class="se">\n\n</span><span class="s2">&quot;</span>
            <span class="k">elif</span> <span class="s1">&#39;40b&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|im_start|&gt;system</span><span class="se">\n</span><span class="s2">Answer the questions.&lt;|im_end|&gt;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|im_end|&gt;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#39;s questions. USER: &quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="s2">&quot; ASSISTANT:&quot;</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span> <span class="o">+</span> <span class="n">post_prompt</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">input_text</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="n">input_text</span> <span class="o">+</span> <span class="n">post_prompt</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">raw_image</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">raw_image</span> <span class="o">=</span> <span class="p">[</span><span class="n">raw_image</span><span class="p">]</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">raw_image</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;llava&#39;</span><span class="p">,</span> <span class="s1">&#39;fuyu&#39;</span><span class="p">,</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;llava&quot;</span><span class="p">:</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#39;s questions. USER: &quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="s2">&quot; ASSISTANT:&quot;</span>
                <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Which city is this? Answer:&quot;</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">post_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span> <span class="o">+</span> <span class="n">post_prompt</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">input_text</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">post_prompt</span> <span class="o">=</span> <span class="n">input_text</span> <span class="o">+</span> <span class="n">post_prompt</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;fuyu&#39;</span><span class="p">:</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;Describe this image:&quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Answer the following VQAv2 question based on the image: How many people are in the image?</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;kosmos-2&quot;</span><span class="p">:</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;&lt;grounding&gt;An image of&quot;</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;fuyu&#39;</span><span class="p">,</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">]:</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="s2">&quot; ASSISTANT:&quot;</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">post_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span> <span class="o">+</span> <span class="n">post_prompt</span> <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">input_text</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">post_prompt</span> <span class="o">=</span> <span class="n">input_text</span> <span class="o">+</span> <span class="n">post_prompt</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;fuyu&#39;</span><span class="p">,</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">]:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">input_text</span><span class="p">,</span>
                                       <span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                       <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">input_text</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                           <span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                           <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                           <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">input_text</span><span class="p">,</span>
                                           <span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                           <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;mllama&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">raw_image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                    <span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">input_text</span><span class="p">)</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                        <span class="n">text</span><span class="o">=</span><span class="n">input_text</span><span class="p">,</span>
                                        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
                <span class="n">other_vision_inputs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;aspect_ratio_ids&quot;</span><span class="p">:</span>
                    <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;aspect_ratio_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">(),</span>
                    <span class="s2">&quot;aspect_ratio_mask&quot;</span><span class="p">:</span>
                    <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;aspect_ratio_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">(),</span>
                <span class="p">}</span>
                <span class="n">other_decoder_inputs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;cross_attention_mask&quot;</span><span class="p">:</span>
                    <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;cross_attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">(),</span>
                <span class="p">}</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="n">input_text</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pre_prompt</span> <span class="o">=</span> <span class="n">input_text</span>
                <span class="n">post_prompt</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">image</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;image_path is None. Will not pass image as input, skipping the vision encoder.&quot;</span>
                <span class="p">)</span>
                <span class="n">image</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;llava_onevision&#39;</span><span class="p">]:</span>
            <span class="n">pre_prompt</span> <span class="o">=</span> <span class="s2">&quot;&lt;|im_start|&gt;user &quot;</span>
            <span class="k">if</span> <span class="n">input_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Question: which city is this? Answer:&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;Why is this video funny?&quot;</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">pre_prompt</span> <span class="o">+</span> <span class="n">post_prompt</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">video_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                       <span class="n">text</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                                       <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">videos</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span>
                                       <span class="n">text</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                                       <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

        <span class="c1"># Repeat inputs to match batch size</span>
        <span class="n">pre_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">pre_prompt</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">post_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">post_prompt</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s1">&#39;fuyu&#39;</span><span class="p">,</span> <span class="s1">&#39;pix2struct&#39;</span><span class="p">,</span> <span class="s1">&#39;kosmos-2&#39;</span><span class="p">,</span> <span class="s1">&#39;vila&#39;</span><span class="p">,</span> <span class="s1">&#39;phi-3-vision&#39;</span><span class="p">,</span>
                <span class="s1">&#39;phi-4-multimodal&#39;</span><span class="p">,</span> <span class="s1">&#39;llava_next&#39;</span><span class="p">,</span> <span class="s1">&#39;internvl&#39;</span><span class="p">,</span> <span class="s1">&#39;llava_onevision&#39;</span>
        <span class="p">]:</span>
            <span class="k">if</span> <span class="n">image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="k">elif</span> <span class="n">image</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                             <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                            <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_text</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                            <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Generate decoder_input_ids for enc-dec models</span>
        <span class="c1"># Custom prompts can be added as:</span>
        <span class="c1"># decoder_input_ids = model.tokenizer(decoder_prompt).input_ids</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_llm</span><span class="p">:</span>
            <span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hf_model_dir</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;blip2&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
                <span class="n">decoder_start_id</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">text_config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>  <span class="c1"># T5</span>
            <span class="k">elif</span> <span class="s2">&quot;nougat&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
                <span class="n">decoder_start_id</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bos_token_id</span>  <span class="c1"># Nougat</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">decoder_start_id</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>

            <span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">([[</span><span class="n">decoder_start_id</span><span class="p">]])</span>
            <span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">decoder_input_ids</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">pre_prompt</span><span class="p">,</span> <span class="n">post_prompt</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">,</span> <span class="n">other_audio_inputs</span><span class="p">,</span> <span class="n">other_decoder_inputs</span></div>


<div class="viewcode-block" id="MultimodalModelRunner.run">
<a class="viewcode-back" href="../../../python-api/tensorrt_llm.runtime.html#tensorrt_llm.runtime.MultimodalModelRunner.run">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">input_image</span><span class="p">,</span> <span class="n">input_audio</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">):</span>
        <span class="n">input_text</span><span class="p">,</span> <span class="n">pre_prompt</span><span class="p">,</span> <span class="n">post_prompt</span><span class="p">,</span> <span class="n">processed_image</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">other_vision_inputs</span><span class="p">,</span> <span class="n">other_audio_inputs</span><span class="p">,</span> <span class="n">other_decoder_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_inputs</span><span class="p">(</span>
            <span class="n">input_text</span><span class="p">,</span> <span class="n">input_image</span><span class="p">,</span> <span class="n">input_audio</span><span class="p">)</span>
        <span class="n">output_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">pre_prompt</span><span class="p">,</span>
                                    <span class="n">post_prompt</span><span class="p">,</span>
                                    <span class="n">processed_image</span><span class="p">,</span>
                                    <span class="n">decoder_input_ids</span><span class="p">,</span>
                                    <span class="n">max_new_tokens</span><span class="p">,</span>
                                    <span class="n">other_vision_inputs</span><span class="o">=</span><span class="n">other_vision_inputs</span><span class="p">,</span>
                                    <span class="n">other_audio_inputs</span><span class="o">=</span><span class="n">other_audio_inputs</span><span class="p">,</span>
                                    <span class="n">other_decoder_inputs</span><span class="o">=</span><span class="n">other_decoder_inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">output_text</span></div>
</div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            

<div class="bd-sidebar-secondary"></div>


              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
<a class="footer-brand logo" href="https://www.nvidia.com">
  <img src="../../../_static/nvidia-logo-horiz-rgb-1c-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA"/>
  <img src="../../../_static/nvidia-logo-horiz-rgb-1c-wht-for-screen.svg" class="logo__image only-dark" alt="NVIDIA"/>
</a></div>
      
        <div class="footer-item">

<div class="footer-links">
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/">Privacy Policy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/">Manage My Privacy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/preferences/start/">Do Not Sell or Share My Data</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/">Terms of Service</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/">Accessibility</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/">Corporate Policies</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/product-security/">Product Security</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/contact/">Contact</a>
  
  
  
</div>
</div>
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright  2025, NVidia.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>