examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-BertModel-bert/bert-base-uncased]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-BertForQuestionAnswering-bert/bert-base-cased-squad2]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-BertForSequenceClassification-bert/bert-base-uncased-yelp-polarity]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-RobertaModel-bert/roberta-base]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-RobertaForQuestionAnswering-bert/roberta-base-squad2]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-RobertaForSequenceClassification-bert/twitter-roberta-base-emotion]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha_fp32_acc-tp:1-pp:1-float16-BertModel-bert/bert-base-uncased]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-disable_context_fmha-tp:1-pp:1-float16-BertModel-bert/bert-base-uncased]
examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-disable_context_fmha-tp:2-pp:1-float16-BertModel-bert/bert-base-uncased]
examples/test_bert.py::test_llm_bert_general[compare_hf-disable_remove_input_padding-use_attention_plugin-disable_context_fmha-tp:2-pp:1-float16-BertForQuestionAnswering-bert/bert-base-cased-squad2]
examples/test_bindings.py::test_llm_bindings_example[llama-7b]
examples/test_chatglm.py::test_llm_chatglm2_6b_single_gpu_summary[chatglm2-6b-32k-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha-nb:1]
examples/test_chatglm.py::test_llm_chatglm2_6b_single_gpu_summary[chatglm2-6b-32k-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-enable_fmha-nb:4]
examples/test_chatglm.py::test_llm_chatglm2_6b_single_gpu_summary[chatglm2-6b-32k-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-disable_fmha-nb:2]
examples/test_chatglm.py::test_llm_chatglm2_6b_single_gpu_summary[chatglm2-6b-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha-nb:4]
examples/test_chatglm.py::test_llm_chatglm2_6b_single_gpu_summary[chatglm2-6b-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-enable_fmha_fp32_acc-nb:2]
examples/test_chatglm.py::test_llm_chatglm3_6b_2gpus_summary[chatglm3-6b-disable_debug]
examples/test_chatglm.py::test_llm_chatglm3_6b_2gpus_summary[chatglm3-6b-enable_debug]
examples/test_chatglm.py::test_llm_chatglm3_6b_long_context_ppl[SlimPajama-6B-chatglm3-6b-128k]
examples/test_chatglm.py::test_llm_chatglm3_6b_long_sq[long_input_1-chatglm3-6b-32k-nb:1]
examples/test_chatglm.py::test_llm_chatglm3_6b_long_sq[long_input_2-chatglm3-6b-32k-nb:4]
examples/test_chatglm.py::test_llm_chatglm3_6b_quantization_summary[chatglm3-6b-fp8]
examples/test_chatglm.py::test_llm_chatglm3_6b_quantization_summary[chatglm3-6b-int4_awq]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-32k-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha-nb:1]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-32k-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-enable_fmha-nb:4]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-32k-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-disable_fmha-nb:2]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-base-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha-nb:4]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-base-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-enable_fmha_fp32_acc-nb:2]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha-nb:4]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-enable_fmha-nb:4]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-enable_fmha_fp32_acc-nb:2]
examples/test_chatglm.py::test_llm_chatglm3_6b_single_gpu_summary[chatglm3-6b-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-disable_fmha-nb:2]
examples/test_chatglm.py::test_llm_chatglm_6b_single_gpu_summary[enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-nb:4]
examples/test_chatglm.py::test_llm_chatglm_6b_single_gpu_summary[enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-nb:2]
examples/test_chatglm.py::test_llm_glm_4_9b_single_gpu_summary[glm-4-9b-chat-disable_weight_only]
examples/test_chatglm.py::test_llm_glm_4_9b_single_gpu_summary[glm-4-9b-chat-enable_weight_only]
examples/test_chatglm.py::test_llm_glm_4_9b_single_gpu_summary[glm-4-9b-enable_weight_only]
examples/test_commandr.py::test_llm_commandr_v01_single_gpu_summary[disable_weight_only]
examples/test_commandr.py::test_llm_commandr_v01_single_gpu_summary[enable_weight_only]
examples/test_commandr.py::test_llm_commandr_plus_4gpus_summary[disable_weight_only]
examples/test_commandr.py::test_llm_commandr_plus_4gpus_summary[enable_weight_only]
examples/test_dbrx.py::test_llm_dbrx_8gpus[dbrx-base-bfloat16-tp4pp2]
examples/test_dbrx.py::test_llm_dbrx_quantization_4gpus[dbrx-base-int8_kv]
examples/test_dbrx.py::test_llm_dbrx_quantization_4gpus[dbrx-base-int8_wo]
examples/test_dbrx.py::test_llm_dbrx_quantization_4gpus[dbrx-instruct-int4_wo]
examples/test_mmdit.py::test_mmdit_multiple_gpus[stable-diffusion-3.5-medium-tp1]
examples/test_mmdit.py::test_mmdit_multiple_gpus[stable-diffusion-3.5-medium-tp2]
examples/test_dit.py::test_llm_dit_multiple_gpus[dit-xl-2-256x256-tp1]
examples/test_dit.py::test_llm_dit_multiple_gpus[dit-xl-2-512x512-fp8-linear-tp4]
examples/test_dit.py::test_llm_dit_multiple_gpus[dit-xl-2-512x512-tp4]
examples/test_stdit.py::test_stdit_multiple_gpus[OpenSora-STDiT-v3-tp1]
examples/test_stdit.py::test_stdit_multiple_gpus[OpenSora-STDiT-v3-tp2]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[no_streaming-gpt2-use_cpp_session-use_logits-draft_len_8-float16-bs1]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[no_streaming-llama_v2-use_cpp_session-use_tokens-draft_len_4-float16-bs2]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[streaming-llama_v2-use_cpp_session-use_logits-draft_len_4-float16-bs2]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[streaming-gpt2-use_cpp_session-use_tokens-draft_len_8-float16-bs1]
examples/test_eagle.py::test_llm_eagle_1gpu[llama3.1-eagle-8b-hf_v0.5-float16-bs8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-bart-large-cnn-float16-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-enable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-byt5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-enable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-flan-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-flan-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:2-pp:2-nb:1-enable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-mbart-large-50-many-to-one-mmt-float16-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-mbart-large-50-many-to-one-mmt-float16-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:2-pp:2-nb:1-enable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:2-pp:1-nb:1-enable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[no_compare_hf-byt5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-enable_fp8]
examples/test_enc_dec.py::test_llm_enc_dec_general[no_compare_hf-byt5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:2-pp:1-nb:1-disable_fp8]
examples/test_exaone.py::test_llm_exaone_1gpu[disable_weight_only-exaone-float16-nb:1]
examples/test_exaone.py::test_llm_exaone_1gpu[disable_weight_only-exaone-float16-nb:4]
examples/test_exaone.py::test_llm_exaone_1gpu[enable_weight_only-exaone-float16-nb:1]
examples/test_exaone.py::test_llm_exaone_2gpu[exaone-float16-nb:1]
examples/test_gemma.py::test_llm_gemma_1gpu_mmlu[gemma-2b-it-flax-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2-27b-it-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-fp8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-wo_int4-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-wo_int4-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-it-flax-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-keras-fp8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-keras-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-keras-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-keras-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-keras-smooth_quant-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-keras-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-torch-fp8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-torch-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-torch-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-torch-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-torch-smooth_quant-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-2b-torch-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-fp8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-wo_int4-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-wo_int4-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-it-flax-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-fp8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-smooth_quant-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-keras-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-torch-fp8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-torch-int8_kv_cache-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-torch-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-torch-other-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-torch-smooth_quant-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-torch-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_gemma_1gpu_summary[gemma-7b-torch-wo_int8-bfloat16-8]
examples/test_gemma.py::test_llm_hf_gemma_quantization_1gpu[gemma-2-27b-it-fp8-bfloat16-8]
examples/test_gemma.py::test_hf_gemma_fp8_base_bf16_multi_lora[gemma-2b]
examples/test_gemma.py::test_hf_gemma_fp8_base_bf16_multi_lora[gemma-7b]
examples/test_gemma.py::test_hf_gemma_fp8_base_bf16_multi_lora[gemma-2-9b-it]
examples/test_gemma.py::test_hf_gemma_fp8_base_bf16_multi_lora[gemma-2-27b-it]
examples/test_gpt.py::test_llm_gpt2_medium_1gpu[non_streaming-use_py_session-disable_gemm_plugin]
examples/test_gpt.py::test_llm_gpt2_medium_1gpu[streaming-use_cpp_session-enable_gemm_plugin]
examples/test_gpt.py::test_llm_gpt2_medium_1node_4gpus[tp1pp4]
examples/test_gpt.py::test_llm_gpt2_medium_1node_4gpus[tp2pp2]
examples/test_gpt.py::test_llm_gpt2_medium_1node_4gpus[tp4pp1]
examples/test_gpt.py::test_llm_gpt2_medium_bad_words_1gpu[non_streaming-use_cpp_session]
examples/test_gpt.py::test_llm_gpt2_medium_stop_words_1gpu[streaming-use_cpp_session]
examples/test_gpt.py::test_llm_gpt2_multi_lora_1gpu[900_stories]
examples/test_gpt.py::test_llm_gpt2_next_prompt_tuning[use_cpp_session-tp1]
examples/test_gpt.py::test_llm_gpt2_parallel_embedding_2gpu[float16-1]
examples/test_gpt.py::test_llm_gpt2_parallel_embedding_2gpu[float16-0]
examples/test_gpt.py::test_llm_gpt2_santacoder_1node_4gpus[parallel_build-enable_fmha-enable_gemm_plugin-enable_attention_plugin]
examples/test_gpt.py::test_llm_gpt2_starcoder_1node_4gpus[starcoder-enable_fmha-enable_gemm_plugin-enable_attention_plugin]
examples/test_gpt.py::test_llm_gpt2_starcoder_1node_4gpus[starcoder2-disable_fmha-enable_gemm_plugin-enable_attention_plugin]
examples/test_gpt.py::test_llm_gpt2_starcoder_1node_4gpus[starcoderplus-enable_fmha-enable_gemm_plugin-enable_attention_plugin]
examples/test_gpt.py::test_llm_gpt2_starcoder_weight_only[starcoder-int4-float16]
examples/test_gpt.py::test_llm_gpt2_starcoder_weight_only[starcoder-int8-float16]
examples/test_gpt.py::test_llm_gpt2_starcoder_weight_only[starcoder2-int4-float16]
examples/test_gpt.py::test_llm_gpt2_starcoder_weight_only[starcoder2-int8-float16]
examples/test_gpt.py::test_llm_gpt2_starcoder_weight_only[starcoderplus-int4-float16]
examples/test_gpt.py::test_llm_gpt2_starcoder_weight_only[starcoderplus-int8-float16]
examples/test_gpt.py::test_llm_gpt3_175b_1node_8gpus[parallel_build-enable_fmha-enable_gemm_plugin-enable_attention_plugin]
examples/test_gpt.py::test_llm_gpt_starcoder_lora_1gpu[peft-lora-starcoder2-15b-unity-copilot-starcoder2-lora_fp16-base_fp16]
examples/test_gpt.py::test_llm_gpt_starcoder_lora_1gpu[peft-lora-starcoder2-15b-unity-copilot-starcoder2-lora_fp16-base_fp8]
examples/test_gpt.py::test_llm_minitron_fp8_with_pseudo_loras[4b]
examples/test_gpt.py::test_starcoder_fp8_quantization_2gpu[starcoder]
examples/test_gpt.py::test_starcoder_fp8_quantization_2gpu[starcoderplus]
examples/test_gpt.py::test_starcoder_fp8_quantization_2gpu[starcoder2]
examples/test_llama.py::test_mistral_nemo_fp8_with_bf16_lora[Mistral-Nemo-12b-Base]
examples/test_mistral.py::test_mistral_nemo_minitron_fp8_with_bf16_lora[Mistral-NeMo-Minitron-8B-Instruct]
examples/test_phi.py::test_phi_fp8_with_bf16_lora[phi-2]
examples/test_phi.py::test_phi_fp8_with_bf16_lora[Phi-3-mini-128k-instruct]
examples/test_phi.py::test_phi_fp8_with_bf16_lora[Phi-3-small-128k-instruct]
examples/test_phi.py::test_phi_fp8_with_bf16_lora[Phi-3.5-mini-instruct]
examples/test_phi.py::test_phi_fp8_with_bf16_lora[Phi-3.5-MoE-instruct]
examples/test_gpt.py::test_streaming_beam[batch_size_1-disable_return_all_generated_tokens-num_beams_1]
examples/test_gpt.py::test_streaming_beam[batch_size_1-disable_return_all_generated_tokens-num_beams_4]
examples/test_gpt.py::test_streaming_beam[batch_size_1-return_all_generated_tokens-num_beams_1]
examples/test_gpt.py::test_streaming_beam[batch_size_1-return_all_generated_tokens-num_beams_4]
examples/test_gpt.py::test_streaming_beam[batch_size_3-disable_return_all_generated_tokens-num_beams_1]
examples/test_gpt.py::test_streaming_beam[batch_size_3-disable_return_all_generated_tokens-num_beams_4]
examples/test_gpt.py::test_streaming_beam[batch_size_3-return_all_generated_tokens-num_beams_1]
examples/test_gpt.py::test_streaming_beam[batch_size_3-return_all_generated_tokens-num_beams_4]
examples/test_granite.py::test_llm_granite[granite-3.0-1b-a400m-instruct-bfloat16]
examples/test_granite.py::test_llm_granite[granite-3.0-2b-instruct-bfloat16]
examples/test_granite.py::test_granite_bf16_lora[granite-3.0-1b-a400m-instruct]
examples/test_granite.py::test_granite_bf16_lora[granite-3.0-2b-instruct]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[no_streaming-gpt2-use_cpp_session-use_logits-draft_len_8-float16-bs1]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[no_streaming-gpt2-use_cpp_session-use_tokens-draft_len_4-float16-bs2]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[streaming-gpt2-use_cpp_session-use_logits-draft_len_4-float16-bs2]
examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[streaming-gpt2-use_cpp_session-use_tokens-draft_len_8-float16-bs1]
examples/test_prompt_lookup.py::test_llm_prompt_lookup_1gpu[no_streaming-gpt2-use_cpp_session-use_tokens-max_matching_ngram_size_2-prompt_lookup_num_tokens_8-float16-bs1]
examples/test_prompt_lookup.py::test_llm_prompt_lookup_1gpu[no_streaming-gpt2-use_cpp_session-use_tokens-max_matching_ngram_size_2-prompt_lookup_num_tokens_8-float16-bs2]
examples/test_prompt_lookup.py::test_llm_prompt_lookup_1gpu[streaming-gpt2-use_cpp_session-use_tokens-max_matching_ngram_size_2-prompt_lookup_num_tokens_8-float16-bs1]
examples/test_prompt_lookup.py::test_llm_prompt_lookup_1gpu[streaming-gpt2-use_cpp_session-use_tokens-max_matching_ngram_size_2-prompt_lookup_num_tokens_8-float16-bs2]
examples/test_grok.py::test_llm_grok_wo_1node_8gpus_summary
examples/test_internlm.py::test_llm_internlm2_7b_1node_1gpu[bfloat16-enable_context_fmha-enable_gemm_plugin-enable_attention_plugin-nb:2]
examples/test_jais.py::test_llm_jais_1node_2gpus_summary[enable_context_fmha-jais-30b-chat-v3-enable_gemm_plugin-enable_attention_plugin]
examples/test_jais.py::test_llm_jais_single_gpu_summary[bfloat16-enable_context_fmha-jais-13b-chat-enable_gemm_plugin-enable_attention_plugin]
examples/test_jais.py::test_llm_jais_single_gpu_summary[float16-enable_context_fmha-jais-13b-chat-enable_gemm_plugin-enable_attention_plugin]
examples/test_llama.py::test_llm_llama_1gpu_streaming_llm[ailab-deepseek-coder-6.7b-instruct]
examples/test_llama.py::test_llm_llama_2gpu_fp8_summary[llama-7b-enable_reduce_fusion-disable_fp8_context_fmha_xqa]
examples/test_llama.py::test_llm_llama_2gpu_fp8_summary[llama-v2-13b-hf-disable_reduce_fusion-disable_fp8_context_fmha_xqa]
examples/test_llama.py::test_llm_llama_2gpu_fp8_summary[llama-v2-13b-hf-enable_reduce_fusion-enable_fp8_context_fmha_xqa]
examples/test_llama.py::test_llm_llama_4gpu_pp4[TinyLlama-1.1B-Chat-v1.0-float16-nb:1]
examples/test_llama.py::test_llm_llama_code_llama_1gpu_summary[CodeLlama-7b-Instruct-enable_context_fmha-enable_gemm_plugin-enable_attention_plugin-nb:4]
examples/test_llama.py::test_llm_llama_code_llama_1gpu_summary[CodeLlama-7b-Instruct-enable_with_fp32_acc-enable_gemm_plugin-enable_attention_plugin-nb:1]
examples/test_llama.py::test_llm_llama_code_llama_multi_gpus_summary[CodeLlama-34b-Instruct-tp4pp1-nb:4]
examples/test_llama.py::test_llm_llama_code_llama_multi_gpus_summary[CodeLlama-70b-hf-tp2pp2-nb:1]
examples/test_llama.py::test_llm_llama_code_llama_quantization_4gpus_summary[CodeLlama-34b-Instruct-tp2pp2-int4_awq-nb:4]
examples/test_llama.py::test_llm_llama_code_llama_quantization_4gpus_summary[CodeLlama-34b-Instruct-tp4pp1-fp8-nb:1]
examples/test_llama.py::test_llm_llama_code_llama_quantization_4gpus_summary[CodeLlama-70b-hf-tp2pp2-int4_awq-nb:1]
examples/test_llama.py::test_llm_llama_code_llama_quantization_4gpus_summary[CodeLlama-70b-hf-tp4pp1-fp8-nb:4]
examples/test_llama.py::test_codellama_fp8_with_bf16_lora[CodeLlama-7b-Instruct]
examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-v2-7b-hf]
examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-v3-8b-instruct-hf]
examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-3.1-8b]
examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-3.2-1b]
examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-3.2-3b]
examples/test_llama.py::test_llm_llama_long_alpaca_8gpu_summary[pg64317-tp8pp1-nb:1]
examples/test_llama.py::test_llm_llama_lookahead_single_gpu_summary[llama-3.1-8b]
examples/test_llama.py::test_llm_llama_lookahead_xqa_fp8_1gpu[llama-3.1-8b]
examples/test_llama.py::test_llm_llama_lookahead_xqa_fp8_1gpu[llama-3.2-1b]
examples/test_llama.py::test_llm_llama_v1_2gpu_summary[llama-7b-nb:4-enable_auto_parallel]
examples/test_llama.py::test_llm_llama_v1_4gpu_paged_kv_cache[llama-3.1-8b]
examples/test_llama.py::test_llm_llama_v1_multiple_lora_1gpu[luotuo_japan-llama-7b-lora_fp16-base_fp16]
examples/test_llama.py::test_llm_llama_v1_multiple_lora_1gpu[luotuo_japan-llama-7b-lora_fp16-base_fp8]
examples/test_llama.py::test_llm_llama_v2_1gpu_auto_parallel[llama-v2-7b-hf]
examples/test_llama.py::test_llm_llama_v2_1gpu_fp8_summary_and_mmlu[llama-v2-7b-hf-disable_fp8_fmha-disable_mmlu_test]
examples/test_llama.py::test_llm_llama_v2_1gpu_fp8_summary_and_mmlu[llama-v2-7b-hf-enable_fp8_fmha-enable_mmlu_test]
examples/test_llama.py::test_llm_llama_v2_1gpu_fp8_summary_and_mmlu[llama-v2-7b-hf-enable_fp8_paged_fmha-enable_mmlu_test]
examples/test_llama.py::test_llm_llama_v2_lora_1gpu[chinese-llama-2-lora-13b-llama-v2-13b-hf-lora_fp16-base_awq]
examples/test_llama.py::test_llm_llama_v2_lora_1gpu[chinese-llama-2-lora-13b-llama-v2-13b-hf-lora_fp16-base_fp16]
examples/test_llama.py::test_llm_llama_v2_lora_1gpu[chinese-llama-2-lora-13b-llama-v2-13b-hf-lora_fp16-base_fp8]
examples/test_llama.py::test_llm_llama_v2_lora_1gpu[chinese-llama-2-lora-13b-llama-v2-13b-hf-lora_fp16-base_int8_wo]
examples/test_llama.py::test_llm_llama_v2_lora_1gpu[chinese-llama-2-lora-13b-llama-v2-13b-hf-lora_fp16-base_sq_ootb]
examples/test_llama.py::test_llm_llama_v2_lora_benchmark_2gpu[chinese_lora-llama-v2-13b-hf]
examples/test_llama.py::test_llm_llama_v3_1_1node_multi_gpus[enable_gemm_allreduce_plugin-llama-3.1-405b-enable_fp8]
examples/test_llama.py::test_llm_llama_v3_1_1node_multi_gpus[enable_gemm_allreduce_plugin-llama-3.1-405b-fp8-disable_fp8]
examples/test_llama.py::test_llm_llama_v3_1_1node_multi_gpus[enable_gemm_allreduce_plugin-llama-3.1-70b-disable_fp8]
examples/test_llama.py::test_llm_llama_v3_1_1node_multi_gpus[disable_gemm_allreduce_plugin-llama-3.1-70b-enable_fp8]
examples/test_llama.py::test_llm_llama_v3_1_1node_multi_gpus[disable_gemm_allreduce_plugin-llama-3.1-8b-disable_fp8]
examples/test_llama.py::test_llm_llama_v3_1_1node_multi_gpus[enable_gemm_allreduce_plugin-llama-3.1-8b-enable_fp8]
examples/test_llama.py::test_llm_llama_v3_1m_long_context_8gpus[Llama-3-8B-Instruct-Gradient-1048k]
examples/test_llama.py::test_llm_llama_v3_8b_1048k_long_context_ppl[SlimPajama-6B-Llama-3-8B-Instruct-Gradient-1048k]
examples/test_llama.py::test_llm_llama_v3_8b_1048k_long_context_ppl[passkey-Llama-3-8B-Instruct-Gradient-1048k]
examples/test_llama.py::test_llm_llama_v3_1_autoq_1gpu_mmlu[llama-3.1-8b]
examples/test_llama.py::test_llm_llama_v3_dora_1gpu[commonsense-llama-v3-8b-dora-r32-llama-v3-8b-hf-base_fp16]
examples/test_llama.py::test_llm_llama_1gpu_fp4_model_config[llama-v3-8b-instruct-hf-fp4_plugin]
examples/test_llama.py::test_llm_llama_1gpu_fp4[llama-3.1-8b-enable_norm_quant_fusion-disable_fused_quant-fp4_plugin-float16]
examples/test_llama.py::test_llm_llama_1gpu_fp4[llama-3.1-8b-enable_norm_quant_fusion-enable_fused_quant-fp4_plugin-float16]
examples/test_llama.py::test_llm_llama_1gpu_fp4[llama-3.1-8b-disable_norm_quant_fusion-disable_fused_quant-fp4_plugin-float16]
examples/test_llama.py::test_llm_llama_1gpu_fp4[llama-3.1-8b-disable_norm_quant_fusion-enable_fused_quant-fp4_plugin-float16]
examples/test_llama.py::test_llm_llama_1gpu_fp4[llama-3.1-8b-disable_norm_quant_fusion-disable_fused_quant-fp4_ootb-float16]
examples/test_llama.py::test_llm_llama_1gpu_fp4[llama-3.1-70b-instruct-enable_norm_quant_fusion-enable_fused_quant-fp4_plugin-bfloat16]
examples/test_llama.py::test_llm_llama_2gpu_fp4[llama-3.1-70b-instruct-fp4_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba-1.4b-float16-enable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba-130m-float16-enable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba-2.8b-float16-disable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba-370m-float16-enable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba-790m-float16-disable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba-codestral-7B-v0.1-float16-disable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba-codestral-7B-v0.1-float16-enable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba2-1.3b-float16-enable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba2-130m-float16-enable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba2-2.7b-float16-disable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba2-370m-float16-enable_gemm_plugin]
examples/test_mamba.py::test_llm_mamba_1gpu[mamba2-780m-float16-disable_gemm_plugin]
examples/test_medusa.py::test_llm_medusa_1gpu[use_cpp_session-medusa-vicuna-7b-v1.3-4-heads-bfloat16-bs1]
examples/test_medusa.py::test_llm_medusa_1gpu[use_cpp_session-medusa-vicuna-7b-v1.3-4-heads-bfloat16-bs8]
examples/test_medusa.py::test_llm_medusa_1gpu[use_py_session-medusa-vicuna-7b-v1.3-4-heads-bfloat16-bs1]
examples/test_medusa.py::test_llm_medusa_1gpu[use_py_session-medusa-vicuna-7b-v1.3-4-heads-bfloat16-bs8]
examples/test_medusa.py::test_llm_medusa_fp8_modelOpt_ckpt_1gpu[use_cpp_session-llama3.1-medusa-8b-hf_v0.1-bs1]
examples/test_medusa.py::test_llm_medusa_fp8_modelOpt_ckpt_1gpu[use_py_session-llama3.1-medusa-8b-hf_v0.1-bs8]
examples/test_mistral.py::test_llm_mistral_lora_1gpu[komt-mistral-7b-v1-lora-komt-mistral-7b-v1]
examples/test_mistral.py::test_llm_mistral_quantization_8gpus_summary[mistral-7b-v0.1-fp8-nb:4]
examples/test_mistral.py::test_llm_mistral_quantization_4gpus_llmapi[mistral-7b-v0.3-int4]
examples/test_mistral.py::test_llm_mistral_quantization_4gpus_llmapi[mistral-7b-v0.3-int4_awq]
examples/test_mistral.py::test_llm_mistral_quantization_4gpus_llmapi[mistral-7b-v0.3-int8_awq]
examples/test_mistral.py::test_llm_mistral_v1_1gpu[mistral-7b-v0.1-float16-max_attention_window_size_4096-summarization]
examples/test_mistral.py::test_llm_mistral_v1_1gpu[mistral-7b-v0.1-float16-max_attention_window_size_4096-summarization_long]
examples/test_mistral.py::test_llm_mistral_v1_smooth_quant_4gpus[mistral-7b-v0.1]
examples/test_mixtral.py::test_llm_mixtral_4gpus_fp8_mmlu_llmapi[Mixtral-8x7B-Instruct-v0.1-fp8]
examples/test_mistral.py::test_llm_mistral_nemo_minitron_fp8_quantization[Mistral-NeMo-Minitron-8B-Instruct]
examples/test_mistral.py::test_llm_mistral_nemo_fp8_quantization_1gpu[Mistral-Nemo-12b-Base-summarization]
examples/test_mistral.py::test_llm_mistral_nemo_fp8_quantization_1gpu[Mistral-Nemo-12b-Base-inference]
examples/test_mixtral.py::test_llm_mixtral_fp8_4gpus_summary[Mixtral-8x22B-v0.1-nb:1]
examples/test_mixtral.py::test_llm_mixtral_fp8_4gpus_summary[Mixtral-8x7B-v0.1-nb:4]
examples/test_mixtral.py::test_llm_mixtral_moe_plugin_fp8_lora_4gpus[Mixtral-8x7B-v0.1-chinese-mixtral-lora]
examples/test_mixtral.py::test_llm_mixtral_moe_plugin_lora_4gpus[Mixtral-8x7B-v0.1-chinese-mixtral-lora]
examples/test_mixtral.py::test_llm_mixtral_pp_reduce_scatter_4gpus[Mixtral-8x7B-v0.1]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x22B-v0.1-plugin-renormalize-tensor_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x7B-v0.1-ootb_except_mha-no_renormalize-expert_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x7B-v0.1-ootb_except_mha-no_renormalize-mixed_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x7B-v0.1-ootb_except_mha-no_renormalize-tensor_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x7B-v0.1-plugin-no_renormalize-tensor_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x7B-v0.1-plugin-renormalize-expert_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x7B-v0.1-plugin-renormalize-mixed_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_8gpus_summary[Mixtral-8x7B-v0.1-plugin-renormalize-tensor_parallel]
examples/test_mixtral.py::test_llm_mixtral_v1_smooth_quant_4gpus[Mixtral-8x7B-v0.1]
examples/test_mixtral.py::test_llm_mixtral_wo_2gpus_summary[Mixtral-8x7B-v0.1-int4-nb:1]
examples/test_mixtral.py::test_llm_mixtral_wo_2gpus_summary[Mixtral-8x7B-v0.1-int8-nb:4]
examples/test_mixtral.py::test_llm_mixtral_1gpu_fp4[Mixtral-8x7B-v0.1-fp4_plugin]
examples/test_mixtral.py::test_llm_mixtral_1gpu_fp4_llmapi[Mixtral-8x7B-Instruct-v0.1]
examples/test_mixtral.py::test_llm_mixtral_int4_awq_1gpu_summary[mixtral-8x7b-v0.1-AWQ]
examples/test_multimodal.py::test_llm_multimodal_general[Phi-3-vision-128k-instruct-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[Phi-3-vision-128k-instruct-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[Phi-3.5-vision-instruct-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[Qwen2-VL-7B-Instruct-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:4]
examples/test_multimodal.py::test_llm_multimodal_general[VILA1.5-3b-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[VILA1.5-3b-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-flan-t5-xl-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-flan-t5-xl-pp:1-tp:1-bfloat16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-opt-2.7b-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-opt-2.7b-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-opt-2.7b-pp:1-tp:1-int4_weight_only-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-opt-2.7b-pp:1-tp:1-int8_weight_only-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[deplot-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[deplot-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[fuyu-8b-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[fuyu-8b-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[kosmos-2-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[kosmos-2-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-1.5-7b-hf-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-1.5-7b-hf-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-v1.6-mistral-7b-hf-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-v1.6-mistral-7b-hf-pp:1-tp:1-float16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-v1.6-mistral-7b-hf-vision-trtllm-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-v1.6-mistral-7b-hf-vision-trtllm-pp:1-tp:2-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-onevision-qwen2-7b-ov-hf-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-onevision-qwen2-7b-ov-hf-video-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[neva-22b-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[neva-22b-pp:1-tp:1-bfloat16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[nougat-base-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[nougat-base-pp:1-tp:1-bfloat16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[video-neva-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[video-neva-pp:1-tp:1-bfloat16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[Llama-3.2-11B-Vision-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[Llama-3.2-11B-Vision-pp:1-tp:1-bfloat16-bs:8-cpp_e2e:False-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[Llama-3.2-11B-Vision-pp:1-tp:2-bfloat16-bs:1-cpp_e2e:False-nb:1]
# Multimodal Executor Cpp E2E Tests
examples/test_multimodal.py::test_llm_multimodal_general[VILA1.5-3b-pp:1-tp:1-float16-bs:1-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[VILA1.5-3b-pp:1-tp:1-float16-bs:8-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-opt-2.7b-pp:1-tp:1-float16-bs:8-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[blip2-opt-2.7b-pp:1-tp:1-int4_weight_only-bs:1-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[fuyu-8b-pp:1-tp:1-float16-bs:8-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[kosmos-2-pp:1-tp:1-float16-bs:8-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[llava-1.5-7b-hf-pp:1-tp:1-float16-bs:8-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_multimodal_general[neva-22b-pp:1-tp:1-bfloat16-bs:8-cpp_e2e:True-nb:1]
examples/test_multimodal.py::test_llm_fp8_multimodal_general[fp8-fp8-scienceqa-Llama-3.2-11B-Vision-Instruct-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False]
examples/test_nemotron.py::test_llm_nemotron_3_8b_1gpu[bfloat16-full_prec]
examples/test_nemotron.py::test_llm_nemotron_3_8b_1gpu[bfloat16-int4_awq]
examples/test_nemotron.py::test_llm_nemotron_4_15b_1gpu[bfloat16-fp8]
examples/test_nemotron.py::test_llm_nemotron_4_15b_1gpu[bfloat16-full_prec]
examples/test_nemotron.py::test_llm_nemotron_4_15b_2gpus[bfloat16-fp8]
examples/test_nemotron.py::test_llm_nemotron_4_15b_2gpus[bfloat16-full_prec]
examples/test_nemotron.py::test_llm_nemotron_4_15b_2gpus[bfloat16-int4_awq]
examples/test_nemotron_nas.py::test_nemotron_nas_summary_1gpu[DeciLM-7B]
examples/test_nemotron_nas.py::test_nemotron_nas_summary_2gpu[DeciLM-7B]
examples/test_phi.py::test_llm_phi_1node_2gpus_summary[Phi-3.5-MoE-instruct-nb:1]
examples/test_phi.py::test_llm_phi_1node_2gpus_summary[phi-2-nb:4]
examples/test_phi.py::test_llm_phi_lora_1gpu[Phi-3-mini-4k-instruct-ru-lora-Phi-3-mini-4k-instruct-lora_fp16-base_fp16]
examples/test_phi.py::test_llm_phi_lora_1gpu[Phi-3-mini-4k-instruct-ru-lora-Phi-3-mini-4k-instruct-lora_fp16-base_fp8]
examples/test_phi.py::test_llm_phi_quantization_1gpu[phi-2-fp8-bfloat16]
examples/test_phi.py::test_llm_phi_quantization_1gpu[Phi-3-mini-128k-instruct-fp8-float16]
examples/test_phi.py::test_llm_phi_quantization_1gpu[Phi-3-small-128k-instruct-fp8-bfloat16]
examples/test_phi.py::test_llm_phi_quantization_1gpu[Phi-3.5-mini-instruct-fp8-float16]
examples/test_phi.py::test_llm_phi_quantization_1gpu[Phi-3.5-MoE-instruct-fp8-bfloat16]
examples/test_phi.py::test_llm_phi_single_gpu_summary[phi-2-float16-enable_gemm_plugin-enable_attention_plugin-enable_fmha-nb:4]
examples/test_phi.py::test_llm_phi_single_gpu_summary[phi-2-float16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_phi.py::test_llm_phi_single_gpu_summary[Phi-3-mini-4k-instruct-bfloat16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_phi.py::test_llm_phi_single_gpu_summary[Phi-3-mini-128k-instruct-bfloat16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_phi.py::test_llm_phi_single_gpu_summary[Phi-3-mini-4k-instruct-bfloat16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_phi.py::test_llm_phi_single_gpu_summary[Phi-3-small-128k-instruct-bfloat16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_phi.py::test_llm_phi_single_gpu_summary[Phi-3-small-8k-instruct-bfloat16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_phi.py::test_llm_phi_single_gpu_summary[Phi-3.5-mini-instruct-bfloat16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_phi.py::test_llm_phi_single_gpu_summary[phi-2-float16-enable_gemm_plugin-enable_attention_plugin-enable_fmha-nb:4]
examples/test_phi.py::test_llm_phi_single_gpu_summary[phi-2-float16-enable_gemm_plugin-enable_attention_plugin-enable_fmha_with_fp32_acc-nb:1]
examples/test_pytorch.py::test_llm_llama_1gpu[llama-3.1-8b-enable_fp4]
examples/test_pytorch.py::test_llm_deepseek_1gpu[deepseek-v3-lite-disable_fp8-enable_fp4]
examples/test_pytorch.py::test_llm_deepseek_1gpu[deepseek-v3-lite-disable_fp8-disable_fp4]
examples/test_pytorch.py::test_llm_deepseek_1gpu[deepseek-v3-lite-enable_fp8-disable_fp4]
examples/test_qwen.py::test_llm_qwen1_5_7b_single_gpu_lora[qwen1.5_7b_chat-Qwen1.5-7B-Chat-750Mb-lora]
examples/test_qwen.py::test_llm_qwen1_5_moe_plugin_single_gpu_lora[qwen1.5_moe_a2.7b_chat-Upcycled-Qwen1.5-MoE2.7B-LoRA]
examples/test_qwen.py::test_llm_qwen1_5_moe_single_gpu_lora[qwen1.5_moe_a2.7b_chat-Upcycled-Qwen1.5-MoE2.7B-LoRA]
examples/test_qwen.py::test_llm_qwen_1node_8gpus_summary[qwen1.5_72b_chat-tp4pp2-context_fmha]
examples/test_qwen.py::test_llm_qwen_1node_8gpus_summary[qwen2_72b_instruct-tp8pp1-context_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_1node_8gpus_summary[qwen2.5_72b_chat-tp4pp2-context_fmha]
examples/test_qwen.py::test_llm_qwen_1node_8gpus_summary[qwen2.5_72b_chat-tp8pp1-context_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_7b_int8_kv_1node_1gpus[qwen1.5_7b_chat-enable_gemm_plugin-enable_weight_only]
examples/test_qwen.py::test_llm_qwen_7b_int8_kv_1node_1gpus[qwen2_7b_instruct-enable_gemm_plugin-enable_weight_only]
examples/test_qwen.py::test_llm_qwen_7b_int8_kv_1node_1gpus[qwen2_vl_7b_instruct-enable_gemm_plugin-enable_weight_only]
examples/test_qwen.py::test_llm_qwen_7b_int8_kv_1node_1gpus[qwen2.5_7b_chat-enable_gemm_plugin-enable_weight_only]
examples/test_qwen.py::test_llm_qwen_7b_multi_gpus_summary[qwen1.5_7b_chat-enable_fmha_fp32_acc-enable_plugin-tp2pp2-nb:4]
examples/test_qwen.py::test_llm_qwen_7b_multi_gpus_summary[qwen2_7b_instruct-enable_fmha_fp32_acc-enable_plugin-tp2pp2-nb:4]
examples/test_qwen.py::test_llm_qwen_7b_multi_gpus_summary[qwen2_vl_7b_instruct-enable_fmha_fp32_acc-enable_plugin-tp2pp2-nb:4]
examples/test_qwen.py::test_llm_qwen_7b_multi_gpus_summary[qwen2.5_7b_chat-enable_fmha_fp32_acc-enable_plugin-tp2pp2-nb:4]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen1.5_0.5b_chat-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen1.5_0.5b_chat-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-disable_fmha]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen1.5_7b_chat-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen1.5_7b_chat-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-enable_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2_0.5b_instruct-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2_7b_instruct-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2_7b_instruct-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-enable_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2_vl_7b_instruct-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-disable_fmha]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2_vl_7b_instruct-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-enable_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2.5_0.5b_instruct-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-enable_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2.5_1.5b_instruct-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-enable_fmha_fp32_acc]
examples/test_internlm.py::test_llm_internlm2_7b_1node_1gpu[bfloat16-enable_context_fmha-enable_gemm_plugin-enable_attention_plugin-nb:2] # 5 mins
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2.5_7b_instruct-enable_paged_kv_cache-enable_remove_input_padding-disable_weight_only-enable_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_single_gpu_summary[qwen2.5_7b_instruct-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-enable_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_awq_single_gpu_summary[qwen1.5_7b_chat-nb:4]
examples/test_qwen.py::test_llm_qwen_awq_single_gpu_summary[qwen2_7b_instruct-nb:4]
examples/test_qwen.py::test_llm_qwen_awq_single_gpu_summary[qwen2_vl_7b_instruct-nb:4]
examples/test_qwen.py::test_llm_qwen_awq_single_gpu_summary[qwen2.5_7b_instruct-nb:4]
examples/test_qwen.py::test_llm_qwen_int4_single_gpu_summary[qwen1.5_14b_chat_int4-nb:4]
examples/test_qwen.py::test_llm_qwen_int4_single_gpu_summary[qwen1.5_7b_chat_awq-nb:1]
examples/test_qwen.py::test_llm_qwen_int4_single_gpu_summary[qwen2_7b_awq-nb:1]
examples/test_qwen.py::test_llm_qwen_int4_single_gpu_summary[qwen2.5_14b_instruct_int4-nb:4]
examples/test_qwen.py::test_llm_qwen_moe_multi_gpu_summary[qwen2_57b_a14b-tp2pp2-context_fmha_fp32_acc]
examples/test_qwen.py::test_llm_qwen_moe_multi_gpu_summary[qwen2_57b_a14b-tp4pp1-context_fmha]
examples/test_qwen.py::test_llm_qwen_moe_single_gpu_summary[qwen1.5_moe_a2.7b_chat-enable_paged_kv_cache-enable_remove_input_padding-enable_weight_only-enable_fmha]
examples/test_qwen.py::test_llm_qwen_smooth_quant_single_gpu_summary[qwen1.5_7b_chat-enable_ptpc-nb:4]
examples/test_qwen.py::test_llm_qwen_smooth_quant_single_gpu_summary[qwen2_7b_instruct-enable_ptpc-nb:4]
examples/test_qwen.py::test_llm_qwen_smooth_quant_single_gpu_summary[qwen2_vl_7b_instruct-enable_ptpc-nb:4]
examples/test_qwen.py::test_llm_qwen_smooth_quant_single_gpu_summary[qwen2.5_7b_instruct-enable_ptpc-nb:4]
examples/test_qwen.py::test_llm_hf_qwen_quantization_1gpu[qwen2_0.5b_instruct-fp8-bfloat16]
examples/test_qwen.py::test_llm_hf_qwen_quantization_1gpu[qwen2_7b_instruct-fp8-bfloat16]
examples/test_qwen.py::test_llm_hf_qwen_quantization_1gpu[qwen2_vl_7b_instruct-fp8-bfloat16]
examples/test_qwen.py::test_llm_hf_qwen_quantization_1gpu[qwen2.5_0.5b_instruct-fp8-float16]
examples/test_qwen.py::test_llm_hf_qwen_quantization_1gpu[qwen2.5_1.5b_instruct-fp8-float16]
examples/test_qwen.py::test_llm_hf_qwen_quantization_1gpu[qwen2.5_7b_instruct-fp8-float16]
examples/test_qwen.py::test_llm_hf_qwen_multi_lora_1gpu[qwen2_0.5b_instruct]
examples/test_qwen.py::test_llm_hf_qwen_multi_lora_1gpu[qwen2.5_0.5b_instruct]
examples/test_qwen.py::test_llm_hf_qwen_multi_lora_1gpu[qwen2.5_1.5b_instruct]
examples/test_qwenvl.py::test_llm_qwenvl_single_gpu_summary[qwen-vl-chat]
examples/test_qwen2audio.py::test_llm_qwen2audio_single_gpu[qwen2_audio_7b_instruct]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_cpp_session-recurrentgemma-2b-use_paged_cache-disable_quant-float16-enable_attn_plugin-enable_gemm_plugin]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_py_session-recurrentgemma-2b-flax-no_paged_cache-disable_quant-float16-enable_attn_plugin-disable_gemm_plugin]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_py_session-recurrentgemma-2b-no_paged_cache-disable_quant-float16-disable_attn_plugin-enable_gemm_plugin]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_py_session-recurrentgemma-2b-no_paged_cache-disable_quant-float16-enable_attn_plugin-enable_gemm_plugin]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_py_session-recurrentgemma-2b-use_paged_cache-disable_quant-float16-enable_attn_plugin-enable_gemm_plugin]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_cpp_session-recurrentgemma-2b-use_paged_cache-fp8-float16-enable_attn_plugin-enable_gemm_plugin]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_cpp_session-recurrentgemma-2b-use_paged_cache-int8_sq-float16-enable_attn_plugin-enable_gemm_plugin]
examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_cpp_session-recurrentgemma-2b-use_paged_cache-int4_awq-float16-enable_attn_plugin-enable_gemm_plugin]
examples/test_redrafter.py::test_llm_redrafter_1gpu[use_cpp_session-redrafter-vicuna-7b-v1.3-bfloat16-dl5-nb8-bs8]
examples/test_redrafter.py::test_llm_redrafter_1gpu[use_py_session-redrafter-vicuna-7b-v1.3-bfloat16-dl5-nb5-bs8]
examples/test_sdxl.py::test_sdxl_1node_multi_gpus[num_gpu:2]
examples/test_sdxl.py::test_sdxl_1node_multi_gpus[num_gpu:4]
examples/test_skywork.py::test_llm_skywork_1node_2gpus_summary[enabled-Skywork-13B-base-enable_gemm_plugin-enable_attention_plugin]
examples/test_skywork.py::test_llm_skywork_single_gpu_summary[bfloat16-enabled-Skywork-13B-base-enable_gemm_plugin-enable_attention_plugin]
examples/test_smaug.py::test_llm_smaug_1node_8gpus_summary[enabled-enable_gemm_plugin-enable_attention_plugin]
examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-enable_attention_plugin-disable_weight_only-float16-nb:1-use_cpp_runtime]
examples/test_whisper.py::test_llm_whisper_general[large-v3-enable_gemm_plugin-enable_attention_plugin-disable_weight_only-float16-nb:1-use_python_runtime]
examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-enable_attention_plugin-int8-float16-nb:1-use_cpp_runtime]
examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-enable_attention_plugin-int4-float16-nb:1-use_cpp_runtime]

# Accuracy test list
accuracy/test_accuracy.py::TestGpt2::test_auto_dtype
accuracy/test_accuracy.py::TestGpt2::test_gemm_plugin
accuracy/test_accuracy.py::TestGpt2::test_attention_ootb
accuracy/test_accuracy.py::TestGpt2::test_context_fmha_disabled
accuracy/test_accuracy.py::TestGpt2::test_context_fmha_fp32_acc
accuracy/test_accuracy.py::TestGpt2::test_weight_only[int8]
accuracy/test_accuracy.py::TestGpt2::test_weight_only[int4]
accuracy/test_accuracy.py::TestGpt2::test_int8_kv_cache
accuracy/test_accuracy.py::TestGpt2::test_smooth_quant[]
accuracy/test_accuracy.py::TestGpt2::test_smooth_quant[per_token-per_channel]
accuracy/test_accuracy.py::TestGpt2::test_beam_search
accuracy/test_accuracy.py::TestGpt2::test_beam_search_large
accuracy/test_accuracy.py::TestGpt2::test_weight_streaming_ootb
accuracy/test_accuracy.py::TestGpt2::test_weight_streaming_plugin
accuracy/test_accuracy.py::TestGpt2::test_cuda_graph
accuracy/test_accuracy.py::TestGpt2Medium::test_auto_dtype
accuracy/test_accuracy.py::TestGpt2Medium::test_fp8
accuracy/test_accuracy.py::TestGpt2Medium::test_fp8_lm_head
accuracy/test_accuracy.py::TestSantacoder::test_auto_dtype
accuracy/test_accuracy.py::TestStarcoder2_3B::test_auto_dtype
accuracy/test_accuracy.py::TestStarcoder2_15B::test_smooth_quant_ootb
accuracy/test_accuracy.py::TestGptNext::test_auto_dtype
accuracy/test_accuracy.py::TestMinitron4BBase::test_auto_dtype
accuracy/test_accuracy.py::TestMinitron4BBase::test_fp8
accuracy/test_accuracy.py::TestPhi2::test_auto_dtype
accuracy/test_accuracy.py::TestLongAlpaca7B::test_auto_dtype
accuracy/test_accuracy.py::TestLongAlpaca7B::test_multiblock_aggressive
accuracy/test_accuracy.py::TestMamba130M::test_auto_dtype
accuracy/test_accuracy.py::TestVicuna7B::test_lookahead
accuracy/test_accuracy.py::TestVicuna7B::test_medusa[]
accuracy/test_accuracy.py::TestVicuna7B::test_medusa[cuda_graph]
accuracy/test_accuracy.py::TestVicuna7B::test_eagle[]
accuracy/test_accuracy.py::TestVicuna7B::test_eagle[cuda_graph]
accuracy/test_accuracy.py::TestVicuna7B::test_eagle[cuda_graph-chunked_context]
accuracy/test_accuracy.py::TestVicuna7B::test_eagle[cuda_graph-typical_acceptance]
accuracy/test_accuracy.py::TestLlama7B::test_auto_dtype
accuracy/test_accuracy.py::TestLlama7B::test_beam_search
accuracy/test_accuracy.py::TestLlama7B::test_int4_gptq
accuracy/test_accuracy.py::TestLlama7B::test_streamingllm
accuracy/test_accuracy.py::TestLlama2_7B::test_auto_dtype
accuracy/test_accuracy.py::TestLlama2_7B::test_smooth_quant
accuracy/test_accuracy.py::TestLlama2_7B::test_fp8
accuracy/test_accuracy.py::TestLlama2_7B::test_fp8_2gpus[tp2]
accuracy/test_accuracy.py::TestLlama2_7B::test_fp8_2gpus[pp2]
accuracy/test_accuracy.py::TestLlama2_7B::test_fp8_2gpus[cp2]
accuracy/test_accuracy.py::TestLlama2_7B::test_tp2cp2
accuracy/test_accuracy.py::TestLlama2_7B::test_fp8_gemm_plugin
accuracy/test_accuracy.py::TestLlama2_7B::test_fp8_gemm_swiglu_plugin
accuracy/test_accuracy.py::TestLlama2_7B::test_fp8_low_latency_gemm_plugin
accuracy/test_accuracy.py::TestLlama2_7B::test_smooth_quant_ootb_tp2
accuracy/test_accuracy.py::TestLlama2_7B::test_int4_awq_tp2
accuracy/test_accuracy.py::TestLlama2_7B::test_int4_awq_pre_quantized_tp2
accuracy/test_accuracy.py::TestLlama2_7B::test_int4_gptq_pre_quantized_tp2
accuracy/test_accuracy.py::TestLlama2_7B::test_weight_sparsity
accuracy/test_accuracy.py::TestTinyLlama1_1BChat::test_weight_only[int8]
accuracy/test_accuracy.py::TestTinyLlama1_1BChat::test_weight_only[int4]
accuracy/test_accuracy.py::TestTinyLlama1_1BChat::test_weight_only_int8_kv_cache[int8]
accuracy/test_accuracy.py::TestTinyLlama1_1BChat::test_pp4
accuracy/test_accuracy.py::TestLlama3_8BInstruct::test_auto_dtype
accuracy/test_accuracy.py::TestLlama3_8BInstruct::test_fp8
accuracy/test_accuracy.py::TestLlama3_1_8B::test_auto_dtype
accuracy/test_accuracy.py::TestLlama3_1_8B::test_fp8
accuracy/test_accuracy.py::TestLlama3_1_8BInstruct::test_auto_dtype
accuracy/test_accuracy.py::TestLlama3_1_8BInstruct::test_fp8_pre_quantized
accuracy/test_accuracy.py::TestLlama3_2_1B::test_auto_dtype
accuracy/test_accuracy.py::TestLlama3_2_1B::test_smooth_quant
accuracy/test_accuracy.py::TestLlama3_2_1B::test_smooth_quant_ootb
accuracy/test_accuracy.py::TestLlama3_2_1B::test_int4_awq
accuracy/test_accuracy.py::TestLlama3_2_1B::test_int4_awq_int8_kv_cache
accuracy/test_accuracy.py::TestLlama3_2_1B::test_int4_awq_manage_weights
accuracy/test_accuracy.py::TestLlama3_2_1B::test_fp8
accuracy/test_accuracy.py::TestLlama3_2_1B::test_fp8_pp2
accuracy/test_accuracy.py::TestLlama3_2_1B::test_fp8_rowwise
accuracy/test_accuracy.py::TestLlama3_2_1B::test_weight_streaming[1.0]
accuracy/test_accuracy.py::TestGemma2B::test_auto_dtype
accuracy/test_accuracy.py::TestGemma2B::test_weight_only[int8]
accuracy/test_accuracy.py::TestGemma2B::test_fp8
accuracy/test_accuracy.py::TestGemma2B::test_int4_awq
accuracy/test_accuracy.py::TestGemma7B::test_auto_dtype
accuracy/test_accuracy.py::TestGemma7B::test_weight_only[int8]
accuracy/test_accuracy.py::TestGemma7B::test_fp8
accuracy/test_accuracy.py::TestGemma7B::test_int4_awq
accuracy/test_accuracy.py::TestGemma2_9BIt::test_auto_dtype
accuracy/test_accuracy.py::TestGemma2_9BIt::test_weight_only[int8]
accuracy/test_accuracy.py::TestGemma2_9BIt::test_weight_only[int4]

disaggregated/test_disaggregated.py::test_disaggregated_single_gpu_with_mpirun[TinyLlama-1.1B-Chat-v1.0]
disaggregated/test_disaggregated.py::test_disaggregated_multi_gpu_with_mpirun[TinyLlama-1.1B-Chat-v1.0]
disaggregated/test_disaggregated.py::test_disaggregated_cuda_graph[TinyLlama-1.1B-Chat-v1.0]
test_e2e.py::test_benchmark_sanity[bert_base] # 127.18s
test_e2e.py::test_benchmark_sanity[gpt_350m] # 64.06s
test_e2e.py::test_benchmark_sanity[gpt_350m_sq_per_tensor] # 97.04s
test_e2e.py::test_benchmark_sanity[llama_70b] # 91.93s
test_e2e.py::test_benchmark_sanity[roberta_base]
test_e2e.py::test_benchmark_sanity[t5_base]
test_e2e.py::test_benchmark_sanity_enable_fp8[gpt_350m]
test_e2e.py::test_benchmark_sanity_enable_fp8[gptj_6b]
test_e2e.py::test_benchmark_sanity_enable_fp8[llama_7b]
test_e2e.py::test_falcon_e2e[gpu_percent_0-use_py_session-gqa]
test_e2e.py::test_falcon_e2e[gpu_percent_0_8-use_cpp_session-mqa]
test_e2e.py::test_llama_e2e[use_cpp_session-remove_input_padding]
test_e2e.py::test_llama_e2e[use_py_session-remove_input_padding]
test_e2e.py::test_llama_e2e[use_py_session]
test_e2e.py::test_llmapi_load_engine_from_build_command[falcon-falcon-7b-instruct] # 5min
test_e2e.py::test_llmapi_load_engine_from_build_command[gptj-gpt-j-6b] # 5min
test_e2e.py::test_llmapi_load_engine_from_build_command[llama-codellama/CodeLlama-7b-Instruct-hf] # 5min
test_e2e.py::test_llmapi_load_engine_from_build_command[llama-llama-models/llama-7b-hf] # 5min
test_e2e.py::test_mistral_e2e[use_cpp_session-remove_input_padding]
test_e2e.py::test_mistral_e2e[use_py_session-remove_input_padding]
test_e2e.py::test_mistral_e2e[use_py_session]
test_e2e.py::test_openai_multi_chat_example
test_e2e.py::test_openai_consistent_chat
test_e2e.py::test_llmapi_server_example
# Pivot to Pytorch test cases.
test_e2e.py::test_ptp_quickstart
test_e2e.py::test_ptp_quickstart_advanced[Llama3.1-8B-BF16-llama-3.1-model/Meta-Llama-3.1-8B]
test_e2e.py::test_ptp_quickstart_advanced[Llama3.1-8B-FP8-llama-3.1-model/Llama-3.1-8B-Instruct-FP8]
test_e2e.py::test_ptp_quickstart_advanced[Llama3.1-8B-NVFP4-nvfp4-quantized/Meta-Llama-3.1-8B]
test_e2e.py::test_ptp_quickstart_advanced[Nemotron4_4B-BF16-nemotron/Minitron-4B-Base]
test_e2e.py::test_ptp_quickstart_advanced_8gpus[Llama3.1-70B-BF16-llama-3.1-model/Meta-Llama-3.1-70B]
test_e2e.py::test_ptp_quickstart_advanced_8gpus[Llama3.1-70B-FP8-llama-3.1-model/Llama-3.1-70B-Instruct-FP8]
test_e2e.py::test_ptp_quickstart_advanced_8gpus[Llama3.1-405B-FP8-llama-3.1-model/Llama-3.1-405B-Instruct-FP8]
test_e2e.py::test_ptp_quickstart_advanced_8gpus[Mixtral-8x7B-BF16-Mixtral-8x7B-v0.1]
test_e2e.py::test_ptp_quickstart_advanced_8gpus[Mixtral-8x7B-NVFP4-nvfp4-quantized/Mixtral-8x7B-Instruct-v0.1]
test_e2e.py::test_ptp_quickstart_advanced_deepseek_r1_8gpus[DeepSeek-R1-DeepSeek-R1/DeepSeek-R1]
test_e2e.py::test_ptp_quickstart_multimodal[NVILA-8B-FP16-vila/NVILA-8B-image]
test_e2e.py::test_ptp_quickstart_multimodal[NVILA-8B-FP16-vila/NVILA-8B-video]
test_e2e.py::test_ptp_quickstart_multimodal[llava-v1.6-mistral-7b-llava-v1.6-mistral-7b-hf-image]
test_e2e.py::test_ptp_quickstart_multimodal[qwen2-vl-7b-instruct-Qwen2-VL-7B-Instruct-image]
test_e2e.py::test_ptp_quickstart_multimodal[qwen2-vl-7b-instruct-Qwen2-VL-7B-Instruct-video]
test_e2e.py::test_ptp_quickstart_bert[BertForSequenceClassification-bert/bert-base-uncased-yelp-polarity]
test_e2e.py::test_ptp_star_attention_example[Llama3.1-8B-BF16-llama-3.1-model/Meta-Llama-3.1-8B]
test_e2e.py::test_trtllm_bench_pytorch_backend_sanity[meta-llama/Llama-3.1-8B-llama-3.1-8b-hf-nvfp4-False-False]
test_e2e.py::test_ptp_scaffolding[DeepSeek-R1-Distill-Qwen-7B-DeepSeek-R1/DeepSeek-R1-Distill-Qwen-7B]
examples/test_pytorch.py::test_mmlu_llmapi_4gpus[Llama-3.3-70B-Instruct-fp8-modelopt-hf-model-hub/Llama-3.3-70B-Instruct-fp8]
examples/test_pytorch.py::test_mmlu_llmapi_4gpus[Llama-3.3-70B-Instruct-fp4-modelopt-hf-model-hub/Llama-3.3-70B-Instruct-fp4]
examples/test_pytorch.py::test_mmlu_llmapi_2gpus[Mixtral-8x7B-Instruct-v0.1-fp8-modelopt-hf-model-hub/Mixtral-8x7B-Instruct-v0.1-fp8]
examples/test_pytorch.py::test_mmlu_llmapi_2gpus[Mixtral-8x7B-Instruct-v0.1-fp4-modelopt-hf-model-hub/Mixtral-8x7B-Instruct-v0.1-fp4]
examples/test_medusa.py::test_codellama_medusa_1gpu[CodeLlama-7b-Instruct]
examples/test_medusa.py::test_llama_medusa_1gpu[llama-v2-7b-hf]
examples/test_medusa.py::test_llama_medusa_1gpu[llama-3.2-1b]
examples/test_medusa.py::test_llama_medusa_1gpu[llama-3.1-8b]
examples/test_medusa.py::test_mistral_medusa_1gpu[mistral-7b-v0.1]
examples/test_medusa.py::test_qwen_medusa_1gpu[qwen_7b_chat]
examples/test_medusa.py::test_qwen_medusa_1gpu[qwen1.5_7b_chat]
examples/test_medusa.py::test_qwen_medusa_1gpu[qwen2_7b_instruct]
examples/test_medusa.py::test_qwen_medusa_1gpu[qwen2_0.5b_instruct]
examples/test_medusa.py::test_qwen_medusa_1gpu[qwen2.5_1.5b_instruct]
examples/test_medusa.py::test_phi_medusa_1gpu[phi-2]
examples/test_medusa.py::test_phi_medusa_1gpu[Phi-3-mini-128k-instruct]
examples/test_medusa.py::test_phi_medusa_1gpu[Phi-3-small-128k-instruct]
examples/test_medusa.py::test_phi_medusa_1gpu[Phi-3.5-mini-instruct]

# PyTorch flow disaggregated tests
disaggregated/test_disaggregated.py::test_disaggregated_multi_gpu_with_mpirun[TinyLlama-1.1B-Chat-v1.0]
disaggregated/test_disaggregated.py::test_disaggregated_cuda_graph[TinyLlama-1.1B-Chat-v1.0]
disaggregated/test_disaggregated.py::test_disaggregated_deepseek_v3_lite_fp8[DeepSeek-V3-Lite-fp8]
disaggregated/test_disaggregated.py::test_disaggregated_deepseek_v3_lite_fp8_attention_dp[DeepSeek-V3-Lite-fp8]
disaggregated/test_disaggregated.py::test_disaggregated_deepseek_v3_lite_fp8_attention_dp_one[DeepSeek-V3-Lite-fp8]
disaggregated/test_disaggregated.py::test_disaggregated_deepseek_v3_lite_fp8_attention_dp_one_mtp[DeepSeek-V3-Lite-fp8]

# These tests will impact triton. They should be at the end of all tests (https://nvbugs/4904271)
# examples/test_openai.py::test_llm_openai_triton_1gpu
# examples/test_openai.py::test_llm_openai_triton_plugingen_1gpu
