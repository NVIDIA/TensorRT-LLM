version: 0.0.1
l0_dgx_b300:
- condition:
    ranges:
      system_gpu_count:
        gte: 4
        lte: 4
    wildcards:
      gpu:
      - '*gb110*'
      - '*b300*'
      linux_distribution_name: ubuntu*
      cpu: x86_64
    terms:
      stage: post_merge
      backend: pytorch
  tests:
  - unittest/_torch/modules/test_fused_moe.py::test_fused_moe_alltoall_fp4[DeepEP]
  - unittest/_torch/modules/test_fused_moe.py::test_fused_moe_alltoall_fp4[DeepEPLowLatency]
  - unittest/_torch/modules/test_fused_moe.py::test_fused_moe_fp8_blockwise_wide_ep[NotEnabled]

  # ------------- AutoDeploy tests ---------------
