version: 0.0.1
l0_a100:
- condition:
    ranges:
      system_gpu_count:
        gte: 1
        lte: 1
    wildcards:
      gpu:
      - '*a100*'
      linux_distribution_name: ubuntu*
    terms:
      stage: pre_merge
      backend: "pytorch"
  tests:
    - unittest/llmapi/test_llm_pytorch.py -m "part0"
    - unittest/llmapi/test_llm_pytorch.py -m "part1"
    - unittest/llmapi/test_llm_pytorch.py -m "part2"
    - unittest/llmapi/test_llm_pytorch.py -m "part3"
    - unittest/llmapi/test_mpi_session.py ISOLATION
    - unittest/llmapi/test_memory_profiling.py::test_profile_kvcache # profile kvcache for vision encoder
    - unittest/llmapi/test_memory_profiling.py::test_pyexecutor_and_kvcache_share_execution_stream # test that PyExecutor and KVCacheManager share the same execution_stream
    - unittest/trt/model_api/test_model_quantization.py
    # executor
    - unittest/executor/test_base_worker.py ISOLATION
    - unittest/executor/test_rpc_proxy.py
    - unittest/executor/test_rpc_worker.py
- condition:
    ranges:
      system_gpu_count:
        gte: 1
        lte: 1
    wildcards:
      gpu:
      - '*a100*'
      linux_distribution_name: ubuntu*
    terms:
      stage: post_merge
      backend: tensorrt
  tests:
  - unittest/trt/attention/test_sage_attention.py unittest/llmapi/test_llm_download.py unittest/llmapi/test_llm_kv_cache_events.py unittest/trt/model/redrafter unittest/trt/model/test_phi.py unittest/trt/model/test_unet.py unittest/trt/python_plugin unittest/tools unittest/utils unittest/others
  - unittest/llmapi/test_llm_models.py -m "part1"
  - unittest/llmapi/test_llm_models.py -m "not (part0 or part1)"
  - unittest/llmapi/test_llm.py -m "part0"
  - unittest/llmapi/test_llm.py -m "not part0" TIMEOUT (90)
  - unittest/llmapi/test_executor.py
  - accuracy/test_llm_api.py::TestLlama3_1_8BInstruct::test_guided_decoding[xgrammar]
- condition:
    ranges:
      system_gpu_count:
        gte: 1
        lte: 1
    wildcards:
      gpu:
      - '*a100*'
      linux_distribution_name: ubuntu*
    terms:
      stage: post_merge
      backend: tensorrt
  tests:
  - unittest/trt/model_api/test_model_level_api.py
  - unittest/trt/model_api/test_model_api_multi_gpu.py
  - unittest/trt/model/test_gpt_e2e.py
  - unittest/trt/model/eagle
  - unittest/llmapi/test_llm_models.py -m "part0"
  - examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-enable_attention_plugin-disable_weight_only-float16-nb:1-use_cpp_runtime]
  - examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-enable_attention_plugin-disable_weight_only-float16-nb:1-use_python_runtime]
- condition:
    ranges:
      system_gpu_count:
        gte: 1
        lte: 1
    wildcards:
      gpu:
      - '*a100*'
      linux_distribution_name: ubuntu*
    terms:
      stage: post_merge
      backend: triton
  tests:
  - triton_server/test_triton.py::test_gpt_disaggregated_serving_bls[gpt-disaggregated-serving-bls]
  - triton_server/test_triton.py::test_llava[llava]
  - triton_server/test_triton.py::test_gpt_ib[gpt-ib]
  - triton_server/test_triton.py::test_gpt_ib_ptuning[gpt-ib-ptuning]
  - triton_server/test_triton.py::test_gpt_2b_ib_lora[gpt-2b-ib-lora]
  - triton_server/test_triton.py::test_gpt_ib_lad[gpt-ib-lad]
  - triton_server/test_triton.py::test_gpt_speculative_decoding[gpt-speculative-decoding]
  - triton_server/test_triton.py::test_gpt_ib_speculative_decoding_bls[gpt-ib-speculative-decoding-bls]
  - triton_server/test_triton.py::test_gpt_gather_logits[gpt-gather-logits]
  - triton_server/test_triton.py::test_medusa[medusa]
  - triton_server/test_triton.py::test_mllama[mllama]
  - triton_server/test_triton.py::test_eagle[eagle]
  - triton_server/test_triton.py::test_llava_onevision[llava_onevision]
  - triton_server/test_triton.py::test_qwen2_vl[qwen2_vl]
- condition:
    ranges:
      system_gpu_count:
        gte: 1
        lte: 1
    wildcards:
      gpu:
      - '*a100*'
      linux_distribution_name: ubuntu*
    terms:
      stage: post_merge
      backend: fmha
  tests:
  - test_fmha.py::test_fmha TIMEOUT (90)
