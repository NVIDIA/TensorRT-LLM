meta-llama/Llama-3.3-70B-Instruct:
  - quant_algo: NVFP4
    kv_cache_quant_algo: FP8
    accuracy: 0
  - quant_algo: FP8
    accuracy: 0
