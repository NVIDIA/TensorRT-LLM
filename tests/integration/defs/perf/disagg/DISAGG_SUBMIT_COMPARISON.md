# Disagg æäº¤è„šæœ¬å¯¹æ¯”åˆ†æ

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†å¯¹æ¯”äº†ä¸¤ä¸ª disagg æäº¤ç³»ç»Ÿçš„å·®å¼‚ï¼š
- **disagg_acc/submit.sh** - è€ç‰ˆæœ¬ Shell è„šæœ¬æ–¹å¼
- **disagg/slurm/benchmark/submit.py** - æ–°ç‰ˆæœ¬ Python + YAML é…ç½®æ–¹å¼

---

## ä¸€ã€æ ¸å¿ƒå·®å¼‚æ€»ç»“

| ç»´åº¦ | disagg_acc (æ—§ç‰ˆ) | disagg (æ–°ç‰ˆ) |
|------|------------------|---------------|
| **å®ç°è¯­è¨€** | Pure Shell | Python + Shell |
| **é…ç½®æ–¹å¼** | ç¡¬ç¼–ç å¾ªç¯ | YAML é…ç½®æ–‡ä»¶ |
| **å‚æ•°ä¼ é€’** | ä½ç½®å‚æ•° (14ä¸ª) | YAMLé©±åŠ¨ (28ä¸ª) |
| **èŠ‚ç‚¹è®¡ç®—** | ç®€å•å…¬å¼ | åŸºäº TP å’Œ GPU/èŠ‚ç‚¹ |
| **é…ç½®ç®¡ç†** | å•ä¸ª config.yaml | ctx_config.yaml + gen_config.yaml åˆ†ç¦» |
| **æ‰©å±•æ€§** | ä½ï¼ˆéœ€ä¿®æ”¹è„šæœ¬ï¼‰ | é«˜ï¼ˆåªéœ€ä¿®æ”¹YAMLï¼‰ |
| **å¯ç»´æŠ¤æ€§** | å·® | å¥½ |

---

## äºŒã€ctx_num è®¡ç®—é€»è¾‘å¯¹æ¯”

### 2.1 disagg_acc/submit.sh çš„è®¡ç®—é€»è¾‘

```bash
# æ–‡ä»¶ï¼šdisagg_acc/submit.sh
for b in 1024; do
    concurrency=$((b * 8))                    # concurrency = 1024 * 8 = 8192
    ctx_num=$(((concurrency + 5499)/5500))    # ctx_num = (8192 + 5499) / 5500 = 2
    total_gpu_num=$((ctx_num + 2))            # total_gpu_num = 2 + 2 = 4 (ctx + gen)
    total_tasks=$((total_gpu_num * 4))        # total_tasks = 4 * 4 = 16
done
```

**è®¡ç®—å…¬å¼ï¼š**
```
ctx_num = ceil(concurrency / 5500)
total_nodes = ctx_num + gen_nodes (ç¡¬ç¼–ç ä¸º2)
```

**ç‰¹ç‚¹ï¼š**
- å‡è®¾æ¯ä¸ª ctx server å¤„ç† 5500 å¹¶å‘
- gen_nodes ç¡¬ç¼–ç ï¼ˆdep8=2, dep16=4, dep32=8ï¼‰
- ç®€å•ä½†ä¸çµæ´»

### 2.2 disagg/submit.py çš„è®¡ç®—é€»è¾‘

```python
# æ–‡ä»¶ï¼šdisagg/slurm/benchmark/submit.py

def calculate_nodes(tp_size, num_servers, gpus_per_node):
    """Calculate required nodes based on tensor parallel size and server count."""
    return (tp_size + gpus_per_node - 1) // gpus_per_node * num_servers

# å®é™…è®¡ç®—
ctx_nodes = calculate_nodes(ctx_tp_size, ctx_num, gpus_per_node)
gen_nodes = calculate_nodes(gen_tp_size, gen_num, gpus_per_node)
total_nodes = ctx_nodes + gen_nodes
```

**è®¡ç®—å…¬å¼ï¼š**
```
nodes_per_server = ceil(tp_size / gpus_per_node)
total_nodes = nodes_per_server * num_servers
```

**ç‰¹ç‚¹ï¼š**
- åŸºäº TP size å’Œ GPU/èŠ‚ç‚¹åŠ¨æ€è®¡ç®—
- æ”¯æŒä»»æ„ TP é…ç½®
- ctx_num å’Œ gen_num ç”± YAML é…ç½®å†³å®š
- æ›´é€šç”¨ã€æ›´çµæ´»

**ç¤ºä¾‹å¯¹æ¯”ï¼š**
```
åœºæ™¯ï¼šctx_tp=4, ctx_num=2, gen_tp=32, gen_num=1, gpus_per_node=4

æ—§ç‰ˆï¼ˆç¡¬ç¼–ç ï¼‰:
  ctx_num = 2 (é…ç½®å›ºå®š)
  gen_nodes = 8 (dep32 ç¡¬ç¼–ç )
  total = 10 nodes

æ–°ç‰ˆï¼ˆåŠ¨æ€è®¡ç®—ï¼‰:
  ctx_nodes = ceil(4/4) * 2 = 1 * 2 = 2
  gen_nodes = ceil(32/4) * 1 = 8 * 1 = 8
  total = 10 nodes
```

---

## ä¸‰ã€å‚æ•°ä¼ é€’å¯¹æ¯”

### 3.1 disagg_acc å‚æ•°ä¼ é€’ï¼ˆ14ä¸ªä½ç½®å‚æ•°ï¼‰

```bash
# submit.sh -> disaggr_torch.slurm
sbatch ... disaggr_torch.slurm \
    ${ctx_num}              # $1
    4                       # $2 - ctx_tp_size
    4                       # $3 - ctx_batch_size
    4480                    # $4 - ctx_max_num_tokens
    true                    # $5 - ctx_enable_attention_dp
    1                       # $6 - num_gen_servers
    8                       # $7 - gen_tp_size
    1024                    # $8 - gen_batch_size
    1024                    # $9 - gen_max_num_tokens
    true                    # $10 - gen_enable_attention_dp
    "0.8"                   # $11 - gen_gpu_memory_fraction
    0                       # $12 - eplb_num_slots
    "$mtp_size"             # $13 - mtp_size
    "$concurrency"          # $14 - concurrency
```

**é—®é¢˜ï¼š**
- å‚æ•°é¡ºåºå›ºå®šï¼Œæ˜“å‡ºé”™
- éš¾ä»¥æ‰©å±•ï¼ˆå¢åŠ å‚æ•°éœ€è¦ä¿®æ”¹æ‰€æœ‰è°ƒç”¨ï¼‰
- å¯è¯»æ€§å·®
- æ²¡æœ‰å‚æ•°éªŒè¯

### 3.2 disagg å‚æ•°ä¼ é€’ï¼ˆ28ä¸ªä½ç½®å‚æ•° + YAMLé…ç½®ï¼‰

```python
# submit.py -> disaggr_torch.slurm
cmd = [
    'sbatch',
    # SLURM é…ç½®é€šè¿‡å‘½ä»¤è¡Œå‚æ•°
    f'--partition={slurm_config["partition"]}',
    f'--account={slurm_config["account"]}',
    # ...
    slurm_config['script_file'],
    
    # ç¡¬ä»¶é…ç½®ï¼ˆ6ä¸ªï¼‰
    str(hw_config['gpus_per_node']),        # $1
    str(slurm_config['numa_bind']),         # $2
    str(ctx_nodes),                         # $3
    str(gen_nodes),                         # $4
    str(ctx_tp_size),                       # $5
    str(gen_tp_size),                       # $6
    
    # Worker é…ç½®ï¼ˆ5ä¸ªï¼‰
    str(ctx_num),                           # $7
    ctx_config_path,                        # $8 - YAMLè·¯å¾„
    str(gen_num),                           # $9
    gen_config_path,                        # $10 - YAMLè·¯å¾„
    config['benchmark']['concurrency_list'], # $11
    
    # Benchmark é…ç½®ï¼ˆ7ä¸ªï¼‰
    str(config['sequence']['input_length']), # $12
    str(config['sequence']['output_length']),# $13
    str(config['benchmark']['multi_round']), # $14
    str(config['benchmark']['benchmark_ratio']), # $15
    str(config['benchmark']['streaming']),   # $16
    str(config['benchmark']['use_nv_sa_benchmark']), # $17
    config['benchmark']['mode'],             # $18
    str(config['worker_config']['gen']['cache_transceiver_config']['max_tokens_in_buffer']), # $19
    
    # ç¯å¢ƒé…ç½®ï¼ˆ8ä¸ªï¼‰
    env_config['dataset_file'],              # $20
    env_config['model_path'],                # $21
    env_config['trtllm_repo'],               # $22
    env_config['work_dir'],                  # $23
    log_dir,                                 # $24
    env_config['container_mount'],           # $25
    env_config['container_image'],           # $26
    str(env_config['build_wheel']),          # $27
    
    # Profilingï¼ˆ1ä¸ªï¼‰
    str(config['profiling']['nsys_on'])      # $28
]
```

**ä¼˜åŠ¿ï¼š**
- Worker é…ç½®é€šè¿‡ YAML æ–‡ä»¶ä¼ é€’ï¼ˆæ›´æ¸…æ™°ï¼‰
- Python ä»£ç æœ‰ç±»å‹è½¬æ¢å’ŒéªŒè¯
- æ˜“äºæ·»åŠ æ–°å‚æ•°
- é…ç½®å’Œä»£ç åˆ†ç¦»

---

## å››ã€é…ç½®ç®¡ç†å¯¹æ¯”

### 4.1 disagg_acc é…ç½®ç®¡ç†

```bash
# é…ç½®ç”Ÿæˆï¼šdisaggr_torch.slurm ä¸­è°ƒç”¨ gen_yaml.py
srun ... python3 ${workdir}/${gen_yaml_file} --config ${full_logdir}/config.yaml \
    --model ${model_dir} \
    --num_ctx_servers ${num_ctx_servers} \
    --ctx_tp_size ${ctx_tp_size} \
    # ... 14ä¸ªå‘½ä»¤è¡Œå‚æ•°
```

**ç”Ÿæˆæ–‡ä»¶ï¼š**
- `config.yaml` - å•ä¸€é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰é…ç½®

**ç‰¹ç‚¹ï¼š**
- é…ç½®åœ¨è¿è¡Œæ—¶åŠ¨æ€ç”Ÿæˆ
- æ‰€æœ‰é…ç½®åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­
- éœ€è¦ç­‰å¾…é…ç½®æ–‡ä»¶ç”Ÿæˆï¼ˆè½®è¯¢æ£€æŸ¥ï¼‰

### 4.2 disagg é…ç½®ç®¡ç†

```python
# é…ç½®åœ¨ submit.py ä¸­é¢„å…ˆç”Ÿæˆ
def save_worker_config(config, output_path, worker_type):
    """Save worker config to a separate YAML file."""
    worker_config = config['worker_config'][worker_type]
    with open(output_path, 'w') as f:
        yaml.dump(worker_config, f, default_flow_style=False)

# åˆ†åˆ«ä¿å­˜
save_worker_config(config, ctx_config_path, 'ctx')
save_worker_config(config, gen_config_path, 'gen')
```

**ç”Ÿæˆæ–‡ä»¶ï¼š**
- `ctx_config.yaml` - ctx worker é…ç½®
- `gen_config.yaml` - gen worker é…ç½®
- `server_config.yaml` - server é…ç½®ï¼ˆè¿è¡Œæ—¶ç”Ÿæˆï¼‰

**ç‰¹ç‚¹ï¼š**
- é…ç½®é¢„å…ˆç”Ÿæˆï¼Œæäº¤å‰å°±å‡†å¤‡å¥½
- ctx/gen é…ç½®åˆ†ç¦»ï¼Œä¾¿äºç‹¬ç«‹ç®¡ç†
- å‡å°‘è¿è¡Œæ—¶ä¾èµ–

---

## äº”ã€SLURM è„šæœ¬å¯¹æ¯”

### 5.1 disagg_acc/disaggr_torch.slurm ç‰¹ç‚¹

```bash
# ç¡¬ç¼–ç çš„ SLURM é…ç½®
#SBATCH --nodes=2
#SBATCH --ntasks=8
#SBATCH --partition=36x2-a01r
#SBATCH --account=coreai_comparch_trtllm

# è¿è¡Œæ—¶ç”Ÿæˆé…ç½®
srun ... python3 ${workdir}/${gen_yaml_file} --config ${full_logdir}/config.yaml ...

# ä¸²è¡Œå¯åŠ¨
srun ... bash ${workdir}/start_worker.sh ... &
srun ... bash ${workdir}/start_server.sh ... &
srun ... bash ${workdir}/run_benchmark.sh ...
```

**ç‰¹ç‚¹ï¼š**
- SLURM å‚æ•°éƒ¨åˆ†ç¡¬ç¼–ç åœ¨è„šæœ¬å¤´éƒ¨
- éœ€è¦åœ¨è„šæœ¬å†…ç”Ÿæˆé…ç½®æ–‡ä»¶
- ç®€å•çš„ä¸²è¡Œå¯åŠ¨
- é”™è¯¯å¤„ç†è¾ƒå¼±

### 5.2 disagg/slurm/benchmark/disaggr_torch.slurm ç‰¹ç‚¹

```bash
# æ— ç¡¬ç¼–ç ï¼Œæ‰€æœ‰å‚æ•°ç”± submit.py ä¼ é€’
# æ–‡ä»¶å¤´éƒ¨æ²¡æœ‰ #SBATCH æŒ‡ä»¤

# é…ç½®å·²é¢„å…ˆç”Ÿæˆï¼Œç›´æ¥è¯»å–
enable_pdl=$(python3 -c "import yaml; ...")

# èŠ‚ç‚¹åˆ†é…é€»è¾‘
all_nodes=($(scontrol show hostname $SLURM_NODELIST | sort))
gen_node_list=(${all_nodes[@]:0:${gen_nodes}})
ctx_node_list=(${all_nodes[@]:${gen_nodes}:${total_nodes_num}})

# å¾ªç¯å¯åŠ¨å¤šä¸ª worker
for i in $(seq 0 $((num_gen_servers - 1))); do
    srun -N ${gen_nodes_num_in_single_server} ... \
        bash ${work_dir}/start_worker.sh "GEN" ${i} ... &
done

for i in $(seq 0 $((num_ctx_servers - 1))); do
    srun -N ${ctx_nodes_num_in_single_server} ... \
        bash ${work_dir}/start_worker.sh "CTX" ${i} ... &
done
```

**ç‰¹ç‚¹ï¼š**
- å®Œå…¨åŠ¨æ€é…ç½®ï¼Œæ— ç¡¬ç¼–ç 
- æ”¯æŒå¤š server å®ä¾‹ï¼ˆå¾ªç¯å¯åŠ¨ï¼‰
- èŠ‚ç‚¹æ™ºèƒ½åˆ†é…ï¼ˆgen nodes åœ¨å‰ï¼Œctx nodes åœ¨åï¼‰
- å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—
- æ”¯æŒ wheel æ„å»ºå’Œå®‰è£…

---

## å…­ã€æ—¥å¿—ç›®å½•ç»“æ„å¯¹æ¯”

### 6.1 disagg_acc æ—¥å¿—ç»“æ„

```
bm_1028_deepseek-r1-1024-1024/
â””â”€â”€ dep8_concurrency8192_eplb0_mtp0/
    â”œâ”€â”€ config.yaml              # ç»Ÿä¸€é…ç½®
    â”œâ”€â”€ output_workers.log       # worker æ—¥å¿—
    â”œâ”€â”€ output_server.log        # server æ—¥å¿—
    â””â”€â”€ benchmark.log            # benchmark æ—¥å¿—
```

### 6.2 disagg æ—¥å¿—ç»“æ„

```
1024-1024/
â””â”€â”€ ctx2_gen1_dep32_batch32_eplb0_mtp0/
    â”œâ”€â”€ ctx_config.yaml          # ctx worker é…ç½®
    â”œâ”€â”€ gen_config.yaml          # gen worker é…ç½®
    â”œâ”€â”€ server_config.yaml       # server é…ç½®
    â”œâ”€â”€ job_info.txt             # SLURM job ä¿¡æ¯
    â”œâ”€â”€ environment.txt          # ç¯å¢ƒå˜é‡
    â”œâ”€â”€ container_launch.log     # å®¹å™¨å¯åŠ¨æ—¥å¿—
    â”œâ”€â”€ build.log                # TRT-LLM æ„å»ºæ—¥å¿—
    â”œâ”€â”€ install.log              # å®‰è£…æ—¥å¿—
    â”œâ”€â”€ output_gen_0.log         # gen worker 0 æ—¥å¿—
    â”œâ”€â”€ output_gen_1.log         # gen worker 1 æ—¥å¿—
    â”œâ”€â”€ output_ctx_0.log         # ctx worker 0 æ—¥å¿—
    â”œâ”€â”€ output_server.log        # server æ—¥å¿—
    â””â”€â”€ bench.log                # benchmark æ—¥å¿—
```

**æ–°ç‰ˆä¼˜åŠ¿ï¼š**
- æ—¥å¿—æ›´ç»†ç²’åº¦ï¼ˆæ¯ä¸ª worker ç‹¬ç«‹æ—¥å¿—ï¼‰
- åŒ…å«æ„å»ºå’Œå®‰è£…æ—¥å¿—
- è®°å½•ç¯å¢ƒä¿¡æ¯ä¾¿äºè°ƒè¯•
- ç›®å½•ååŒ…å«æ›´å¤šé…ç½®ä¿¡æ¯

---

## ä¸ƒã€èåˆå¯è¡Œæ€§åˆ†æ

### 7.1 å…³é”®å·®å¼‚ç‚¹

| å·®å¼‚ç‚¹ | å½±å“ | èåˆéš¾åº¦ |
|--------|------|---------|
| ctx_num è®¡ç®—é€»è¾‘ | ä¸­ | **ä½** - å¯é€‰ä¸¤ç§æ¨¡å¼ |
| é…ç½®ç”Ÿæˆæ—¶æœº | é«˜ | **ä¸­** - éœ€ç»Ÿä¸€ä¸ºé¢„ç”Ÿæˆ |
| å‚æ•°ä¼ é€’æ–¹å¼ | é«˜ | **é«˜** - éœ€å¤§é‡é‡æ„ |
| èŠ‚ç‚¹åˆ†é…é€»è¾‘ | é«˜ | **ä¸­** - disagg_acc è¾ƒç®€å• |
| å¤š server æ”¯æŒ | ä¸­ | **ä½** - disagg_acc åªç”¨å•server |

### 7.2 èåˆæ–¹æ¡ˆå»ºè®®

#### **æ–¹æ¡ˆ Aï¼šæœ€å°ä¾µå…¥å¼èåˆ** â­ æ¨è

åœ¨ `submit.py` ä¸­æ·»åŠ  **legacy æ¨¡å¼**æ”¯æŒï¼š

```python
def calculate_ctx_num_legacy(concurrency, capacity_per_ctx=5500):
    """
    Legacy ctx_num calculation (disagg_acc compatible)
    
    Args:
        concurrency: Total concurrency
        capacity_per_ctx: Capacity per ctx server (default 5500)
    
    Returns:
        ctx_num
    """
    return (concurrency + capacity_per_ctx - 1) // capacity_per_ctx

def submit_job(config):
    # æ£€æµ‹æ˜¯å¦å¯ç”¨ legacy æ¨¡å¼
    use_legacy_ctx_calc = config.get('metadata', {}).get('use_legacy_ctx_calculation', False)
    
    if use_legacy_ctx_calc:
        # Legacy æ¨¡å¼ï¼šæ ¹æ® concurrency è®¡ç®— ctx_num
        concurrency = int(config['benchmark']['concurrency_list'].split(',')[0])
        ctx_num = calculate_ctx_num_legacy(concurrency)
        config['hardware']['num_ctx_servers'] = ctx_num
        print(f"   ğŸ”§ Legacy mode: Calculated ctx_num={ctx_num} for concurrency={concurrency}")
    
    # åç»­é€»è¾‘ä¿æŒä¸å˜
    ctx_tp_size = config['worker_config']['ctx']['tensor_parallel_size']
    gen_tp_size = config['worker_config']['gen']['tensor_parallel_size']
    # ...
```

**YAML é…ç½®ç¤ºä¾‹ï¼š**
```yaml
metadata:
  model_name: "deepseek-r1-fp4"
  use_legacy_ctx_calculation: true  # å¯ç”¨ legacy æ¨¡å¼

benchmark:
  concurrency_list: "8192"  # ç”¨äºè®¡ç®— ctx_num

hardware:
  gpus_per_node: 4
  num_gen_servers: 1  # ä»éœ€æŒ‡å®š
  # num_ctx_servers å°†è‡ªåŠ¨è®¡ç®—
```

**ä¼˜åŠ¿ï¼š**
- âœ… å‘åå…¼å®¹ disagg_acc çš„è®¡ç®—é€»è¾‘
- âœ… ä¸å½±å“ç°æœ‰åŠŸèƒ½
- âœ… é€šè¿‡é…ç½®é€‰é¡¹æ§åˆ¶
- âœ… å®ç°ç®€å•ï¼Œé£é™©ä½

#### **æ–¹æ¡ˆ Bï¼šå®Œå…¨ç»Ÿä¸€ï¼ˆæ¨èé•¿æœŸï¼‰**

åºŸå¼ƒ disagg_accï¼Œæ‰€æœ‰æµ‹è¯•è¿ç§»åˆ°æ–°ç‰ˆï¼š

1. **åˆ›å»ºè¿ç§»å·¥å…·**ï¼š
```python
# disagg_acc_to_yaml.py
def convert_submit_sh_to_yaml(submit_sh_path):
    """å°† submit.sh ä¸­çš„é…ç½®è½¬æ¢ä¸º YAML"""
    # è§£æ submit.sh ä¸­çš„å¾ªç¯å’Œå‚æ•°
    # ç”Ÿæˆå¯¹åº”çš„ YAML é…ç½®æ–‡ä»¶
    pass
```

2. **ç»Ÿä¸€é…ç½®æ ¼å¼**ï¼š
   - æ‰€æœ‰é…ç½®ä½¿ç”¨ YAML
   - ä½¿ç”¨æ–°ç‰ˆçš„èŠ‚ç‚¹è®¡ç®—é€»è¾‘
   - ä½¿ç”¨åˆ†ç¦»çš„ worker é…ç½®

3. **é€æ­¥è¿ç§»**ï¼š
   - ç¬¬ä¸€é˜¶æ®µï¼šä¸¤å¥—ç³»ç»Ÿå¹¶è¡Œ
   - ç¬¬äºŒé˜¶æ®µï¼šæ–°åŠŸèƒ½åªåœ¨æ–°ç‰ˆå®ç°
   - ç¬¬ä¸‰é˜¶æ®µï¼šåºŸå¼ƒæ—§ç‰ˆ

**ä¼˜åŠ¿ï¼š**
- âœ… é•¿æœŸç»´æŠ¤æˆæœ¬ä½
- âœ… åŠŸèƒ½ç»Ÿä¸€ï¼Œé¿å…åˆ†è£‚
- âœ… æ›´å¥½çš„æ‰©å±•æ€§

**åŠ£åŠ¿ï¼š**
- âš ï¸ éœ€è¦è¿ç§»ç°æœ‰é…ç½®
- âš ï¸ å¯èƒ½å½±å“ç°æœ‰è„šæœ¬

---

## å…«ã€å…·ä½“å®æ–½æ­¥éª¤ï¼ˆæ–¹æ¡ˆ Aï¼‰

### Step 1: åœ¨ submit.py ä¸­æ·»åŠ  legacy æ”¯æŒ

```python
# disagg/slurm/benchmark/submit.py

def calculate_ctx_num_legacy(concurrency, capacity_per_ctx=5500):
    """Legacy ctx_num calculation for disagg_acc compatibility"""
    return (concurrency + capacity_per_ctx - 1) // capacity_per_ctx

def submit_job(config):
    # ... ç°æœ‰ä»£ç  ...
    
    # Check for legacy mode
    metadata = config.get('metadata', {})
    use_legacy = metadata.get('use_legacy_ctx_calculation', False)
    
    if use_legacy:
        # Parse first concurrency value
        concurrency_str = config['benchmark']['concurrency_list']
        first_concurrency = int(concurrency_str.split(',')[0])
        
        # Calculate ctx_num using legacy formula
        ctx_num = calculate_ctx_num_legacy(
            first_concurrency,
            capacity_per_ctx=metadata.get('ctx_capacity', 5500)
        )
        
        # Override hardware config
        config['hardware']['num_ctx_servers'] = ctx_num
        
        print(f"   ğŸ”§ Legacy mode enabled:")
        print(f"      Concurrency: {first_concurrency}")
        print(f"      Calculated ctx_num: {ctx_num}")
        print(f"      Capacity per ctx: {metadata.get('ctx_capacity', 5500)}")
    
    # ... ç»§ç»­ç°æœ‰é€»è¾‘ ...
```

### Step 2: æ›´æ–° config_loader.py

åœ¨ `TestConfig` ä¸­æ·»åŠ  legacy æ¨¡å¼è¯†åˆ«ï¼š

```python
# config_loader.py

def _load_config_file(self, yaml_path: Path, test_type: str,
                     test_category: str) -> TestConfig:
    """Load single YAML config file"""
    # ... ç°æœ‰ä»£ç  ...
    
    # æ£€æµ‹ legacy æ¨¡å¼
    metadata = config_data.get('metadata', {})
    if metadata.get('use_legacy_ctx_calculation'):
        print(f"   ğŸ”§ Legacy ctx_num calculation enabled")
    
    # ... ç»§ç»­ ...
```

### Step 3: åˆ›å»º legacy é…ç½®æ¨¡æ¿

```yaml
# test_configs/disagg/perf/deepseek-r1-fp4_1k1k_dep8_legacy.yaml

metadata:
  model_name: "deepseek-r1-fp4"
  precision: "fp4"
  use_legacy_ctx_calculation: true  # å¯ç”¨ legacy æ¨¡å¼
  ctx_capacity: 5500                # æ¯ä¸ª ctx server çš„å®¹é‡
  supported_gpus: ["GB200"]

# å…¶ä»–é…ç½®ä¿æŒä¸å˜
benchmark:
  concurrency_list: "8192"  # å°†ç”¨äºè®¡ç®— ctx_num
  
hardware:
  gpus_per_node: 4
  num_gen_servers: 1
  # num_ctx_servers å°†è‡ªåŠ¨è®¡ç®—ä¸º 2
```

### Step 4: æµ‹è¯•éªŒè¯

```bash
# æµ‹è¯• legacy æ¨¡å¼
python3 disagg/slurm/benchmark/submit.py \
    -c test_configs/disagg/perf/deepseek-r1-fp4_1k1k_dep8_legacy.yaml

# åº”è¯¥çœ‹åˆ°ï¼š
#   ğŸ”§ Legacy mode enabled:
#      Concurrency: 8192
#      Calculated ctx_num: 2
#      Capacity per ctx: 5500
```

---

## ä¹ã€æ€»ç»“

### ä¸»è¦åŒºåˆ«

1. **æ¶æ„å±‚é¢**ï¼š
   - æ—§ç‰ˆï¼šShell è„šæœ¬ + ç¡¬ç¼–ç é…ç½®
   - æ–°ç‰ˆï¼šPython + YAML + åŠ¨æ€é…ç½®

2. **èŠ‚ç‚¹è®¡ç®—**ï¼š
   - æ—§ç‰ˆï¼šåŸºäºå¹¶å‘æ•°çš„ç®€å•å…¬å¼
   - æ–°ç‰ˆï¼šåŸºäº TP size çš„ç²¾ç¡®è®¡ç®—

3. **é…ç½®ç®¡ç†**ï¼š
   - æ—§ç‰ˆï¼šè¿è¡Œæ—¶ç”Ÿæˆå•ä¸€é…ç½®
   - æ–°ç‰ˆï¼šé¢„ç”Ÿæˆåˆ†ç¦»é…ç½®

4. **æ‰©å±•æ€§**ï¼š
   - æ—§ç‰ˆï¼šéœ€ä¿®æ”¹è„šæœ¬ä»£ç 
   - æ–°ç‰ˆï¼šåªéœ€ä¿®æ”¹ YAML é…ç½®

### èåˆå»ºè®®

**çŸ­æœŸï¼ˆæ¨èï¼‰ï¼šæ–¹æ¡ˆ A - æœ€å°ä¾µå…¥å¼èåˆ**
- åœ¨æ–°ç‰ˆä¸­æ·»åŠ  legacy æ¨¡å¼æ”¯æŒ
- é€šè¿‡é…ç½®å¼€å…³æ§åˆ¶
- ä¿æŒå‘åå…¼å®¹

**é•¿æœŸï¼šæ–¹æ¡ˆ B - å®Œå…¨ç»Ÿä¸€**
- è¿ç§»æ‰€æœ‰é…ç½®åˆ°æ–°ç‰ˆ
- åºŸå¼ƒ disagg_acc
- ç»Ÿä¸€ç»´æŠ¤

### ä¼˜å…ˆçº§

1. âœ… **é«˜ä¼˜å…ˆçº§**ï¼šå®ç°æ–¹æ¡ˆ Aï¼ˆ1-2å¤©å·¥ä½œé‡ï¼‰
2. â­ **ä¸­ä¼˜å…ˆçº§**ï¼šåˆ›å»ºé…ç½®è¿ç§»å·¥å…·ï¼ˆ1å‘¨ï¼‰
3. ğŸ“ **ä½ä¼˜å…ˆçº§**ï¼šå®Œå…¨åºŸå¼ƒæ—§ç‰ˆï¼ˆé•¿æœŸè®¡åˆ’ï¼‰

---

**å»ºè®®ï¼šå…ˆå®æ–½æ–¹æ¡ˆ Aï¼ŒéªŒè¯ç¨³å®šåå†è€ƒè™‘å®Œå…¨è¿ç§»ã€‚**

