unittest_case_name,gpu,parallel_factor,comment
unittest/trt/quantization,NVIDIA A10,18,
unittest/trt/model/test_gptj.py,NVIDIA A10,5,
unittest/trt/functional,NVIDIA A10,6,
unittest/trt/model/test_gptneox.py,NVIDIA A10,2,
unittest/trt/attention/test_bert_attention.py,NVIDIA A10,17,
unittest/trt/model/test_falcon.py,NVIDIA A10,16,
"unittest/trt/model/test_gpt.py -k ""partition2""",NVIDIA A10,11,
"unittest/trt/model/test_gpt.py -k ""partition3""",NVIDIA A10,11,
"unittest/trt/model/test_gpt.py -k ""other""",NVIDIA A10,13,
unittest/trt/attention/test_gpt_attention_IFB.py,NVIDIA A10,17,
unittest/trt/attention/test_gpt_attention_no_cache.py,NVIDIA A10,23,
unittest/trt/model/test_mamba.py,NVIDIA A10,12,
unittest/trt/model/test_llama.py,NVIDIA A10,3,
"unittest/trt/attention/test_gpt_attention.py -k ""partition0""",NVIDIA A10,14,
"unittest/trt/attention/test_gpt_attention.py -k ""partition1""",NVIDIA A10,10,
"unittest/trt/attention/test_gpt_attention.py -k ""partition2""",NVIDIA A10,3,
"unittest/trt/attention/test_gpt_attention.py -k ""partition3""",NVIDIA A10,3,
"unittest/trt/attention/test_gpt_attention.py -k ""xqa_generic""",NVIDIA A10,2,
"unittest/trt/model/test_gpt.py -k ""partition0""",NVIDIA A30,13,
"unittest/trt/model/test_gpt.py -k ""partition1""",NVIDIA A30,13,
"unittest/trt/model/test_gpt.py -k ""partition2""",NVIDIA A30,4,
"unittest/trt/model/test_gpt.py -k ""partition3""",NVIDIA A30,4,
unittest/attention/test_sage_attention.py unittest/llmapi/test_llm_download.py unittest/llmapi/test_llm_kv_cache_events.py unittest/llmapi/test_mpi_session.py unittest/trt/model/redrafter unittest/trt/model/test_phi.py unittest/trt/model/test_unet.py unittest/python_plugin unittest/tools unittest/utils unittest/others,NVIDIA A30,1,
"unittest/llmapi/test_llm_models.py -m ""part0""",NVIDIA A30,1,
"unittest/llmapi/test_llm_models.py -m ""part1""",NVIDIA A30,1,
"unittest/llmapi/test_llm_models.py -m ""not (part0 or part1)""",NVIDIA A30,1,
unittest/attention/test_sage_attention.py unittest/llmapi/test_llm_download.py unittest/llmapi/test_llm_kv_cache_events.py unittest/llmapi/test_mpi_session.py unittest/trt/model/redrafter unittest/trt/model/test_phi.py unittest/trt/model/test_unet.py unittest/python_plugin unittest/tools unittest/utils unittest/others,NVIDIA A100X,4,
llmapi-tp-2gpu,NVIDIA H100 80GB HBM3,1,
unittest/llmapi/test_llm_models_multi_gpu.py,NVIDIA H100 80GB HBM3,1,
unittest/trt/model/test_gptneox.py,NVIDIA H100 80GB HBM3,7,
unittest/trt/attention/test_bert_attention.py,NVIDIA H100 80GB HBM3,11,
unittest/trt/model_api/test_model_quantization.py,NVIDIA H100 80GB HBM3,3,
model-bert,NVIDIA H100 80GB HBM3,11,
unittest/trt/model/test_gpt_e2e.py,NVIDIA H100 80GB HBM3,12,
unittest/bindings,NVIDIA H100 80GB HBM3,1,
unittest/llmapi/test_llm_quant.py,NVIDIA H100 80GB HBM3,1,
"unittest/trt/attention/test_gpt_attention.py -k ""xqa_generic""",NVIDIA H100 80GB HBM3,6,
unittest/trt/functional/test_moe.py,NVIDIA H100 80GB HBM3,10,
unittest/trt/quantization/test_weight_only_quant_matmul.py,NVIDIA H100 80GB HBM3,13,
unittest/trt/quantization/test_weight_only_groupwise_quant_matmul.py,NVIDIA H100 80GB HBM3,13,
unittest/trt/attention/test_gpt_attention_IFB.py,NVIDIA H100 80GB HBM3,11,
unittest/trt/attention/test_gpt_attention_no_cache.py,NVIDIA H100 80GB HBM3,13,
unittest/trt/model/test_mamba.py,NVIDIA H100 80GB HBM3,10,
"unittest/trt/attention/test_gpt_attention.py -k ""partition0""",NVIDIA L40S,14,
"unittest/trt/attention/test_gpt_attention.py -k ""partition1""",NVIDIA L40S,10,
"unittest/trt/attention/test_gpt_attention.py -k ""partition2""",NVIDIA L40S,6,
"unittest/trt/attention/test_gpt_attention.py -k ""partition3""",NVIDIA L40S,6,
"unittest/trt/attention/test_gpt_attention.py -k ""xqa_generic""",NVIDIA L40S,3,
unittest/trt/functional,NVIDIA L40S,32,
llmapi-tp-2gpu,NVIDIA H100 PCIe,1,
unittest/llmapi/test_llm_models_multi_gpu.py,NVIDIA H100 PCIe,1,
unittest/trt/model/test_gptneox.py,NVIDIA H100 PCIe,7,
unittest/trt/attention/test_bert_attention.py,NVIDIA H100 PCIe,11,
unittest/trt/model_api/test_model_quantization.py,NVIDIA H100 PCIe,3,
model-bert,NVIDIA H100 PCIe,11,
unittest/trt/model/test_gpt_e2e.py,NVIDIA H100 PCIe,12,
unittest/bindings,NVIDIA H100 PCIe,1,
unittest/llmapi/test_llm_quant.py,NVIDIA H100 PCIe,1,
"unittest/trt/attention/test_gpt_attention.py -k ""xqa_generic""",NVIDIA H100 PCIe,6,
unittest/trt/functional/test_moe.py,NVIDIA H100 PCIe,10,
unittest/trt/quantization/test_weight_only_quant_matmul.py,NVIDIA H100 PCIe,13,
unittest/trt/quantization/test_weight_only_groupwise_quant_matmul.py,NVIDIA H100 PCIe,13,
unittest/trt/attention/test_gpt_attention_IFB.py,NVIDIA H100 PCIe,11,
unittest/trt/attention/test_gpt_attention_no_cache.py,NVIDIA H100 PCIe,13,
unittest/trt/model/test_mamba.py,NVIDIA H100 PCIe,10,
llmapi-tp-2gpu,NVIDIA H100 NVL,1,
unittest/llmapi/test_llm_models_multi_gpu.py,NVIDIA H100 NVL,1,
unittest/trt/model/test_gptneox.py,NVIDIA H100 NVL,7,
unittest/trt/attention/test_bert_attention.py,NVIDIA H100 NVL,11,
unittest/trt/model_api/test_model_quantization.py,NVIDIA H100 NVL,3,
model-bert,NVIDIA H100 NVL,11,
unittest/trt/model/test_gpt_e2e.py,NVIDIA H100 NVL,12,
unittest/bindings,NVIDIA H100 NVL,1,
unittest/llmapi/test_llm_quant.py,NVIDIA H100 NVL,1,
"unittest/trt/attention/test_gpt_attention.py -k ""xqa_generic""",NVIDIA H100 NVL,6,
unittest/trt/functional/test_moe.py,NVIDIA H100 NVL,10,
unittest/trt/quantization/test_weight_only_quant_matmul.py,NVIDIA H100 NVL,13,
unittest/trt/quantization/test_weight_only_groupwise_quant_matmul.py,NVIDIA H100 NVL,13,
unittest/trt/attention/test_gpt_attention_IFB.py,NVIDIA H100 NVL,11,
unittest/trt/attention/test_gpt_attention_no_cache.py,NVIDIA H100 NVL,13,
unittest/trt/model/test_mamba.py,NVIDIA H100 NVL,10,
llmapi-tp-2gpu,NVIDIA H100,1,
unittest/llmapi/test_llm_models_multi_gpu.py,NVIDIA H100,1,
unittest/trt/model/test_gptneox.py,NVIDIA H100,7,
unittest/trt/attention/test_bert_attention.py,NVIDIA H100,11,
unittest/trt/model_api/test_model_quantization.py,NVIDIA H100,3,
model-bert,NVIDIA H100,11,
unittest/trt/model/test_gpt_e2e.py,NVIDIA H100,12,
unittest/bindings,NVIDIA H100,1,
unittest/llmapi/test_llm_quant.py,NVIDIA H100,1,
"unittest/trt/attention/test_gpt_attention.py -k ""xqa_generic""",NVIDIA H100,6,
unittest/trt/functional/test_moe.py,NVIDIA H100,10,
unittest/trt/quantization/test_weight_only_quant_matmul.py,NVIDIA H100,13,
unittest/trt/quantization/test_weight_only_groupwise_quant_matmul.py,NVIDIA H100,13,
unittest/trt/attention/test_gpt_attention_IFB.py,NVIDIA H100,11,
unittest/trt/attention/test_gpt_attention_no_cache.py,NVIDIA H100,13,
unittest/trt/model/test_mamba.py,NVIDIA H100,10,
"unittest/trt/attention/test_gpt_attention.py -k ""partition0""",NVIDIA L40,14,
"unittest/trt/attention/test_gpt_attention.py -k ""partition1""",NVIDIA L40,10,
"unittest/trt/attention/test_gpt_attention.py -k ""partition2""",NVIDIA L40,6,
"unittest/trt/attention/test_gpt_attention.py -k ""partition3""",NVIDIA L40,6,
"unittest/trt/attention/test_gpt_attention.py -k ""xqa_generic""",NVIDIA L40,3,
unittest/_torch/attention,NVIDIA Graphics Device,4,B200 Bring Up Board
unittest/_torch/misc,NVIDIA Graphics Device,4,B200 Bring Up Board
unittest/_torch/speculative,NVIDIA Graphics Device,4,B200 Bring Up Board
unittest/_torch/thop/parallel,NVIDIA Graphics Device,16,B200 Bring Up Board
"unittest/_torch/auto_deploy/unit/singlegpu -k ""not test_trtllm_bench_backend_comparison""",NVIDIA Graphics Device,4,B200 Bring Up Board
unittest/_torch/attention,NVIDIA B200,4,
unittest/_torch/misc,NVIDIA B200,4,
unittest/_torch/speculative,NVIDIA B200,4,
unittest/_torch/thop/parallel,NVIDIA B200,16,
"unittest/_torch/auto_deploy/unit/singlegpu -k ""not test_trtllm_bench_backend_comparison""",NVIDIA B200,4,
unittest/_torch/attention,NVIDIA H100,4,
unittest/_torch/misc,NVIDIA H100,4,
unittest/_torch/speculative,NVIDIA H100,2,
unittest/_torch/thop/parallel,NVIDIA H100,16,
