methods:
  __init__:
    parameters:
      gpus_per_node:
        annotation: Optional[int]
        default: null
      enable_attention_dp:
        annotation: bool
        default: false
      cp_config:
        annotation: Optional[dict]
        default: null
      auto_parallel:
        annotation: bool
        default: false
      auto_parallel_world_size:
        annotation: int
        default: 1
      build_config:
        annotation: Optional[tensorrt_llm.BuildConfig]
        default: null
      kwargs:
        annotation: Any
        default: inspect._empty
      iter_stats_max_iterations:
        annotation: Optional[int]
        default: null
      request_stats_max_iterations:
        annotation: Optional[int]
        default: null
      workspace:
        annotation: Optional[str]
        default: null
      embedding_parallel_mode:
        annotation: str
        default: 'SHARDING_ALONG_VOCAB'
      fast_build:
        annotation: bool
        default: false
      enable_build_cache:
        annotation: Union[tensorrt_llm.llmapi.llm_utils.BuildCacheConfig, bool]
        default: false
      peft_cache_config:
        annotation: Optional[tensorrt_llm.llmapi.llm_args.PeftCacheConfig]
        default: null
      scheduler_config:
        annotation: Optional[tensorrt_llm.llmapi.llm_args.SchedulerConfig]
        default: null
      batching_type:
        annotation: Optional[tensorrt_llm.llmapi.llm_args.BatchingType]
        default: null
      normalize_log_probs:
        annotation: bool
        default: false
      gather_generation_logits:
        annotation: bool
        default: false
      extended_runtime_perf_knob_config:
        annotation: Optional[tensorrt_llm.llmapi.llm_args.ExtendedRuntimePerfKnobConfig]
        default: null
      backend:
        annotation: Optional[str]
        default: null

    return_annotation: None
  generate:
    parameters:
      # TODO [TRTLLM-3925]
      disaggregated_params:
        annotation: Optional[tensorrt_llm.disaggregated_params.DisaggregatedParams]
        default: null
      kv_cache_retention_config:
        annotation: Optional[tensorrt_llm.bindings.executor.KvCacheRetentionConfig]
        default: null
      queries:
        annotation: Union[str, List[int], tensorrt_llm.inputs.data.TextPrompt, tensorrt_llm.inputs.data.TokensPrompt,
          Sequence[Union[str, List[int], tensorrt_llm.inputs.data.TextPrompt, tensorrt_llm.inputs.data.TokensPrompt]],
          NoneType]
        default: null
    return_annotation: Union[tensorrt_llm.llmapi.llm.RequestOutput, List[tensorrt_llm.llmapi.llm.RequestOutput]]
  generate_async:
    parameters:
      disaggregated_params:
        annotation: Optional[tensorrt_llm.disaggregated_params.DisaggregatedParams]
        default: null
      kv_cache_retention_config:
        annotation: Optional[tensorrt_llm.bindings.executor.KvCacheRetentionConfig]
        default: null
      queries:
        annotation: Union[str, List[int], tensorrt_llm.inputs.data.TextPrompt, tensorrt_llm.inputs.data.TokensPrompt,
          NoneType]
        default: null
    return_annotation: tensorrt_llm.llmapi.llm.RequestOutput
  get_kv_cache_events:
    parameters:
      timeout:
        annotation: Optional[float]
        default: 2
    return_annotation: List[dict]
  get_kv_cache_events_async:
    parameters:
      timeout:
        annotation: Optional[float]
        default: 2
    return_annotation: tensorrt_llm.executor.result.IterationResult
  get_stats:
    parameters:
      timeout:
        annotation: Optional[float]
        default: 2
    return_annotation: List[dict]
  get_stats_async:
    parameters:
      timeout:
        annotation: Optional[float]
        default: 2
    return_annotation: tensorrt_llm.executor.result.IterationResult
  save:
    parameters:
      engine_dir:
        annotation: str
        default: inspect._empty
    return_annotation: None
  shutdown:
    parameters: {}
    return_annotation: None
properties:
  workspace:
    annotation: pathlib.Path
    default: inspect._empty
