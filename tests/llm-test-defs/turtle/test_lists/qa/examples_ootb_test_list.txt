examples/test_baichuan.py::test_llm_baichuan_1node_2gpus[v1_13b-serial_build-float16-disable_gemm_plugin-disable_attention_plugin]
examples/test_baichuan.py::test_llm_baichuan_single_gpu_summary[v1_13b-bfloat16-disable_gemm_plugin-disable_attention_plugin]
examples/test_baichuan.py::test_llm_baichuan_single_gpu_summary[v1_13b-bfloat16-enable_gemm_plugin-disable_attention_plugin]
examples/test_baichuan.py::test_llm_baichuan_single_gpu_summary[v2_13b-float16-enable_gemm_plugin-disable_attention_plugin]
examples/test_baichuan.py::test_llm_baichuan_single_gpu_summary[v1_13b-int4-enable_gemm_plugin-disable_attention_plugin]
examples/test_baichuan.py::test_llm_baichuan_single_gpu_summary[v2_13b-int8-enable_gemm_plugin-disable_attention_plugin]
examples/test_falcon.py::test_llm_falcon_rw_1b_1node_2gpus[use_py_session-disable_attention_plugin-disable_parallel_embedding-nb:4]
examples/test_falcon.py::test_llm_falcon_rw_1b_1node_2gpus[use_py_session-disable_attention_plugin-embedding_sharding_dim:0-nb:4]
examples/test_falcon.py::test_llm_falcon_rw_1b_1node_1gpus[use_py_session-float16-disabled-disable_attention_plugin-nb:1]
examples/test_gpt.py::test_llm_gpt2_1gpu[disable_gemm_plugin-disable_attention_plugin]
examples/test_gpt.py::test_llm_gpt2_santacoder_1node_4gpus[serial_build-disable_fmha-disable_gemm_plugin-disable_attention_plugin]
examples/test_gpt.py::test_llm_gpt2_starcoder_1node_4gpus[starcoder-disable_fmha-disable_gemm_plugin-disable_attention_plugin]
examples/test_gpt.py::test_llm_gpt3_175b_1node_8gpus[serial_build-disable_fmha-disable_gemm_plugin-disable_attention_plugin]
examples/test_gptj.py::test_llm_gptj_single_gpu_summary[disable_fp8_context_fmha_xqa-enable_weight_only_groupwise_quant_matmul_plugin-disabled-disable_gpt_attention_plugin-disable_gemm_plugin-disable_fp8-nb:1]
examples/test_llama.py::test_llm_llama_code_llama_1gpu_summary[CodeLlama-7b-Instruct-disable_context_fmha-disable_gemm_plugin-disable_attention_plugin-nb:1]
examples/test_llama.py::test_llm_llama_v2_1gpu_weight_streaming[llama-v2-7b-hf-1.0-ootb]
examples/test_llama.py::test_llm_llama_v2_1gpu_weight_streaming[llama-v2-70b-hf-0.05-ootb]
examples/test_phi.py::test_llm_phi_single_gpu_summary[phi-2-float16-disable_gemm_plugin-disable_attention_plugin-disable_fmha-nb:2]
